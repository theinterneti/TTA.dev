# E2B Machine Learning Template
# This creates a pre-configured ML environment for faster sandbox startup

# MUST use E2B base image
FROM e2bdev/code-interpreter:latest

# Install core ML dependencies (done once at build time, not per-sandbox!)
RUN pip install --no-cache-dir \
    torch \
    transformers \
    numpy \
    pandas \
    scikit-learn \
    matplotlib \
    seaborn \
    plotly

# Install additional utilities
RUN pip install --no-cache-dir \
    tqdm \
    datasets \
    evaluate \
    accelerate

# Set up Hugging Face cache directory
ENV HF_HOME=/root/.cache/huggingface
RUN mkdir -p /root/.cache/huggingface

# Create working directory
RUN mkdir -p /root/workspace
WORKDIR /root/workspace

# Optional: Pre-download a common model (uncomment if needed)
# RUN python -c "from transformers import AutoModel; AutoModel.from_pretrained('distilbert-base-uncased')"

# Set environment variables
ENV TRANSFORMERS_CACHE=/root/.cache/huggingface
ENV TORCH_HOME=/root/.cache/torch

# Build this template with:
# e2b template build -c "/root/.jupyter/start-up.sh"
#
# This will:
# 1. Build the Docker image with all ML dependencies
# 2. Upload to E2B cloud
# 3. Create a snapshot (micro VM)
# 4. Return a template ID like: template_abc123xyz
#
# Usage in Python:
# from e2b_code_interpreter import Sandbox
# sandbox = await Sandbox.create(template="template_abc123xyz")
#
# Benefits:
# - 30 seconds install time â†’ 100ms startup time
# - Consistent ML environment every time
# - Pre-configured Hugging Face cache
# - Ready for immediate code execution
