"""Comprehensive tests for CachePrimitive.

Generated by ACE + E2B self-learning system.
Total scenarios: 4
Total iterations: 0
Strategies learned: 1
"""

import asyncio
from unittest.mock import AsyncMock, call

import pytest

from tta_dev_primitives.core.base import WorkflowContext
from tta_dev_primitives.performance import CachePrimitive

# Cache Hit and Miss Scenarios


@pytest.mark.asyncio
class TestCacheHitMiss:
    """
    Tests for CachePrimitive to validate cache hit/miss behavior.
    """

    async def test_cache_miss_on_first_access(self):
        """
        Validates that the primitive is executed on the first access (cache miss).
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "initial_value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()

        result = await cache.execute({"key": "test_key"}, context)

        assert result == "initial_value"
        mock_primitive.execute.assert_called_once_with({"key": "test_key"}, context)

    async def test_cache_hit_on_second_access(self):
        """
        Validates that the cached value is returned on the second access (cache hit),
        and the primitive is not executed.
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "initial_value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()

        # First access (cache miss)
        result1 = await cache.execute({"key": "test_key"}, context)
        assert result1 == "initial_value"
        mock_primitive.execute.assert_called_once_with({"key": "test_key"}, context)

        # Second access (cache hit)
        result2 = await cache.execute({"key": "test_key"}, context)
        assert result2 == "initial_value"
        mock_primitive.execute.assert_called_once()  # Still only called once

    async def test_multiple_cache_hits_return_same_value(self):
        """
        Validates that multiple cache hits return the same cached value.
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "initial_value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()

        # First access (cache miss)
        result1 = await cache.execute({"key": "test_key"}, context)
        assert result1 == "initial_value"
        mock_primitive.execute.assert_called_once_with({"key": "test_key"}, context)

        # Multiple cache hits
        result2 = await cache.execute({"key": "test_key"}, context)
        result3 = await cache.execute({"key": "test_key"}, context)
        result4 = await cache.execute({"key": "test_key"}, context)

        assert result2 == "initial_value"
        assert result3 == "initial_value"
        assert result4 == "initial_value"
        mock_primitive.execute.assert_called_once()  # Primitive still called only once

    async def test_different_cache_keys_result_in_different_cached_values(self):
        """
        Validates that different cache keys result in different cached values.
        Each key should trigger a primitive execution.
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.side_effect = ["value1", "value2", "value3"]

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()

        result1 = await cache.execute({"key": "key1"}, context)
        assert result1 == "value1"
        assert mock_primitive.execute.call_count == 1

        result2 = await cache.execute({"key": "key2"}, context)
        assert result2 == "value2"
        assert mock_primitive.execute.call_count == 2

        result3 = await cache.execute({"key": "key3"}, context)
        assert result3 == "value3"
        assert mock_primitive.execute.call_count == 3

        mock_primitive.execute.assert_has_calls(
            [
                call({"key": "key1"}, context),
                call({"key": "key2"}, context),
                call({"key": "key3"}, context),
            ]
        )

        # Check cache hits for each key
        result4 = await cache.execute({"key": "key1"}, context)
        assert result4 == "value1"
        assert mock_primitive.execute.call_count == 3

        result5 = await cache.execute({"key": "key2"}, context)
        assert result5 == "value2"
        assert mock_primitive.execute.call_count == 3

        result6 = await cache.execute({"key": "key3"}, context)
        assert result6 == "value3"
        assert mock_primitive.execute.call_count == 3


# TTL Expiration Tests

import pytest


@pytest.mark.asyncio
class TestCacheTTLExpiration:
    """
    Tests for CachePrimitive TTL expiration.
    """

    async def test_cache_return_before_ttl(self):
        """
        Test that cached value is returned before TTL expires.
        """
        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        # First execution
        value1 = await cache.execute(input_data, context)
        assert value1 == "expensive value"
        assert mock_primitive.execute.call_count == 1

        # Second execution (should be cached)
        value2 = await cache.execute(input_data, context)
        assert value2 == "expensive value"
        assert mock_primitive.execute.call_count == 1

    async def test_cache_expires_after_ttl(self):
        """
        Test that cached value expires after TTL seconds.
        """
        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        # First execution
        value1 = await cache.execute(input_data, context)
        assert value1 == "expensive value"
        assert mock_primitive.execute.call_count == 1

        await asyncio.sleep(ttl * 2)  # Wait for TTL to expire

        # Second execution (should re-execute)
        value2 = await cache.execute(input_data, context)
        assert value2 == "expensive value"
        assert mock_primitive.execute.call_count == 2

    async def test_expired_entry_removed(self):
        """
        Test that expired entry is removed from cache (implicitly via re-execution).
        """
        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        await cache.execute(input_data, context)

        # Verify it's in cache (implementation detail check)
        assert "test_key" in cache._cache

        await asyncio.sleep(ttl * 2)  # Wait for TTL to expire

        # Re-execute
        await cache.execute(input_data, context)
        assert "test_key" in cache._cache
        assert mock_primitive.execute.call_count == 2

    async def test_new_execution_after_expiration(self):
        """
        Test that new execution happens after expiration.
        """
        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        await cache.execute(input_data, context)
        assert mock_primitive.execute.call_count == 1

        await asyncio.sleep(ttl * 2)  # Wait for TTL to expire

        await cache.execute(input_data, context)
        assert mock_primitive.execute.call_count == 2

    async def test_statistics_track_expirations(self):
        """
        Test that statistics track expirations correctly.
        """
        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        await cache.execute(input_data, context)
        # Note: expirations are only counted when we try to access an expired key
        # or when a cleanup task runs (if implemented).
        # In the current implementation, it seems to check on access.

        assert cache._stats["hits"] == 0

        await asyncio.sleep(ttl * 2)  # Wait for TTL to expire

        await cache.execute(input_data, context)
        # The implementation might not explicitly count "expirations" in the same way
        # as the mock class did, but let's check if it re-executed.
        assert mock_primitive.execute.call_count == 2

    @pytest.mark.parametrize("ttl_value", [0.1, 0.2])
    async def test_longer_ttl_values(self, ttl_value):
        """Test with longer TTL values."""
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "expensive value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl_value,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        await cache.execute(input_data, context)
        assert mock_primitive.execute.call_count == 1

        await asyncio.sleep(ttl_value / 2)
        await cache.execute(input_data, context)
        assert mock_primitive.execute.call_count == 1

        await asyncio.sleep(ttl_value)
        await cache.execute(input_data, context)
        assert mock_primitive.execute.call_count == 2


# Statistics Tracking Tests
import pytest


@pytest.mark.asyncio
class TestCacheStatistics:
    """
    Tests for CachePrimitive statistics.
    """

    async def test_stats_structure(self):
        """
        Test that _stats has the correct structure.
        """
        mock_primitive = AsyncMock()
        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )

        assert isinstance(cache._stats, dict)
        assert "hits" in cache._stats
        assert "misses" in cache._stats
        assert "expirations" in cache._stats

    async def test_hit_count_increments(self):
        """
        Test that the hit count increments on cache hits.
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        # Miss
        await cache.execute(input_data, context)

        # Hits
        await cache.execute(input_data, context)
        await cache.execute(input_data, context)
        await cache.execute(input_data, context)

        assert cache._stats["hits"] == 3

    async def test_miss_count_increments(self):
        """
        Test that the miss count increments on cache misses.
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()

        await cache.execute({"key": "key1"}, context)
        await cache.execute({"key": "key2"}, context)

        assert cache._stats["misses"] == 2

    async def test_expiration_count_increments(self):
        """
        Test that the expiration count increments when entries expire.
        """
        # Note: The current implementation of CachePrimitive doesn't explicitly count expirations
        # in the _stats dict in the same way the mock did (it might, let's check implementation).
        # Checking implementation:
        # if age < self.ttl_seconds: ... else: del self._cache[cache_key]; self._stats["expirations"] += 1
        # So it DOES count expirations.

        ttl = 0.1
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "value"

        cache = CachePrimitive(
            primitive=mock_primitive,
            cache_key_fn=lambda d, c: d["key"],
            ttl_seconds=ttl,
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        await cache.execute(input_data, context)

        await asyncio.sleep(ttl * 2)

        # Trigger expiration
        await cache.execute(input_data, context)

        assert cache._stats["expirations"] == 1

    async def test_hit_rate_calculation(self):
        """
        Test hit rate calculation (manual calculation since get_stats is not in real class).
        """
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = "value"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )
        context = WorkflowContext()
        input_data = {"key": "test_key"}

        # Miss
        await cache.execute(input_data, context)
        # Hit
        await cache.execute(input_data, context)

        hits = cache._stats["hits"]
        misses = cache._stats["misses"]
        total = hits + misses
        hit_rate = (hits / total) * 100 if total > 0 else 0.0

        assert hits == 1
        assert misses == 1
        assert hit_rate == 50.0


# Edge Cases and Error Handling
import logging

import pytest

logging.basicConfig(level=logging.INFO)


# Edge Cases and Error Handling
import logging

import pytest

logging.basicConfig(level=logging.INFO)


@pytest.mark.asyncio
class TestCacheEdgeCases:
    async def test_empty_cache_stats(self):
        mock_primitive = AsyncMock()
        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: d["key"]
        )

        assert cache._stats["hits"] == 0
        assert cache._stats["misses"] == 0
        assert cache._stats["expirations"] == 0

    async def test_cache_key_function_various_types(self):
        mock_primitive = AsyncMock()
        mock_primitive.execute.side_effect = lambda d, c: f"value_{d['val']}"

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: str(d["val"])
        )
        context = WorkflowContext()

        # Dict input (converted to str by key_fn)
        await cache.execute({"val": {"a": 1}}, context)

        # String input
        await cache.execute({"val": "test_string"}, context)

        # Int input
        await cache.execute({"val": 123}, context)

        assert mock_primitive.execute.call_count == 3
        assert cache._stats["misses"] == 3

        # Hits
        await cache.execute({"val": {"a": 1}}, context)
        await cache.execute({"val": "test_string"}, context)
        await cache.execute({"val": 123}, context)

        assert cache._stats["hits"] == 3

    async def test_cache_none_input(self):
        # The real CachePrimitive stores whatever the primitive returns
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = None

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: "none_key"
        )
        context = WorkflowContext()

        val1 = await cache.execute({}, context)
        assert val1 is None

        val2 = await cache.execute({}, context)
        assert val2 is None
        assert cache._stats["hits"] == 1

    async def test_cache_empty_dict_input(self):
        mock_primitive = AsyncMock()
        mock_primitive.execute.return_value = {}

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: "empty_dict_key"
        )
        context = WorkflowContext()

        val1 = await cache.execute({}, context)
        assert val1 == {}

        val2 = await cache.execute({}, context)
        assert val2 == {}
        assert cache._stats["hits"] == 1

    async def test_concurrent_access(self):
        # The real CachePrimitive does not currently implement request coalescing (thundering herd protection)
        # So concurrent requests for the same missing key will both execute the primitive.

        mock_primitive = AsyncMock()

        # Simulate slow execution
        async def slow_execute(data, context):
            await asyncio.sleep(0.05)
            return "value"

        mock_primitive.execute.side_effect = slow_execute

        cache = CachePrimitive(
            primitive=mock_primitive, cache_key_fn=lambda d, c: "concurrent_key"
        )
        context = WorkflowContext()

        # Launch 5 concurrent requests
        tasks = [cache.execute({}, context) for _ in range(5)]
        results = await asyncio.gather(*tasks)

        for res in results:
            assert res == "value"

        # Since there is no locking/coalescing, we expect multiple executions
        # But subsequent requests should hit the cache

        await cache.execute({}, context)
        assert cache._stats["hits"] >= 1
