{"pattern": "sequential_workflow", "antipattern": "async def process_data(data: dict) -> dict:\n    step1_result = await process_step1(data)\n    step2_result = await process_step2(step1_result)\n    step3_result = await process_step3(step2_result)\n    return step3_result", "correct": "from tta_dev_primitives import WorkflowContext\n\n# Define the workflow\nworkflow = process_step1 >> process_step2 >> process_step3\n\n# Execute with context\ncontext = WorkflowContext(correlation_id=\"req-123\")\nresult = await workflow.execute(data, context)", "explanation": "Use SequentialPrimitive (>>) instead of manual async chaining. Benefits: automatic tracing, composition, error handling.", "severity": "error", "rule": "TTA001"}
{"pattern": "parallel_execution", "antipattern": "import asyncio\n\nasync def fetch_all(inputs: list) -> list:\n    results = await asyncio.gather(\n        fetch_api1(inputs[0]),\n        fetch_api2(inputs[1]),\n        fetch_api3(inputs[2])\n    )\n    return results", "correct": "from tta_dev_primitives import ParallelPrimitive, WorkflowContext\n\n# Define parallel workflow\nworkflow = fetch_api1 | fetch_api2 | fetch_api3\n\n# Execute concurrently\ncontext = WorkflowContext()\nresults = await workflow.execute(inputs, context)", "explanation": "Use ParallelPrimitive (|) or asyncio.gather(). Benefits: automatic tracing, error handling, composability.", "severity": "error", "rule": "TTA001"}
{"pattern": "retry_logic", "antipattern": "async def call_api_with_retry(data: dict, max_retries: int = 3) -> dict:\n    for attempt in range(max_retries):\n        try:\n            return await api_call(data)\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            await asyncio.sleep(2 ** attempt)", "correct": "from tta_dev_primitives.recovery import RetryPrimitive\n\n# Create retry workflow\nreliable_api = RetryPrimitive(\n    primitive=api_call,\n    max_retries=3,\n    backoff_strategy=\"exponential\",\n    initial_delay=1.0\n)\n\nresult = await reliable_api.execute(data, context)", "explanation": "Use RetryPrimitive instead of manual retry loops. Benefits: configurable strategies, jitter, observability.", "severity": "error", "rule": "TTA003"}
{"pattern": "timeout_handling", "antipattern": "import asyncio\n\nasync def api_with_timeout(data: dict) -> dict:\n    try:\n        return await asyncio.wait_for(slow_api(data), timeout=30)\n    except asyncio.TimeoutError:\n        raise Exception(\"API call timed out\")", "correct": "from tta_dev_primitives.recovery import TimeoutPrimitive\n\n# Add timeout protection\ntimed_api = TimeoutPrimitive(\n    primitive=slow_api,\n    timeout_seconds=30.0,\n    raise_on_timeout=True\n)\n\nresult = await timed_api.execute(data, context)", "explanation": "Use TimeoutPrimitive instead of asyncio.wait_for(). Benefits: circuit breaker pattern, metrics, composition.", "severity": "error", "rule": "TTA004"}
{"pattern": "caching", "antipattern": "cache = {}\n\nasync def expensive_operation(key: str) -> dict:\n    if key in cache:\n        return cache[key]\n    result = await llm_call(key)\n    cache[key] = result\n    return result", "correct": "from tta_dev_primitives.performance import CachePrimitive\n\n# Add intelligent caching\ncached_llm = CachePrimitive(\n    primitive=llm_call,\n    ttl_seconds=3600,\n    max_size=1000,\n    key_fn=lambda data, ctx: data.get(\"prompt\")\n)\n\nresult = await cached_llm.execute(data, context)", "explanation": "Use CachePrimitive instead of manual dictionaries. Benefits: LRU eviction, TTL, thread-safety, metrics.", "severity": "warning", "rule": "TTA005"}
{"pattern": "fallback_logic", "antipattern": "async def api_with_fallback(data: dict) -> dict:\n    try:\n        return await primary_api(data)\n    except Exception:\n        try:\n            return await backup_api(data)\n        except Exception:\n            return await final_fallback(data)", "correct": "from tta_dev_primitives.recovery import FallbackPrimitive\n\n# Graceful degradation\nresilient_api = FallbackPrimitive(\n    primary=primary_api,\n    fallbacks=[backup_api, final_fallback]\n)\n\nresult = await resilient_api.execute(data, context)", "explanation": "Use FallbackPrimitive for cascading fallbacks. Benefits: automatic failover, metrics, composability.", "severity": "error", "rule": "TTA001"}
{"pattern": "workflow_context", "antipattern": "# Missing context - no tracing\nresult = await my_primitive.execute(data)", "correct": "from tta_dev_primitives import WorkflowContext\n\n# Always pass context for tracing\ncontext = WorkflowContext(\n    correlation_id=\"req-123\",\n    data={\"user_id\": \"user-789\"}\n)\nresult = await my_primitive.execute(data, context)", "explanation": "Always pass WorkflowContext to execute(). Benefits: distributed tracing, correlation IDs, metrics.", "severity": "error", "rule": "TTA002"}
{"pattern": "custom_primitive", "antipattern": "class MyProcessor:\n    async def process(self, data: dict) -> dict:\n        # Custom logic\n        return processed_data", "correct": "from tta_dev_primitives import WorkflowPrimitive, WorkflowContext\n\nclass MyProcessor(WorkflowPrimitive[dict, dict]):\n    async def _execute_impl(\n        self,\n        context: WorkflowContext,\n        input_data: dict\n    ) -> dict:\n        # Custom logic with automatic observability\n        return processed_data", "explanation": "Extend WorkflowPrimitive for custom operations. Benefits: composition, observability, type safety.", "severity": "warning", "rule": "TTA001"}
{"pattern": "production_stack", "antipattern": "# No error handling, caching, or observability\nasync def production_workflow(data: dict) -> dict:\n    result = await llm_call(data)\n    return result", "correct": "from tta_dev_primitives import WorkflowContext\nfrom tta_dev_primitives.recovery import RetryPrimitive, FallbackPrimitive, TimeoutPrimitive\nfrom tta_dev_primitives.performance import CachePrimitive\n\n# Production-ready with all safeguards\nworkflow = (\n    CachePrimitive(llm_call, ttl_seconds=3600) >>\n    TimeoutPrimitive(timeout_seconds=30) >>\n    RetryPrimitive(max_retries=3, backoff_strategy=\"exponential\") >>\n    FallbackPrimitive(fallbacks=[backup_llm])\n)\n\ncontext = WorkflowContext(correlation_id=\"prod-req\")\nresult = await workflow.execute(data, context)", "explanation": "Layer primitives for production: Cache -> Timeout -> Retry -> Fallback. Reduces costs 40-60%, ensures reliability.", "severity": "error", "rule": "TTA001"}
{"pattern": "routing", "antipattern": "async def select_model(data: dict) -> dict:\n    if len(data[\"prompt\"]) < 100:\n        return await fast_llm(data)\n    else:\n        return await quality_llm(data)", "correct": "from tta_dev_primitives.core import RouterPrimitive\n\n# Dynamic routing based on logic\nrouter = RouterPrimitive(\n    routes={\n        \"fast\": fast_llm,\n        \"quality\": quality_llm\n    },\n    router_fn=lambda d, c: \"fast\" if len(d.get(\"prompt\", \"\")) < 100 else \"quality\",\n    default=\"fast\"\n)\n\nresult = await router.execute(data, context)", "explanation": "Use RouterPrimitive for conditional routing. Benefits: cost optimization, dynamic selection, metrics.", "severity": "warning", "rule": "TTA001"}
