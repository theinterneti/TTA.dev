File,Line,Category,Type,TODO Text,Context
packages/tta-dev-primitives/README.md,5,other,md,"**Note**: These are development tools for building TTA, not player-facing game components.","Production-ready development primitives for building TTA agents and workflows. This package provides composable patterns, recovery strategies, performance utilities, and observability tools for development automation. |  | **Note**: These are development tools for building TTA, not player-facing game components. |  | ## Features"
packages/tta-dev-primitives/apm.yml,11,config,yml,"NOTE: This is for development tooling, not player-facing game components.","  utilities, and observability tools for development automation. |    |   NOTE: This is for development tooling, not player-facing game components. |  | author: TTA Development Team"
packages/tta-dev-primitives/CURSOR_AGENT.md,32,other,md,"- Never print code blocks with ""TODO"" or placeholder comments"," | ### For Code Changes | - Never print code blocks with ""TODO"" or placeholder comments | - Use edit tools instead of showing full file dumps | - Reference specific line numbers when discussing existing code"
packages/tta-dev-primitives/CURSOR_AGENT.md,199,other,md,# TODO: Add tests later,"âŒ **BAD**: | ```python | # TODO: Add tests later | class NewFeature(WorkflowPrimitive[dict, dict]): |     ..."
packages/tta-dev-primitives/CLINE_AGENT.md,32,other,md,"- Never print code blocks with ""TODO"" or placeholder comments"," | ### For Code Changes | - Never print code blocks with ""TODO"" or placeholder comments | - Use edit tools instead of showing full file dumps | - Reference specific line numbers when discussing existing code"
packages/tta-dev-primitives/CLINE_AGENT.md,199,other,md,# TODO: Add tests later,"âŒ **BAD**: | ```python | # TODO: Add tests later | class NewFeature(WorkflowPrimitive[dict, dict]): |     ..."
packages/tta-dev-primitives/AUGMENT_AGENT.md,32,other,md,"- Never print code blocks with ""TODO"" or placeholder comments"," | ### For Code Changes | - Never print code blocks with ""TODO"" or placeholder comments | - Use edit tools instead of showing full file dumps | - Reference specific line numbers when discussing existing code"
packages/tta-dev-primitives/AUGMENT_AGENT.md,199,other,md,# TODO: Add tests later,"âŒ **BAD**: | ```python | # TODO: Add tests later | class NewFeature(WorkflowPrimitive[dict, dict]): |     ..."
packages/tta-dev-primitives/AGENTS.md,32,other,md,"- Never print code blocks with ""TODO"" or placeholder comments"," | ### For Code Changes | - Never print code blocks with ""TODO"" or placeholder comments | - Use edit tools instead of showing full file dumps | - Reference specific line numbers when discussing existing code"
packages/tta-dev-primitives/AGENTS.md,199,other,md,# TODO: Add tests later,"âŒ **BAD**: | ```python | # TODO: Add tests later | class NewFeature(WorkflowPrimitive[dict, dict]): |     ..."
packages/tta-dev-primitives/IMPROVEMENTS_QUICK_START.md,378,other,md,"logger.debug(""cache_expired"", key=cache_key, age=age)","                return result |             else: |                 logger.debug(""cache_expired"", key=cache_key, age=age) |                 del self._cache[cache_key] | "
packages/tta-dev-primitives/IMPROVEMENTS_QUICK_START.md,386,other,md,"logger.debug(""cache_store"", key=cache_key, cache_size=len(self._cache))"," |         self._cache[cache_key] = (result, time.time()) |         logger.debug(""cache_store"", key=cache_key, cache_size=len(self._cache)) |  |         return result"
packages/tta-dev-primitives/.cline/rules/documentation.instructions.md,225,other,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
packages/tta-dev-primitives/examples/e2b_iterative_code_refinement.py,9,non-actionable,py,- Logic bugs,- Syntax errors | - Import errors | - Logic bugs | - Edge cases not handled | 
packages/tta-dev-primitives/examples/PR_REVIEW_GUIDE.md,342,non-actionable,md,**Debug:**,"### Issue: ""Quality validation fails"" |  | **Debug:** | ```python | # Enable debug logging"
packages/tta-dev-primitives/examples/PR_REVIEW_GUIDE.md,344,non-actionable,md,# Enable debug logging,**Debug:** | ```python | # Enable debug logging | import logging | logging.basicConfig(level=logging.DEBUG)
packages/tta-dev-primitives/examples/PR_REVIEW_GUIDE.md,346,non-actionable,md,logging.basicConfig(level=logging.DEBUG),# Enable debug logging | import logging | logging.basicConfig(level=logging.DEBUG) |  | # Run workflow
packages/tta-dev-primitives/examples/e2b_advanced_iterative_refinement.py,172,non-actionable,py,"print(""ðŸ’­ Fixed previous issue, but might have logic bug..."")","            # Second attempt: Fix previous error but introduce new one |             print(f""ðŸ“ Learning from error: {previous_errors}"") |             print(""ðŸ’­ Fixed previous issue, but might have logic bug..."") |             code = """""" | # Calculate fibonacci sequence (fixed imports)"
packages/tta-dev-primitives/examples/EXAMPLES_API_DRIFT.md,56,non-actionable,md,See GitHub issue: [TODO: Create issue],"## Tracking |  | See GitHub issue: [TODO: Create issue] |  | Last updated: November 5, 2025"
packages/tta-dev-primitives/examples/memory_workflow.py,74,non-actionable,py,"""assistant_response"": ""Why did the programmer quit? Too much debugging!"",","        ""timestamp"": datetime.now().isoformat(), |         ""user_message"": ""Tell me a joke"", |         ""assistant_response"": ""Why did the programmer quit? Too much debugging!"", |         ""intent"": ""entertainment"", |     }"
packages/tta-dev-primitives/examples/memory_workflow.py,131,non-actionable,py,"print(""âš ï¸  Note: In-memory mode does not persist across restarts"")"," |     # Demonstrate persistence (in-memory loses data on restart) |     print(""âš ï¸  Note: In-memory mode does not persist across restarts"") |     print(""   To add persistence, use Redis (optional):"") |     print(""   memory = MemoryPrimitive(redis_url='redis://localhost:6379')"")"
packages/tta-dev-primitives/examples/stage_kb_workflow.py,35,non-actionable,py,# Note: LogSeq MCP is only available in VS Code with MCP configured,"    print(""="" * 70) |  |     # Note: LogSeq MCP is only available in VS Code with MCP configured |     # This example shows graceful degradation when unavailable |     kb = KnowledgeBasePrimitive(logseq_available=False)"
packages/tta-dev-primitives/examples/stage_kb_workflow.py,100,non-actionable,py,"print(""   Note: When LogSeq MCP is available, results will include actual pages"")"," |     print(""\nâœ… KB queries completed successfully"") |     print(""   Note: When LogSeq MCP is available, results will include actual pages"") |  | "
packages/tta-dev-primitives/examples/DOC_GENERATION_GUIDE.md,309,non-actionable,md,"""Security Notes"",","            ""Examples"", |             ""Performance Considerations"", |             ""Security Notes"", |             ""Best Practices"", |         ],"
packages/tta-dev-primitives/examples/DOC_GENERATION_GUIDE.md,367,non-actionable,md,**Debug:**,"### Issue: ""Missing Logseq properties"" |  | **Debug:** | ```python | # Check generated content"
packages/tta-dev-primitives/examples/orchestration_test_generation_with_e2b.py,139,non-actionable,py,"""    # TODO: Add actual test implementation"",","                    f""def test_{func_name}_basic():"", |                     f'    """"""Test {func_name} with basic input.""""""', |                     ""    # TODO: Add actual test implementation"", |                     f""    result = {func_name}()"", |                     ""    assert result is not None"","
packages/tta-dev-primitives/src/tta_dev_primitives/knowledge/knowledge_base.py,162,code,py,# TODO: Call LogSeq MCP search tool when available,"            search_tags.append(f""stage-{query.stage}"") |  |         # TODO: Call LogSeq MCP search tool when available |         # For now, return empty list (MCP integration in future PR) |         return []"
packages/tta-dev-primitives/src/tta_dev_primitives/knowledge/knowledge_base.py,184,code,py,# TODO: Call LogSeq MCP search tool,"            search_tags.append(f""stage-{query.stage}"") |  |         # TODO: Call LogSeq MCP search tool |         return [] | "
packages/tta-dev-primitives/src/tta_dev_primitives/knowledge/knowledge_base.py,199,code,py,"# TODO: Call LogSeq MCP search tool with tags [""examples"", query.topic]","            List of matching KB pages |         """""" |         # TODO: Call LogSeq MCP search tool with tags [""examples"", query.topic] |         return [] | "
packages/tta-dev-primitives/src/tta_dev_primitives/knowledge/knowledge_base.py,214,code,py,# TODO: Call LogSeq MCP get related pages tool,"            List of related KB pages |         """""" |         # TODO: Call LogSeq MCP get related pages tool |         return [] | "
packages/tta-dev-primitives/src/tta_dev_primitives/knowledge/knowledge_base.py,227,code,py,# TODO: Call LogSeq MCP search by tags tool,"            List of matching KB pages |         """""" |         # TODO: Call LogSeq MCP search by tags tool |         return [] | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/README.md,386,other,md,## Notes,{{query (and [[Strategies]] [[my_service]])}} |  | ## Notes |  | Learned during high-load production scenario.
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/README.md,496,other,md,Rich logging for debugging:,### Structured Logging |  | Rich logging for debugging: |  | ```python
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/README.md,665,other,md,notes: str | None = None,"        primitive_type: str, |         context: str, |         notes: str | None = None |     ) -> Path | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/cache.py,195,code,py,logger.debug(,"                # Expired - remove from cache |                 del self._cache[cache_key] |                 logger.debug( |                     ""adaptive_cache_expired"", |                     cache_key=cache_key[:50],"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/cache.py,225,code,py,"logger.debug(""adaptive_cache_eviction"", evicted_key=oldest_key[:50])","            oldest_key = min(self._cache.items(), key=lambda x: x[1][1])[0] |             del self._cache[oldest_key] |             logger.debug(""adaptive_cache_eviction"", evicted_key=oldest_key[:50]) |  |         self._cache[cache_key] = (result, time.time(), context_key)"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,42,code,py,"logger.debug(f""Created Logseq page: {page_path}"")","    # Write content |     page_path.write_text(content, encoding=""utf-8"") |     logger.debug(f""Created Logseq page: {page_path}"") |  | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,63,code,py,"logger.debug(f""Added entry to Logseq journal: {journal_path}"")","    with journal_path.open(""a"", encoding=""utf-8"") as f: |         f.write(f""\n{entry}\n"") |     logger.debug(f""Added entry to Logseq journal: {journal_path}"") |  | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,92,code,py,"notes: str | None = None,","        primitive_type: str, |         context: str, |         notes: str | None = None, |     ) -> None: |         """""""
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,103,code,py,notes: Optional additional notes about the learning event.,"            primitive_type: The type of the primitive (e.g., ""AdaptiveRetryPrimitive""). |             context: The context in which the strategy was learned. |             notes: Optional additional notes about the learning event. |         """""" |         page_title = f""{self.service_name}_{strategy.name}"""
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,110,code,py,"notes=notes,","            primitive_type=primitive_type, |             context=context, |             notes=notes, |             service_name=self.service_name, |         )"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,123,code,py,"notes=notes,","                primitive_type=primitive_type, |                 context=context, |                 notes=notes, |                 event_type=""Strategy Learned"", |             )"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,138,code,py,"notes: str | None = None,","        primitive_type: str, |         context: str, |         notes: str | None = None, |     ) -> None: |         """""""
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,148,code,py,notes: Optional notes for the update.,"            primitive_type: The type of the primitive. |             context: The context of the strategy. |             notes: Optional notes for the update. |         """""" |         # In a real implementation, this would involve reading the existing page,"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,159,code,py,"notes=notes,","            primitive_type=primitive_type, |             context=context, |             notes=notes, |             event_type=""Strategy Performance Updated"", |             metrics=new_metrics,"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,174,code,py,"notes: str | None,","        primitive_type: str, |         context: str, |         notes: str | None, |         service_name: str, |     ) -> str:"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,208,code,py,## Notes,"{related_strategies_query} |  | ## Notes | {notes if notes else ""No additional notes.""} | """""""
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,209,code,py,"{notes if notes else ""No additional notes.""}"," | ## Notes | {notes if notes else ""No additional notes.""} | """""" |         return content"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,218,code,py,"notes: str | None,","        primitive_type: str, |         context: str, |         notes: str | None, |         event_type: str, |         metrics: StrategyMetrics | None = None,"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,225,code,py,if notes:,"        timestamp = datetime.now().strftime(""%Y-%m-%d %H:%M:%S"") |         entry = f""- **{event_type}** for **{strategy_name}** ({primitive_type} in context '{context}') at {timestamp}\n"" |         if notes: |             entry += f""  - Notes: {notes}\n"" |         if metrics:"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,226,code,py,"entry += f""  - Notes: {notes}\n""","        entry = f""- **{event_type}** for **{strategy_name}** ({primitive_type} in context '{context}') at {timestamp}\n"" |         if notes: |             entry += f""  - Notes: {notes}\n"" |         if metrics: |             entry += f""  - Metrics: Success Rate={metrics.success_rate:.1%}, Avg Latency={metrics.avg_latency_ms:.1f}ms, Observations={metrics.contexts_seen}\n"""
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,263,code,py,"notes=""Initial test strategy."",","        primitive_type=""AdaptivePrimitive"", |         context=""development"", |         notes=""Initial test strategy."", |     ) | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/logseq_integration.py,272,code,py,"notes=""Performance improved."",","        primitive_type=""AdaptivePrimitive"", |         context=""development"", |         notes=""Performance improved."", |     ) | "
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/fallback.py,407,code,py,"notes=f""Fallback success rates: {fallback_success_rates}\nOptimal order: {optimal_order}"",","                    primitive_type=""AdaptiveFallbackPrimitive"", |                     context=context_key, |                     notes=f""Fallback success rates: {fallback_success_rates}\nOptimal order: {optimal_order}"", |                 ) |             except Exception as e:"
packages/tta-dev-primitives/src/tta_dev_primitives/adaptive/base.py,398,code,py,"logger.debug(f""Considered strategy adaptation for {current_strategy.name}"")","        # Base implementation is conservative - just track that we considered it |  |         logger.debug(f""Considered strategy adaptation for {current_strategy.name}"") |  |     def get_learning_summary(self) -> dict[str, Any]:"
packages/tta-dev-primitives/src/tta_dev_primitives/benchmarking/__init__.py,7,code,py,"2. Developer Productivity: Development time, bugs introduced, test coverage"," | 1. Code Elegance: Lines of code, complexity, maintainability | 2. Developer Productivity: Development time, bugs introduced, test coverage | 3. Cost Effectiveness: API costs, development costs, maintenance costs | 4. AI Agent Performance: Task completion rates, context understanding"
packages/tta-dev-primitives/src/tta_dev_primitives/lifecycle/stages.py,79,code,py,"""Update CHANGELOG with release notes"",","    recommended_actions=[ |         ""Add LICENSE file (MIT or Apache 2.0 recommended)"", |         ""Update CHANGELOG with release notes"", |         ""Bump version in pyproject.toml"", |         ""Scan for secrets in code"","
packages/tta-dev-primitives/src/tta_dev_primitives/lifecycle/README.md,319,other,md,- Update CHANGELOG with release notes,**Recommended Actions:** | - Add LICENSE file | - Update CHANGELOG with release notes | - Bump version in package manifest | - Scan for secrets in code
packages/tta-dev-primitives/src/tta_dev_primitives/lifecycle/README.md,376,other,md,â€¢ Update CHANGELOG with release notes,ðŸ’¡ RECOMMENDED ACTIONS: |   â€¢ Add LICENSE file (MIT or Apache 2.0 recommended) |   â€¢ Update CHANGELOG with release notes |   â€¢ Bump version in pyproject.toml |   â€¢ Scan for secrets in code
packages/tta-dev-primitives/src/tta_dev_primitives/apm/setup.py,40,code,py,enable_console: Enable console export (for debugging),        service_version: Version of the service |         enable_prometheus: Enable Prometheus metrics export |         enable_console: Enable console export (for debugging) |         prometheus_port: Port for Prometheus metrics endpoint | 
packages/tta-dev-primitives/src/tta_dev_primitives/apm/setup.py,76,code,py,# Add console exporter for debugging, |     if enable_console: |         # Add console exporter for debugging |         console_processor = BatchSpanProcessor(ConsoleSpanExporter()) |         _tracer_provider.add_span_processor(console_processor)
packages/tta-dev-primitives/src/tta_dev_primitives/observability/context_propagation.py,152,code,py,"logger.debug(""Baggage propagation not available"")","            set_baggage(key, value) |     except ImportError: |         logger.debug(""Baggage propagation not available"") |  | "
packages/tta-dev-primitives/src/tta_dev_primitives/observability/context_propagation.py,174,code,py,"logger.debug(""Baggage extraction not available"")","            context.baggage.update(baggage) |     except ImportError: |         logger.debug(""Baggage extraction not available"") | "
packages/tta-dev-primitives/src/tta_dev_primitives/observability/logging.py,22,code,py,"level: Log level (DEBUG, INFO, WARNING, ERROR)"," |     Args: |         level: Log level (DEBUG, INFO, WARNING, ERROR) |     """""" |     if STRUCTLOG_AVAILABLE:"
packages/tta-dev-primitives/src/tta_dev_primitives/ace/cognitive_manager.py,174,code,py,- Debugging techniques that resolve issues,    - Library/import patterns for different tasks |     - Code structure approaches that succeed |     - Debugging techniques that resolve issues |  |     Attributes:
packages/tta-dev-primitives/src/tta_dev_primitives/performance/cache.py,115,code,py,logger.debug(,"                # Cache expired |                 self._stats[""expirations""] += 1 |                 logger.debug( |                     ""cache_expired"", |                     key=cache_key[:50],"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/cache.py,145,code,py,logger.debug(,"        self._cache[cache_key] = (result, time.time()) |  |         logger.debug( |             ""cache_store"", |             key=cache_key[:50],"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,57,code,py,"logger.debug(f""Updated memory: {key}"")","        if key in self.store: |             self.store.move_to_end(key) |             logger.debug(f""Updated memory: {key}"") |         else: |             logger.debug(f""Added memory: {key}"")"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,59,code,py,"logger.debug(f""Added memory: {key}"")","            logger.debug(f""Updated memory: {key}"") |         else: |             logger.debug(f""Added memory: {key}"") |  |         self.store[key] = value"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,67,code,py,"logger.debug(f""Evicted LRU memory: {evicted_key}"")","            evicted_key = next(iter(self.store)) |             self.store.popitem(last=False) |             logger.debug(f""Evicted LRU memory: {evicted_key}"") |  |     def get(self, key: str) -> dict[str, Any] | None:"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,82,code,py,"logger.debug(f""Retrieved memory: {key}"")","        if key in self.store: |             self.store.move_to_end(key) |             logger.debug(f""Retrieved memory: {key}"") |             return self.store[key] | "
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,85,code,py,"logger.debug(f""Memory not found: {key}"")","            return self.store[key] |  |         logger.debug(f""Memory not found: {key}"") |         return None | "
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,117,code,py,"logger.debug(f""Search '{query}' found {len(results)} results"")","                    break |  |         logger.debug(f""Search '{query}' found {len(results)} results"") |         return results | "
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,243,code,py,"logger.debug(f""Stored in Redis: {key}"")","                else: |                     self.redis_client.set(key, value_str) |                 logger.debug(f""Stored in Redis: {key}"") |                 return |             except Exception as e:"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,265,code,py,"logger.debug(f""Retrieved from Redis: {key}"")","                value_str = self.redis_client.get(key)  # type: ignore |                 if value_str: |                     logger.debug(f""Retrieved from Redis: {key}"") |                     return json.loads(str(value_str)) |                 return None"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,285,code,py,Note:,            List of matching memories |  |         Note: |             - In-memory: Simple keyword matching |             - Redis: Could use RediSearch for semantic search (future enhancement)
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,293,code,py,"logger.debug(""Search using in-memory (Redis search not implemented)"")","                # For now, just use fallback search (Redis search needs RediSearch module) |                 # Future: Implement semantic search with RediSearch |                 logger.debug(""Search using in-memory (Redis search not implemented)"") |             except Exception as e: |                 logger.warning(f""Redis search failed: {e}. Using in-memory."")"
packages/tta-dev-primitives/src/tta_dev_primitives/performance/memory.py,305,code,py,# Note: This would clear ALL keys in Redis DB,"        if self.using_redis and self.redis_client: |             try: |                 # Note: This would clear ALL keys in Redis DB |                 # In production, you'd want namespacing |                 logger.warning(""Redis clear not implemented (would clear entire DB)"")"
packages/tta-dev-primitives/src/tta_dev_primitives/orchestration/task_classifier_primitive.py,154,code,py,"code_keywords = [""code"", ""function"", ""class"", ""debug"", ""implement"", ""refactor""]","        ] |         creativity_keywords = [""create"", ""write"", ""generate"", ""design"", ""brainstorm""] |         code_keywords = [""code"", ""function"", ""class"", ""debug"", ""implement"", ""refactor""] |         speed_keywords = [""quick"", ""fast"", ""immediately"", ""urgent"", ""real-time""] |         long_context_keywords = [""document"", ""article"", ""book"", ""long"", ""entire""]"
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,72,code,py,notes: str | None = Field(,"        description=""Date when information was last verified"", |     ) |     notes: str | None = Field( |         default=None, description=""Additional notes or common confusion points"" |     )"
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,73,code,py,"default=None, description=""Additional notes or common confusion points""","    ) |     notes: str | None = Field( |         default=None, description=""Additional notes or common confusion points"" |     ) |     # NEW: Quality metrics for models"
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,144,code,py,Note:,"        ``` |  |     Note: |         This primitive uses hardcoded provider information as of October 2025. |         For production use, integrate with web scraping tools or provider APIs"
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,165,code,py,"notes=""Web UI (ChatGPT) is free forever, but API requires payment after $5 credit"",","                setup_url=""https://platform.openai.com/signup"", |                 pricing_url=""https://openai.com/api/pricing/"", |                 notes=""Web UI (ChatGPT) is free forever, but API requires payment after $5 credit"", |                 models=[ |                     ModelQualityMetrics("
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,211,code,py,"notes=""Web UI (claude.ai) is free with limits, but API has no free tier"",","                setup_url=""https://console.anthropic.com/"", |                 pricing_url=""https://www.anthropic.com/pricing"", |                 notes=""Web UI (claude.ai) is free with limits, but API has no free tier"", |                 models=[ |                     ModelQualityMetrics("
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,257,code,py,"notes=""Google AI Studio is free, Vertex AI is paid. Don't confuse them!"",","                setup_url=""https://aistudio.google.com/"", |                 pricing_url=""https://ai.google.dev/pricing"", |                 notes=""Google AI Studio is free, Vertex AI is paid. Don't confuse them!"", |                 models=[ |                     ModelQualityMetrics("
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,303,code,py,"notes=""BYOK = Bring Your Own Key. You use your own provider API keys."",","                setup_url=""https://openrouter.ai/"", |                 pricing_url=""https://openrouter.ai/docs#limits"", |                 notes=""BYOK = Bring Your Own Key. You use your own provider API keys."", |                 models=[ |                     # OpenRouter provides access to many models - listing top free options"
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,334,code,py,"notes=""100% free, runs on your machine. Requires GPU for good performance."",","                setup_url=""https://ollama.com/"", |                 pricing_url=None, |                 notes=""100% free, runs on your machine. Requires GPU for good performance."", |                 models=[ |                     ModelQualityMetrics("
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,407,code,py,"notes=f""Provider '{provider}' not found in database"",","                    name=provider, |                     has_free_tier=False, |                     notes=f""Provider '{provider}' not found in database"", |                 ) | "
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,633,code,py,"""Google Gemini"": ""GoogleGeminiPrimitive"",  # Note: Not yet implemented","            ""OpenAI API"": ""OpenAIPrimitive"", |             ""Anthropic Claude API"": ""AnthropicPrimitive"", |             ""Google Gemini"": ""GoogleGeminiPrimitive"",  # Note: Not yet implemented |             ""OpenRouter BYOK"": ""OpenRouterPrimitive"",  # Note: Not yet implemented |             ""Ollama"": ""OllamaPrimitive"","
packages/tta-dev-primitives/src/tta_dev_primitives/research/free_tier_research.py,634,code,py,"""OpenRouter BYOK"": ""OpenRouterPrimitive"",  # Note: Not yet implemented","            ""Anthropic Claude API"": ""AnthropicPrimitive"", |             ""Google Gemini"": ""GoogleGeminiPrimitive"",  # Note: Not yet implemented |             ""OpenRouter BYOK"": ""OpenRouterPrimitive"",  # Note: Not yet implemented |             ""Ollama"": ""OllamaPrimitive"", |         }"
packages/tta-dev-primitives/src/tta_dev_primitives/integrations/supabase_primitive.py,73,code,py,"url: Supabase project URL (e.g., https://xxx.supabase.co)"," |         Args: |             url: Supabase project URL (e.g., https://xxx.supabase.co) |             key: Supabase API key (anon or service role key) |             **kwargs: Additional arguments passed to create_client"
packages/tta-dev-primitives/src/tta_dev_primitives/integrations/e2b_primitive.py,157,code,py,# Note: language parameter reserved for future multi-language support,"        env_vars = input_data.get(""env_vars"", {}) |  |         # Note: language parameter reserved for future multi-language support |         # Currently E2B Code Interpreter defaults to Python | "
packages/tta-dev-primitives/src/tta_dev_primitives/integrations/e2b_primitive.py,171,code,py,# Note: E2B SDK doesn't support custom env vars in run_code yet," |         try: |             # Note: E2B SDK doesn't support custom env vars in run_code yet |             # Environment variables would need to be set via sandbox.run_code(""export VAR=value"") |             if env_vars and self._sandbox:"
packages/tta-dev-primitives/src/tta_dev_primitives/integrations/e2b_primitive.py,255,code,py,Note: API key is set via E2B_API_KEY environment variable.,"        """"""Create new E2B sandbox. |  |         Note: API key is set via E2B_API_KEY environment variable. |         The create() method doesn't accept api_key parameter directly. |         """""""
packages/tta-dev-primitives/.cursor/rules/documentation.instructions.md,225,other,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
packages/tta-dev-primitives/docs/memory/README.md,154,non-actionable,md,"""review_notes"": [""Line 42: Consider error handling""],","await memory.add(task_key, { |     ""file_path"": ""main.py"", |     ""review_notes"": [""Line 42: Consider error handling""], |     ""status"": ""in_progress"" | })"
packages/tta-dev-primitives/docs/integrations/E2B_README.md,130,non-actionable,md,"- Syntax errors, import errors, logic bugs are common","**Why this is critical:** | - AI-generated code fails ~30-50% of the time on first attempt | - Syntax errors, import errors, logic bugs are common | - E2B catches these BEFORE they reach production | - FREE tier makes validation cost $0"
packages/tta-dev-primitives/tests/adaptive/test_timeout.py,242,code,py,# Note: Learning may or may not create new strategy depending on threshold, |         # Should learn that timeout can be much lower |         # Note: Learning may or may not create new strategy depending on threshold |         # Just verify execution was successful and tracked |         assert adaptive._success_count == 15
packages/tta-dev-primitives/tests/adaptive/test_timeout.py,265,code,py,# Note: Actual timeout depends on learning algorithm," |         # Baseline was 1000ms, but we should learn a tighter timeout |         # Note: Actual timeout depends on learning algorithm |         # Just verify stats are tracked |         assert stats[""total_executions""] == 15"
packages/tta-dev-primitives/tests/adaptive/test_integration.py,221,code,py,# Note: AdaptiveCachePrimitive doesn't support min_observations_before_learning," |         # Create cache primitive (uses default 3600s TTL) |         # Note: AdaptiveCachePrimitive doesn't support min_observations_before_learning |         cache_service = AdaptiveCachePrimitive( |             target_primitive=fallback_service,"
packages/tta-dev-primitives/tests/lifecycle/test_stage_manager_kb.py,6,code,py,NOTE: These tests spawn subprocess tests and should be run as integration tests.,"ensuring that KB recommendations are properly included in stage validation. |  | NOTE: These tests spawn subprocess tests and should be run as integration tests. | """""" | "
packages/tta-dev-primitives/tests/lifecycle/test_stage_manager_kb.py,35,code,py,Note: Uses empty stage_criteria_map to avoid running expensive,"        """"""Test check_readiness works without KB parameter. |  |         Note: Uses empty stage_criteria_map to avoid running expensive |         validation checks (like pytest) that would cause test timeouts. |         This test focuses on KB integration, not validation logic."
packages/tta-dev-primitives/tests/observability/test_instrumented_primitives.py,228,code,py,"# Note: The actual span_id may be updated by inject_trace_context,"," |     # Child contexts should have parent_span_id set to parent's span_id |     # Note: The actual span_id may be updated by inject_trace_context, |     # but parent_span_id should be set from the parent context |     assert branch1.captured_context.parent_span_id is not None"
packages/tta-dev-primitives/tests/integration/test_prometheus_metrics.py,10,code,py,"Note: Full primitive-level metrics integration (execution time, success/failure rates)","4. Scrape targets are configured correctly |  | Note: Full primitive-level metrics integration (execution time, success/failure rates) | requires OpenTelemetry metrics instrumentation in InstrumentedPrimitive, which is | tracked as a follow-up task. These tests focus on infrastructure readiness."
packages/tta-dev-primitives/tests/integration/test_prometheus_metrics.py,14,code,py,NOTE: All tests in this module require Docker containers and should run as integration tests.,"tracked as a follow-up task. These tests focus on infrastructure readiness. |  | NOTE: All tests in this module require Docker containers and should run as integration tests. | """""" | "
packages/tta-dev-primitives/tests/integration/test_prometheus_metrics.py,222,code,py,# Note: This metric may be 0 if no spans have been sent yet,"    assert result.get(""status"") == ""success"", ""Prometheus query failed"" |  |     # Note: This metric may be 0 if no spans have been sent yet |     # We just verify the metric exists |     data = result.get(""data"", {})"
packages/tta-dev-primitives/tests/integration/test_prometheus_metrics.py,243,code,py,# Note: This metric may be 0 if no metric points have been sent yet,"    assert result.get(""status"") == ""success"", ""Prometheus query failed"" |  |     # Note: This metric may be 0 if no metric points have been sent yet |     # We just verify the metric exists |     data = result.get(""data"", {})"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,18,code,py,NOTE: All tests in this module require Docker containers and should run as integration tests.,"    - OTEL_EXPORTER_OTLP_ENDPOINT: OTLP endpoint (default: http://localhost:4318) |  | NOTE: All tests in this module require Docker containers and should run as integration tests. | """""" | "
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,257,code,py,"# Note: Only primitive.X spans have correlation_id tags, not internal sequential.step_X spans"," |     # Verify we have spans for the sequential workflow |     # Note: Only primitive.X spans have correlation_id tags, not internal sequential.step_X spans |     span_names = [span.get(""operationName"", """") for span in all_spans] | "
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,322,code,py,# Note: Only primitive.X spans have correlation_id tags," |     # Verify parallel branch spans |     # Note: Only primitive.X spans have correlation_id tags |     span_names = [span.get(""operationName"", """") for span in all_spans] | "
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,380,code,py,"# Note: ConditionalPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags"," |     # Verify conditional branch spans |     # Note: ConditionalPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags |     # We can only verify the child primitive spans |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,434,code,py,"# Note: SwitchPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags"," |     # Verify switch case spans |     # Note: SwitchPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags |     # We can only verify the child primitive spans |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,501,code,py,"# Note: RetryPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags"," |     # Verify retry attempt spans |     # Note: RetryPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags |     # We can only verify the child primitive spans |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,554,code,py,"# Note: FallbackPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags"," |     # Verify fallback execution spans |     # Note: FallbackPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags |     # We can only verify the child primitive spans |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,609,code,py,"# Note: SagaPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags"," |     # Verify saga compensation spans |     # Note: SagaPrimitive doesn't extend InstrumentedPrimitive, so it doesn't have correlation_id tags |     # We can only verify the child primitive spans |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/test_otel_backend_integration.py,677,code,py,# Note: Only InstrumentedPrimitive subclasses have correlation_id tags," |     # Verify trace propagation across primitives |     # Note: Only InstrumentedPrimitive subclasses have correlation_id tags |     # ConditionalPrimitive doesn't extend InstrumentedPrimitive, so we can't verify it |     span_names = [span.get(""operationName"", """") for span in all_spans]"
packages/tta-dev-primitives/tests/integration/config/otel-collector-config.yml,52,config,yml,# Logging exporter for debugging,    namespace: tta_primitives |  |   # Logging exporter for debugging |   logging: |     loglevel: debug
packages/tta-dev-primitives/tests/research/test_free_tier_research.py,71,code,py,"assert ""ChatGPT"" in openai_info.notes  # Web UI vs API confusion","        assert openai_info.credit_card_required is True |         assert openai_info.setup_url is not None |         assert ""ChatGPT"" in openai_info.notes  # Web UI vs API confusion |  |     async def test_anthropic_provider_info(self) -> None:"
packages/tta-dev-primitives/tests/research/test_free_tier_research.py,85,code,py,"assert ""claude.ai"" in anthropic_info.notes  # Web UI is free","        assert anthropic_info.has_free_tier is False  # No free API tier |         assert anthropic_info.credit_card_required is True |         assert ""claude.ai"" in anthropic_info.notes  # Web UI is free |  |     async def test_google_gemini_provider_info(self) -> None:"
packages/tta-dev-primitives/tests/research/test_free_tier_research.py,101,code,py,"assert ""AI Studio"" in gemini_info.notes  # AI Studio vs Vertex AI","        assert gemini_info.credit_card_required is False |         assert gemini_info.expires == ""Never"" |         assert ""AI Studio"" in gemini_info.notes  # AI Studio vs Vertex AI |  |     async def test_openrouter_provider_info(self) -> None:"
packages/tta-dev-primitives/tests/research/test_free_tier_research.py,116,code,py,"assert ""BYOK"" in openrouter_info.notes  # BYOK explanation","        assert ""1M"" in openrouter_info.free_tier_details |         assert openrouter_info.credit_card_required is False |         assert ""BYOK"" in openrouter_info.notes  # BYOK explanation |  |     async def test_ollama_provider_info(self) -> None:"
packages/tta-dev-primitives/tests/research/test_free_tier_research.py,146,code,py,"assert ""not found"" in unknown_info.notes","        unknown_info = response.providers[""unknown-provider""] |         assert unknown_info.has_free_tier is False |         assert ""not found"" in unknown_info.notes |  |     async def test_changelog_generation(self) -> None:"
packages/tta-dev-primitives/tests/integrations/test_e2b_primitive.py,121,code,py,mock_sandbox.notebook.exec_cell = AsyncMock(return_value=error_result),"        error_result.logs = Mock(stdout=[], stderr=[""error log""]) |  |         mock_sandbox.notebook.exec_cell = AsyncMock(return_value=error_result) |  |         with patch("
packages/tta-dev-primitives/tests/integrations/test_e2b_primitive.py,145,code,py,mock_sandbox.notebook.exec_cell = slow_exec,"            return Mock(results=[], error=None, logs=Mock(stdout=[], stderr=[])) |  |         mock_sandbox.notebook.exec_cell = slow_exec |  |         with patch("
packages/tta-dev-primitives/tests/integrations/test_e2b_primitive.py,295,code,py,mock_sandbox.notebook.exec_cell = AsyncMock(return_value=empty_result),"        empty_result.logs = Mock(stdout=[], stderr=[]) |  |         mock_sandbox.notebook.exec_cell = AsyncMock(return_value=empty_result) |  |         with patch("
packages/tta-dev-primitives/tests/integrations/test_e2b_primitive.py,340,code,py,mock_sandbox.notebook.exec_cell = AsyncMock(return_value=fib_result),"        fib_result.logs = Mock(stdout=[""55""], stderr=[]) |  |         mock_sandbox.notebook.exec_cell = AsyncMock(return_value=fib_result) |  |         with patch("
packages/tta-dev-primitives/.augment/rules/documentation.instructions.md,225,augment,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
packages/tta-dev-primitives/.github/instructions/documentation.instructions.instructions.md,230,config,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
packages/universal-agent-context/FINAL_VERIFICATION_REPORT.md,38,other,md,**Note**: Some YAML frontmatter validation errors exist but do not affect functionality. These can be fixed in post-export cleanup.,"- âœ… Works across Claude, Gemini, Copilot, Augment |  | **Note**: Some YAML frontmatter validation errors exist but do not affect functionality. These can be fixed in post-export cleanup. |  | ### âœ… Augment CLI-Specific Primitives - `.augment/` (~150 files)"
packages/universal-agent-context/README.md,226,other,md,- Zero critical bugs,- Comprehensive documentation | - Battle-tested in production | - Zero critical bugs |  | ---
packages/universal-agent-context/apm.yml,156,config,yml,# Bug fix workflow,"      - ""Create promotion PR"" |  |   # Bug fix workflow |   bug_fix: |     trigger: ""manual"""
packages/universal-agent-context/apm.yml,157,config,yml,bug_fix:," |   # Bug fix workflow |   bug_fix: |     trigger: ""manual"" |     steps:"
packages/universal-agent-context/CLAUDE.md,30,other,md,#### For Debugging,4. Recommending best practices |  | #### For Debugging | Use Claude's analytical capabilities to: | 1. Reproduce issues systematically
packages/universal-agent-context/CLAUDE.md,144,other,md,- Debugging workflows,- Complex refactoring tasks | - Migration procedures | - Debugging workflows |  | ## Common Workflows
packages/universal-agent-context/CLAUDE.md,148,other,md,"**See AGENTS.md** for common workflows (feature implementation, bug fix, refactoring).","## Common Workflows |  | **See AGENTS.md** for common workflows (feature implementation, bug fix, refactoring). |  | ## Development Commands"
packages/universal-agent-context/EXPORT_SUMMARY.md,100,other,md,- bug-fix.prompt.md,**Workflows** (8 files): | - augster-axiomatic-workflow.prompt.md | - bug-fix.prompt.md | - component-promotion.prompt.md | - context-management.workflow.md
packages/universal-agent-context/EXPORT_SUMMARY.md,112,other,md,- debugging.context.md,- cli.py | - conversation_manager.py | - debugging.context.md | - deployment.context.md | - integration.context.md
packages/universal-agent-context/CONTRIBUTING.md,20,other,md,Found a bug or have a feature request?,### 1. Report Issues |  | Found a bug or have a feature request? |  | 1. Check [existing issues](https://github.com/theinterneti/TTA.dev/issues)
packages/universal-agent-context/CONTRIBUTING.md,25,other,md,- Steps to reproduce (for bugs),"2. Create a new issue with: |    - Clear title and description |    - Steps to reproduce (for bugs) |    - Expected vs. actual behavior |    - Your environment (OS, AI agent, version)"
packages/universal-agent-context/CONTRIBUTING.md,63,other,md,- âœ… **Zero Critical Bugs**: All critical issues resolved,- âœ… **Documentation**: Comprehensive docs for all new features | - âœ… **Battle-Tested**: Real-world usage validation | - âœ… **Zero Critical Bugs**: All critical issues resolved |  | ### File Standards
packages/universal-agent-context/CONTRIBUTING.md,163,other,md,"git commit -m ""fix bug""","# Bad commit messages | git commit -m ""update files"" | git commit -m ""fix bug"" | git commit -m ""changes"" | ```"
packages/universal-agent-context/CONTRIBUTING.md,169,other,md,- `fix:` - Bug fix,**Commit Message Format**: | - `feat:` - New feature | - `fix:` - Bug fix | - `docs:` - Documentation changes | - `test:` - Test changes
packages/universal-agent-context/CONTRIBUTING.md,194,other,md,- [ ] Bug fix, | ## Type of Change | - [ ] Bug fix | - [ ] New feature | - [ ] Documentation update
packages/universal-agent-context/AGENTS.md,246,other,md,"- **Focus**: Implementation, refactoring, bug fixes"," | ### Backend Developer | - **Focus**: Implementation, refactoring, bug fixes | - **Allowed Tools**: editFiles, runCommands, codebase-retrieval, testFailure | - **Denied Tools**: deleteFiles, deployProduction"
packages/universal-agent-context/AGENTS.md,273,other,md,### Bug Fix,6. Promote to staging |  | ### Bug Fix | 1. Reproduce issue | 2. Identify root cause
packages/universal-agent-context/AGENTS.md,323,other,md,## Important Notes,"5. **Maintain 100% pass rate**: Never commit failing tests |  | ## Important Notes |  | - **Package Manager**: Always use `uv`, never pip or poetry"
packages/universal-agent-context/CHANGELOG.md,67,other,md,"- Axiomatic workflow, bug fix, component promotion"," | **Workflow Templates** (8 files): | - Axiomatic workflow, bug fix, component promotion | - Context management, Docker migration, feature implementation | - Quality gate fix, test coverage improvement"
packages/universal-agent-context/CHANGELOG.md,74,other,md,"- 8 context files (debugging, deployment, integration, performance, refactoring, security, testing)","- Python CLI for context management | - Conversation manager | - 8 context files (debugging, deployment, integration, performance, refactoring, security, testing) | - Sessions and specs directories | "
packages/universal-agent-context/GEMINI.md,128,other,md,- `debugging.context.md` - Debugging workflows, | ### Context Helpers (`.augment/context/`) | - `debugging.context.md` - Debugging workflows | - `refactoring.context.md` - Code refactoring patterns | - `performance.context.md` - Performance optimization
packages/universal-agent-context/GEMINI.md,136,other,md,- `bug-fix.prompt.md` - Bug investigation and resolution,- `test-coverage-improvement.prompt.md` - Systematic coverage improvement | - `component-promotion.prompt.md` - Component maturity progression | - `bug-fix.prompt.md` - Bug investigation and resolution |  | ## Best Practices for This Project
packages/universal-agent-context/GEMINI.md,155,other,md,## Important Notes,"- `pytest.ini` - Pytest configuration |  | ## Important Notes |  | **See AGENTS.md** for important notes (package management, circuit breakers, error handling, testing, documentation)."
packages/universal-agent-context/GEMINI.md,157,other,md,"**See AGENTS.md** for important notes (package management, circuit breakers, error handling, testing, documentation).","## Important Notes |  | **See AGENTS.md** for important notes (package management, circuit breakers, error handling, testing, documentation). |  | ---"
packages/universal-agent-context/pyproject.toml,46,other,toml,"""B"",  # flake8-bugbear","    ""F"",  # pyflakes |     ""I"",  # isort |     ""B"",  # flake8-bugbear |     ""C4"", # flake8-comprehensions |     ""UP"", # pyupgrade"
packages/universal-agent-context/examples/README.md,256,non-actionable,md,Each example includes assertions and debug output. To run with pytest:,## ðŸ§ª Testing |  | Each example includes assertions and debug output. To run with pytest: |  | ```bash
packages/universal-agent-context/examples/README.md,283,non-actionable,md,5. **Track History:** Agent history in context helps debug complex workflows,3. **Monitor Performance:** Parallel execution shines with I/O-bound operations | 4. **Handle Failures:** Use `require_all_success=False` for fault tolerance | 5. **Track History:** Agent history in context helps debug complex workflows |  | ---
packages/universal-agent-context/examples/README.md,289,non-actionable,md,Found a bug or want to add an example? See [`/CONTRIBUTING.md`](../../../CONTRIBUTING.md).,## ðŸ¤ Contributing |  | Found a bug or want to add an example? See [`/CONTRIBUTING.md`](../../../CONTRIBUTING.md). |  | ---
packages/universal-agent-context/docs/knowledge/AUGMENT_CLI_CLARIFICATION.md,51,non-actionable,md,"- **Context Files** - Domain-specific context (debugging, deployment, integration, performance, refactoring, security, testing)","- **Python CLI** - Command-line interface for context management | - **Conversation Manager** - Session and context tracking | - **Context Files** - Domain-specific context (debugging, deployment, integration, performance, refactoring, security, testing) | - **Sessions** - Saved conversation sessions | "
packages/universal-agent-context/docs/knowledge/AUGMENT_CLI_CLARIFICATION.md,77,non-actionable,md,"- **Common Tasks** - Bug fix, feature implementation, component promotion, quality gate fix, test coverage improvement","#### 4. Workflow Templates | - **Prompt Files** - Reusable workflow prompts | - **Common Tasks** - Bug fix, feature implementation, component promotion, quality gate fix, test coverage improvement |  | **Files**:"
packages/universal-agent-context/docs/knowledge/AUGMENT_CLI_CLARIFICATION.md,80,non-actionable,md,- `workflows/bug-fix.prompt.md`, | **Files**: | - `workflows/bug-fix.prompt.md` | - `workflows/feature-implementation.prompt.md` | - `workflows/component-promotion.prompt.md`
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,15,augment,md,"**When to Use**: Multi-session development, complex features, component promotion, refactoring, debugging.","**Purpose**: Manage development context across multiple sessions for complex features. |  | **When to Use**: Multi-session development, complex features, component promotion, refactoring, debugging. |  | ## Quick Commands"
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,83,augment,md,## Debugging Pattern,``` |  | ## Debugging Pattern |  | ### Investigation Session
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,87,augment,md,# Create debugging session,### Investigation Session | ```bash | # Create debugging session | python .augment/context/cli.py new tta-debug-session-timeout-2025-10-27 | 
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,88,augment,md,python .augment/context/cli.py new tta-debug-session-timeout-2025-10-27,```bash | # Create debugging session | python .augment/context/cli.py new tta-debug-session-timeout-2025-10-27 |  | # Track investigation
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,91,augment,md,python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \," | # Track investigation | python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \ |   ""Issue: Session timeout after 5 minutes. Investigating Redis TTL settings."" \ |   --importance 0.9"
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,96,augment,md,python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \," | # Track findings | python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \ |   ""Found: Redis TTL set to 300s. Need to increase to 3600s for long sessions."" \ |   --importance 1.0"
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,103,augment,md,# Load debugging session,### Fix and Verification Session | ```bash | # Load debugging session | python .augment/context/cli.py show tta-debug-session-timeout-2025-10-27 | 
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,104,augment,md,python .augment/context/cli.py show tta-debug-session-timeout-2025-10-27,```bash | # Load debugging session | python .augment/context/cli.py show tta-debug-session-timeout-2025-10-27 |  | # Track fix
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,107,augment,md,python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \," | # Track fix | python .augment/context/cli.py add tta-debug-session-timeout-2025-10-27 \ |   ""Fix: Updated Redis TTL to 3600s. Verified with 1-hour test session."" \ |   --importance 0.9"
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,119,augment,md,- `tta-debug-session-timeout-2025-10-27` - Debugging,**Examples**: | - `tta-user-preferences-2025-10-27` - Feature development | - `tta-debug-session-timeout-2025-10-27` - Debugging | - `tta-refactor-agent-orchestration-2025-10-27` - Refactoring | 
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,128,augment,md,- Complex debugging,- Component development (spec-to-production workflow) | - Large-scale refactoring | - Complex debugging |  | âŒ **Don't use for**:
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,131,augment,md,"- Trivial tasks (single-file edits, simple bug fixes)"," | âŒ **Don't use for**: | - Trivial tasks (single-file edits, simple bug fixes) | - Quick queries (""What does this function do?"") | - One-off operations (running tests, checking status)"
packages/universal-agent-context/.augment/workflows/context-management.workflow.md,140,augment,md,- Bug is fixed and verified,Clean up sessions when: | - Feature is complete and merged | - Bug is fixed and verified | - Refactoring is complete | - Session is >30 days old and no longer relevant
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,1,augment,md,# Agentic Workflow: Bug Fix,# Agentic Workflow: Bug Fix |  | **Purpose:** Systematic bug investigation and resolution for TTA components
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,3,augment,md,**Purpose:** Systematic bug investigation and resolution for TTA components,# Agentic Workflow: Bug Fix |  | **Purpose:** Systematic bug investigation and resolution for TTA components |  | **When to Use:**
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,6,augment,md,- Bug reported by user or QA, | **When to Use:** | - Bug reported by user or QA | - Test failure discovered | - Production issue detected
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,15,augment,md,"This workflow guides systematic bug investigation, root cause analysis, fix implementation, and verification to ensure bugs are properly resolved without introducing regressions.","## Workflow Description |  | This workflow guides systematic bug investigation, root cause analysis, fix implementation, and verification to ensure bugs are properly resolved without introducing regressions. |  | ---"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,22,augment,md,- **Bug Description:** Clear description of the bug, | ### Required Inputs | - **Bug Description:** Clear description of the bug | - **Reproduction Steps:** Steps to reproduce the bug | - **Expected Behavior:** What should happen
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,29,augment,md,- **Environment:** Where bug occurs (dev/staging/production), | ### Optional Inputs | - **Environment:** Where bug occurs (dev/staging/production) | - **Severity:** Critical/High/Medium/Low | - **User Impact:** Number of users affected
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,40,augment,md,**Goal:** Reliably reproduce the bug locally,### Step 1: Reproduce the Bug |  | **Goal:** Reliably reproduce the bug locally |  | **Actions:**
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,43,augment,md,1. Review bug description and reproduction steps, | **Actions:** | 1. Review bug description and reproduction steps | 2. Set up test environment | 3. Attempt to reproduce
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,55,augment,md,uv run pytest tests/test_{component}.py::test_{bug_scenario} -v, | # Run specific test if available | uv run pytest tests/test_{component}.py::test_{bug_scenario} -v |  | # Or reproduce manually
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,62,augment,md,- [ ] Bug reproduces consistently, | **Validation Criteria:** | - [ ] Bug reproduces consistently | - [ ] Reproduction steps documented | - [ ] Environment documented
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,81,augment,md,2. Add logging/debugging,**Actions:** | 1. Review error messages and stack traces | 2. Add logging/debugging | 3. Use debugger to step through code | 4. Check recent changes (git log)
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,82,augment,md,3. Use debugger to step through code,1. Review error messages and stack traces | 2. Add logging/debugging | 3. Use debugger to step through code | 4. Check recent changes (git log) | 5. Review related code
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,86,augment,md,**Debugging Techniques:**,5. Review related code |  | **Debugging Techniques:** | ```python | # Add debugging breakpoint
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,88,augment,md,# Add debugging breakpoint,**Debugging Techniques:** | ```python | # Add debugging breakpoint | import pdb; pdb.set_trace() | 
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,94,augment,md,"logger.debug(f""Variable state: {variable}"")","import logging | logger = logging.getLogger(__name__) | logger.debug(f""Variable state: {variable}"") |  | # Check recent changes"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,109,augment,md,- [ ] Understand why bug occurs,**Validation Criteria:** | - [ ] Root cause identified | - [ ] Understand why bug occurs | - [ ] Know what needs to change | - [ ] Documented in AI context
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,127,augment,md,## Bug Fix Design,**Fix Design Template:** | ```markdown | ## Bug Fix Design |  | **Bug:** {brief description}
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,129,augment,md,**Bug:** {brief description},## Bug Fix Design |  | **Bug:** {brief description} | **Root Cause:** {root cause} | 
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,174,augment,md,async def test_bug_fix_regression():,"# Step 1: Write failing test | @pytest.mark.asyncio | async def test_bug_fix_regression(): |     """"""Test that bug is fixed."""""" |     # Arrange"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,175,augment,md,"""""""Test that bug is fixed.""""""","@pytest.mark.asyncio | async def test_bug_fix_regression(): |     """"""Test that bug is fixed."""""" |     # Arrange |     setup_bug_scenario()"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,177,augment,md,setup_bug_scenario(),"    """"""Test that bug is fixed."""""" |     # Arrange |     setup_bug_scenario() |      |     # Act"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,180,augment,md,result = await function_with_bug(),     |     # Act |     result = await function_with_bug() |      |     # Assert
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,189,augment,md,async def function_with_bug():,```python | # Step 2: Implement fix | async def function_with_bug(): |     # Before: Buggy implementation |     # if condition:  # âŒ Wrong condition
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,190,augment,md,# Before: Buggy implementation,# Step 2: Implement fix | async def function_with_bug(): |     # Before: Buggy implementation |     # if condition:  # âŒ Wrong condition |     
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,201,augment,md,uv run pytest tests/test_{component}.py::test_bug_fix_regression -v,```bash | # Step 3: Run regression test | uv run pytest tests/test_{component}.py::test_bug_fix_regression -v |  | # Step 4: Run all tests
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,262,augment,md,**Goal:** Document bug and fix for future reference,### Step 6: Document the Fix |  | **Goal:** Document bug and fix for future reference |  | **Actions:**
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,275,augment,md,## Bug: {brief description},cat >> .augment/memory/component-failures.memory.md << EOF |  | ## Bug: {brief description} |  | **Date:** {date}
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,291,augment,md,{how to prevent similar bugs}, | **Prevention:** | {how to prevent similar bugs} |  | EOF
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,300,augment,md,# Fix for bug #{issue_number}: {brief description},# Add comment explaining the fix | async def fixed_function(): |     # Fix for bug #{issue_number}: {brief description} |     # Previous implementation had {problem} |     # Now correctly handles {scenario}
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,310,augment,md,"""Fixed bug in {component}: {brief description}. Root cause: {root_cause}. Added regression test."" \","```bash | python .augment/context/cli.py add integrated-workflow-2025-10-20 \ |     ""Fixed bug in {component}: {brief description}. Root cause: {root_cause}. Added regression test."" \ |     --importance 0.9 | ```"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,316,augment,md,## Bug Fix: {brief description},**GitHub Issue:** | ```markdown | ## Bug Fix: {brief description} |  | **Component:** {component}
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,349,augment,md,- [ ] Bug reproduces reliably, | ### Overall Success Criteria | - [ ] Bug reproduces reliably | - [ ] Root cause identified | - [ ] Fix implemented with regression test
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,355,augment,md,- [ ] Bug documented,- [ ] No regressions introduced | - [ ] Quality gates pass | - [ ] Bug documented | - [ ] AI context updated | 
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,369,augment,md,### 1. Bug Fix Report,## Output/Deliverables |  | ### 1. Bug Fix Report | ```json | {
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,372,augment,md,"""bug"": {","```json | { |   ""bug"": { |     ""description"": ""{description}"", |     ""component"": ""{component}"","
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,385,augment,md,"""regression_test"": ""tests/test_{component}.py::test_bug_fix""","    ""description"": ""{fix_description}"", |     ""files_changed"": [""{file1}"", ""{file2}""], |     ""regression_test"": ""tests/test_{component}.py::test_bug_fix"" |   }, |   ""validation"": {"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,406,augment,md,- Bug documented, | ### 4. GitHub Issue | - Bug documented | - Fix documented | - Issue closed
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,416,augment,md,# Track bug investigation,"### AI Context Management | ```python | # Track bug investigation | context_manager.add_message( |     session_id=""integrated-workflow-2025-10-20"","
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,420,augment,md,"content=f""Investigating bug in {component}: {description}"",","    session_id=""integrated-workflow-2025-10-20"", |     role=""user"", |     content=f""Investigating bug in {component}: {description}"", |     importance=0.9 | )"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,436,augment,md,"content=f""Bug fixed with regression test. All tests pass."",","    session_id=""integrated-workflow-2025-10-20"", |     role=""assistant"", |     content=f""Bug fixed with regression test. All tests pass."", |     importance=0.9 | )"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,452,augment,md,# Track bug fix metrics,"### Development Observability | ```python | # Track bug fix metrics | @track_execution(""bug_fix"") | async def fix_bug(component: str, bug_id: str):"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,453,augment,md,"@track_execution(""bug_fix"")","```python | # Track bug fix metrics | @track_execution(""bug_fix"") | async def fix_bug(component: str, bug_id: str): |     # Bug fix tracked automatically"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,454,augment,md,"async def fix_bug(component: str, bug_id: str):","# Track bug fix metrics | @track_execution(""bug_fix"") | async def fix_bug(component: str, bug_id: str): |     # Bug fix tracked automatically |     pass"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,455,augment,md,# Bug fix tracked automatically,"@track_execution(""bug_fix"") | async def fix_bug(component: str, bug_id: str): |     # Bug fix tracked automatically |     pass | "
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,467,augment,md,## Common Bug Patterns,--- |  | ## Common Bug Patterns |  | ### 1. Async/Await Issues
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,471,augment,md,# Bug: Missing await,### 1. Async/Await Issues | ```python | # Bug: Missing await | async def get_data(): |     result = fetch_data()  # âŒ Missing await
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,484,augment,md,# Bug: Connection not closed,### 2. Database Connection Leaks | ```python | # Bug: Connection not closed | async def get_session(session_id): |     redis = await create_redis_connection()
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,502,augment,md,# Bug: No error handling,### 3. Missing Error Handling | ```python | # Bug: No error handling | async def get_ai_response(prompt): |     response = await ai_provider.generate(prompt)  # âŒ No error handling
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,525,augment,md,- Debugging Context: `.augment/context/debugging.context.md`, | ### TTA Documentation | - Debugging Context: `.augment/context/debugging.context.md` | - Component Failures: `.augment/memory/component-failures.memory.md` | - Testing Patterns: `.augment/memory/testing-patterns.memory.md`
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,531,augment,md,"- Debugger: `pdb`, `ipdb`","### Tools | - pytest: `uv run pytest` | - Debugger: `pdb`, `ipdb` | - Linting: `uvx ruff check` | - Type checking: `uvx pyright`"
packages/universal-agent-context/.augment/workflows/bug-fix.prompt.md,537,augment,md,**Note:** Always write a regression test before fixing the bug. This ensures the bug is caught if it reappears.,--- |  | **Note:** Always write a regression test before fixing the bug. This ensures the bug is caught if it reappears. |  | 
packages/universal-agent-context/.augment/workflows/quality-gate-fix.prompt.md,147,augment,md,# Run with debugging,uv run pytest tests/component_name/ -v |  | # Run with debugging | uv run pytest tests/component_name/test_file.py::test_function --pdb | ```
packages/universal-agent-context/.augment/workflows/quality-gate-fix.prompt.md,176,augment,md,"**Note:** For comprehensive coverage improvement, use `.augment/workflows/test-coverage-improvement.prompt.md`","4. Verify coverage meets threshold |  | **Note:** For comprehensive coverage improvement, use `.augment/workflows/test-coverage-improvement.prompt.md` |  | **Quick Coverage Fix:**"
packages/universal-agent-context/.augment/workflows/quality-gate-fix.prompt.md,557,augment,md,- Bug Fix: `.augment/workflows/bug-fix.prompt.md`,### Related Workflows | - Test Coverage Improvement: `.augment/workflows/test-coverage-improvement.prompt.md` | - Bug Fix: `.augment/workflows/bug-fix.prompt.md` | - Component Promotion: `.augment/workflows/component-promotion.prompt.md` | 
packages/universal-agent-context/.augment/workflows/quality-gate-fix.prompt.md,562,augment,md,**Note:** Document all quality gate fixes in `.augment/memory/quality-gates.memory.md` for future reference.,--- |  | **Note:** Document all quality gate fixes in `.augment/memory/quality-gates.memory.md` for future reference. |  | 
packages/universal-agent-context/.augment/workflows/component-promotion.prompt.md,336,augment,md,- Critical bug discovered,### Failure Criteria (Rollback Triggers) | - Any quality gate fails | - Critical bug discovered | - Performance degradation >20% | - Error rate >1%
packages/universal-agent-context/.augment/workflows/component-promotion.prompt.md,444,augment,md,- Critical bug discovered,### When to Rollback | - Quality gates fail post-deployment | - Critical bug discovered | - Performance degradation | - Security issue found
packages/universal-agent-context/.augment/workflows/component-promotion.prompt.md,486,augment,md,**Note:** Always validate promotion criteria before executing promotion. Rollback is easier than fixing production issues.,--- |  | **Note:** Always validate promotion criteria before executing promotion. Rollback is easier than fixing production issues. |  | 
packages/universal-agent-context/.augment/workflows/feature-implementation.prompt.md,546,augment,md,- Bug Fix: `.augment/workflows/bug-fix.prompt.md`,- Quality Gate Fix: `.augment/workflows/quality-gate-fix.prompt.md` | - Test Coverage Improvement: `.augment/workflows/test-coverage-improvement.prompt.md` | - Bug Fix: `.augment/workflows/bug-fix.prompt.md` |  | ---
packages/universal-agent-context/.augment/workflows/feature-implementation.prompt.md,550,augment,md,**Note:** This workflow ensures systematic feature implementation following TTA standards and quality gates.,--- |  | **Note:** This workflow ensures systematic feature implementation following TTA standards and quality gates. |  | 
packages/universal-agent-context/.augment/workflows/test-coverage-improvement.prompt.md,546,augment,md,"**Note:** Focus on meaningful tests that verify behavior, not just increase coverage numbers.","--- |  | **Note:** Focus on meaningful tests that verify behavior, not just increase coverage numbers. |  | "
packages/universal-agent-context/.augment/instructions/quality-gates.instructions.md,418,augment,md,- Log errors for debugging,- Catch and handle subprocess errors | - Provide context in error messages | - Log errors for debugging | - Return structured error information | - Fail gracefully with clear messages
packages/universal-agent-context/.augment/instructions/augster-operational-loop.instructions.md,105,augment,md,## Important Notes,"``` |  | ## Important Notes |  | - **Never ask ""Do you want me to continue?""** - This violates the Autonomy maxim"
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,63,augment,md,- 7-day stability period (no critical bugs),- Multi-component workflows tested | - Staging deployment successful | - 7-day stability period (no critical bugs) |  | **Typical Duration:** 1-2 weeks
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,214,augment,md,- Add notes about promotion blockers,**Moving Cards:** | - Move component card when quality gates pass | - Add notes about promotion blockers | - Link to workflow reports | 
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,255,augment,md,### TODO Comments,- `quality-gate-failure` - Quality gate failure |  | ### TODO Comments |  | Link TODO comments to GitHub issues:
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,257,augment,md,Link TODO comments to GitHub issues:,### TODO Comments |  | Link TODO comments to GitHub issues: |  | ```python
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,260,augment,md,# TODO(#123): Increase test coverage to 70% for staging promotion, | ```python | # TODO(#123): Increase test coverage to 70% for staging promotion | def incomplete_function(): |     pass
packages/universal-agent-context/.augment/instructions/component-maturity.instructions.md,264,augment,md,# TODO(#124): Add integration tests for database persistence,    pass |  | # TODO(#124): Add integration tests for database persistence | def database_operation(): |     pass
packages/universal-agent-context/.augment/instructions/augster-protocols.instructions.md,81,augment,md,- Current bug states or issues,### Examples of Invalid PAFs (Do NOT Store) | - Temporary implementation details | - Current bug states or issues | - Specific function implementations | - Variable names or values
packages/universal-agent-context/.augment/instructions/memory-capture.instructions.md,26,augment,md,"**Purpose**: Document failed approaches, bugs, and mistakes to prevent repetition","### Implementation Failures |  | **Purpose**: Document failed approaches, bugs, and mistakes to prevent repetition |  | **When to Capture**:"
packages/universal-agent-context/.augment/instructions/memory-capture.instructions.md,29,augment,md,- After encountering a significant bug or error that took >30 minutes to resolve, | **When to Capture**: | - After encountering a significant bug or error that took >30 minutes to resolve | - When an approach fails after substantial effort (>2 hours) | - When discovering a common pitfall or anti-pattern
packages/universal-agent-context/.augment/instructions/memory-capture.instructions.md,32,augment,md,- After debugging a complex issue with non-obvious root cause,- When an approach fails after substantial effort (>2 hours) | - When discovering a common pitfall or anti-pattern | - After debugging a complex issue with non-obvious root cause | - When a quality gate fails unexpectedly | 
packages/universal-agent-context/.augment/instructions/memory-capture.instructions.md,45,augment,md,"- **High**: Significant development blockers, major bugs affecting multiple components","**Severity Guidelines**: | - **Critical**: System-breaking issues, data loss, security vulnerabilities | - **High**: Significant development blockers, major bugs affecting multiple components | - **Medium**: Moderate issues affecting single component, workarounds available | - **Low**: Minor issues, cosmetic problems, documentation gaps"
packages/universal-agent-context/.augment/context/README.md,199,augment,md,- Capture when: Spent >30 minutes debugging or resolving an issue,"**Memory categories:** | - **implementation-failures:** Failed approaches, errors, and their resolutions |   - Capture when: Spent >30 minutes debugging or resolving an issue |   - Severity: Based on time lost and impact | - **successful-patterns:** Proven solutions and best practices"
packages/universal-agent-context/.augment/context/refactoring.context.md,499,augment,md,**Note:** Always run tests before and after refactoring to ensure behavior is preserved.,--- |  | **Note:** Always run tests before and after refactoring to ensure behavior is preserved. |  | 
packages/universal-agent-context/.augment/context/performance.context.md,532,augment,md,**Note:** Always measure before and after optimization to verify improvement.,--- |  | **Note:** Always measure before and after optimization to verify improvement. |  | 
packages/universal-agent-context/.augment/context/testing.context.md,5,augment,md,"**When to Use:** When writing tests, running test suites, debugging test failures, or improving test coverage.","**Purpose:** Quick reference for testing commands, patterns, fixtures, and best practices in TTA development. |  | **When to Use:** When writing tests, running test suites, debugging test failures, or improving test coverage. |  | ---"
packages/universal-agent-context/.augment/context/testing.context.md,210,augment,md,"@pytest.mark.xfail(reason=""Known bug"")"," | # Expected to fail | @pytest.mark.xfail(reason=""Known bug"") | def test_known_bug(): |     assert buggy_function() == expected_value"
packages/universal-agent-context/.augment/context/testing.context.md,211,augment,md,def test_known_bug():,"# Expected to fail | @pytest.mark.xfail(reason=""Known bug"") | def test_known_bug(): |     assert buggy_function() == expected_value | "
packages/universal-agent-context/.augment/context/testing.context.md,212,augment,md,assert buggy_function() == expected_value,"@pytest.mark.xfail(reason=""Known bug"") | def test_known_bug(): |     assert buggy_function() == expected_value |  | # Parametrize test"
packages/universal-agent-context/.augment/context/testing.context.md,433,augment,md,"**Note:** Good tests are fast, isolated, repeatable, and self-validating. Write tests that give you confidence to refactor and deploy.","--- |  | **Note:** Good tests are fast, isolated, repeatable, and self-validating. Write tests that give you confidence to refactor and deploy. | "
packages/universal-agent-context/.augment/context/deployment.context.md,25,augment,md,DEBUG=true,# .env.development | ENVIRONMENT=development | DEBUG=true | LOG_LEVEL=DEBUG | REDIS_URL=redis://localhost:6379
packages/universal-agent-context/.augment/context/deployment.context.md,37,augment,md,DEBUG=false,# .env.staging | ENVIRONMENT=staging | DEBUG=false | LOG_LEVEL=INFO | REDIS_URL=redis://staging-redis:6379
packages/universal-agent-context/.augment/context/deployment.context.md,49,augment,md,DEBUG=false,# .env.production | ENVIRONMENT=production | DEBUG=false | LOG_LEVEL=WARNING | REDIS_URL=redis://prod-redis:6379
packages/universal-agent-context/.augment/context/deployment.context.md,223,augment,md,#### Debugging,``` |  | #### Debugging | ```bash | # Execute command in pod
packages/universal-agent-context/.augment/context/deployment.context.md,310,augment,md,**Debugging:**,- Pod keeps restarting |  | **Debugging:** | ```bash | # 1. Check pod logs
packages/universal-agent-context/.augment/context/deployment.context.md,337,augment,md,**Debugging:**,- Cannot pull container image |  | **Debugging:** | ```bash | # 1. Check image name
packages/universal-agent-context/.augment/context/deployment.context.md,361,augment,md,**Debugging:**,- Cannot connect to service |  | **Debugging:** | ```bash | # 1. Check service
packages/universal-agent-context/.augment/context/deployment.context.md,373,augment,md,kubectl run -it --rm debug --image=busybox --restart=Never -n tta-staging -- wget -O- http://tta-api:8000/health, | # 4. Test service internally | kubectl run -it --rm debug --image=busybox --restart=Never -n tta-staging -- wget -O- http://tta-api:8000/health | ``` | 
packages/universal-agent-context/.augment/context/deployment.context.md,470,augment,md,**Note:** Always test deployments in staging before production. Monitor closely and be ready to rollback if issues arise.,--- |  | **Note:** Always test deployments in staging before production. Monitor closely and be ready to rollback if issues arise. | 
packages/universal-agent-context/.augment/context/integration.context.md,470,augment,md,**Note:** Integration tests should be run before staging deployment to ensure all components work together correctly.,--- |  | **Note:** Integration tests should be run before staging deployment to ensure all components work together correctly. |  | 
packages/universal-agent-context/.augment/context/debugging.context.md,1,augment,md,# Context: Debugging,# Context: Debugging |  | **Purpose:** Systematic debugging workflows and troubleshooting strategies for TTA development.
packages/universal-agent-context/.augment/context/debugging.context.md,3,augment,md,**Purpose:** Systematic debugging workflows and troubleshooting strategies for TTA development.,"# Context: Debugging |  | **Purpose:** Systematic debugging workflows and troubleshooting strategies for TTA development. |  | **When to Use:** When investigating bugs, errors, test failures, or unexpected behavior."
packages/universal-agent-context/.augment/context/debugging.context.md,5,augment,md,"**When to Use:** When investigating bugs, errors, test failures, or unexpected behavior.","**Purpose:** Systematic debugging workflows and troubleshooting strategies for TTA development. |  | **When to Use:** When investigating bugs, errors, test failures, or unexpected behavior. |  | ---"
packages/universal-agent-context/.augment/context/debugging.context.md,9,augment,md,## Debugging Workflow,--- |  | ## Debugging Workflow |  | ### 1. Reproduce the Issue
packages/universal-agent-context/.augment/context/debugging.context.md,30,augment,md,## Bug Report,**Example:** | ```markdown | ## Bug Report |  | **Description:** Session state not persisting after player action
packages/universal-agent-context/.augment/context/debugging.context.md,55,augment,md,- See if bug still occurs,#### Binary Search | - Comment out half the code | - See if bug still occurs | - Repeat until isolated | 
packages/universal-agent-context/.augment/context/debugging.context.md,66,augment,md,"logger.debug(f""Session state before: {session.state}"")","async def process_action(action: PlayerAction, session: Session): |     logger.info(f""Processing action: {action.type}"") |     logger.debug(f""Session state before: {session.state}"") |      |     result = await execute_action(action)"
packages/universal-agent-context/.augment/context/debugging.context.md,69,augment,md,"logger.debug(f""Action result: {result}"")","     |     result = await execute_action(action) |     logger.debug(f""Action result: {result}"") |      |     await update_session(session, result)"
packages/universal-agent-context/.augment/context/debugging.context.md,72,augment,md,"logger.debug(f""Session state after: {session.state}"")","     |     await update_session(session, result) |     logger.debug(f""Session state after: {session.state}"") |      |     return result"
packages/universal-agent-context/.augment/context/debugging.context.md,77,augment,md,#### Use Debugger,``` |  | #### Use Debugger | ```python | # Add breakpoint
packages/universal-agent-context/.augment/context/debugging.context.md,82,augment,md,# Or use IDE debugger,import pdb; pdb.set_trace() |  | # Or use IDE debugger | # Set breakpoint in IDE and run in debug mode | ```
packages/universal-agent-context/.augment/context/debugging.context.md,83,augment,md,# Set breakpoint in IDE and run in debug mode, | # Or use IDE debugger | # Set breakpoint in IDE and run in debug mode | ``` | 
packages/universal-agent-context/.augment/context/debugging.context.md,98,augment,md,**Goal:** Understand why the bug occurs,### 3. Analyze the Root Cause |  | **Goal:** Understand why the bug occurs |  | **Common Root Causes:**
packages/universal-agent-context/.augment/context/debugging.context.md,225,augment,md,**Goal:** Ensure the bug is fixed and no regressions,### 5. Verify the Fix |  | **Goal:** Ensure the bug is fixed and no regressions |  | **Verification Steps:**
packages/universal-agent-context/.augment/context/debugging.context.md,228,augment,md,1. Run the reproduction steps - bug should be gone, | **Verification Steps:** | 1. Run the reproduction steps - bug should be gone | 2. Run all tests - no regressions | 3. Run quality gates - all pass
packages/universal-agent-context/.augment/context/debugging.context.md,236,augment,md,# 1. Reproduce bug - should be fixed,**Example:** | ```bash | # 1. Reproduce bug - should be fixed | python reproduce_bug.py | 
packages/universal-agent-context/.augment/context/debugging.context.md,237,augment,md,python reproduce_bug.py,```bash | # 1. Reproduce bug - should be fixed | python reproduce_bug.py |  | # 2. Run tests
packages/universal-agent-context/.augment/context/debugging.context.md,257,augment,md,## Common TTA Debugging Scenarios,--- |  | ## Common TTA Debugging Scenarios |  | ### Scenario 1: Redis Connection Issues
packages/universal-agent-context/.augment/context/debugging.context.md,266,augment,md,**Debugging Steps:**,- Session state not persisting |  | **Debugging Steps:** | ```bash | # 1. Check Redis is running
packages/universal-agent-context/.augment/context/debugging.context.md,295,augment,md,**Debugging Steps:**,- Transaction errors |  | **Debugging Steps:** | ```python | # 1. Test query in Neo4j Browser
packages/universal-agent-context/.augment/context/debugging.context.md,302,augment,md,"logger.debug(f""Running query: {query}"")"," | # 2. Add logging | logger.debug(f""Running query: {query}"") | logger.debug(f""Parameters: {parameters}"") | "
packages/universal-agent-context/.augment/context/debugging.context.md,303,augment,md,"logger.debug(f""Parameters: {parameters}"")","# 2. Add logging | logger.debug(f""Running query: {query}"") | logger.debug(f""Parameters: {parameters}"") |  | # 3. Check query result"
packages/universal-agent-context/.augment/context/debugging.context.md,308,augment,md,"logger.debug(f""Query returned {len(records)} records"")","result = session.run(query, **parameters) | records = list(result) | logger.debug(f""Query returned {len(records)} records"") |  | # 4. Verify data exists"
packages/universal-agent-context/.augment/context/debugging.context.md,329,augment,md,**Debugging Steps:**,- Tests hang indefinitely |  | **Debugging Steps:** | ```python | # 1. Check pytest-asyncio marker
packages/universal-agent-context/.augment/context/debugging.context.md,365,augment,md,**Debugging Steps:**,- Type checking errors |  | **Debugging Steps:** | ```bash | # 1. Identify which gate failed
packages/universal-agent-context/.augment/context/debugging.context.md,398,augment,md,## Debugging Tools,--- |  | ## Debugging Tools |  | ### 1. Python Debugger (pdb)
packages/universal-agent-context/.augment/context/debugging.context.md,400,augment,md,### 1. Python Debugger (pdb),## Debugging Tools |  | ### 1. Python Debugger (pdb) | ```python | import pdb
packages/universal-agent-context/.augment/context/debugging.context.md,404,augment,md,def buggy_function():,import pdb |  | def buggy_function(): |     x = 10 |     y = 20
packages/universal-agent-context/.augment/context/debugging.context.md,407,augment,md,pdb.set_trace()  # Debugger will stop here,    x = 10 |     y = 20 |     pdb.set_trace()  # Debugger will stop here |     result = x + y |     return result
packages/universal-agent-context/.augment/context/debugging.context.md,426,augment,md,"level=logging.DEBUG,","# Configure logging | logging.basicConfig( |     level=logging.DEBUG, |     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s' | )"
packages/universal-agent-context/.augment/context/debugging.context.md,433,augment,md,"logger.debug(""Debug message"")"," | # Use logging | logger.debug(""Debug message"") | logger.info(""Info message"") | logger.warning(""Warning message"")"
packages/universal-agent-context/.augment/context/debugging.context.md,440,augment,md,### 3. IDE Debugger,"``` |  | ### 3. IDE Debugger | - **VS Code:** Set breakpoints, run in debug mode | - **PyCharm:** Set breakpoints, run in debug mode"
packages/universal-agent-context/.augment/context/debugging.context.md,441,augment,md,"- **VS Code:** Set breakpoints, run in debug mode"," | ### 3. IDE Debugger | - **VS Code:** Set breakpoints, run in debug mode | - **PyCharm:** Set breakpoints, run in debug mode | - **Advantages:** Visual debugging, variable inspection, call stack"
packages/universal-agent-context/.augment/context/debugging.context.md,442,augment,md,"- **PyCharm:** Set breakpoints, run in debug mode","### 3. IDE Debugger | - **VS Code:** Set breakpoints, run in debug mode | - **PyCharm:** Set breakpoints, run in debug mode | - **Advantages:** Visual debugging, variable inspection, call stack | "
packages/universal-agent-context/.augment/context/debugging.context.md,443,augment,md,"- **Advantages:** Visual debugging, variable inspection, call stack","- **VS Code:** Set breakpoints, run in debug mode | - **PyCharm:** Set breakpoints, run in debug mode | - **Advantages:** Visual debugging, variable inspection, call stack |  | ### 4. Print Debugging"
packages/universal-agent-context/.augment/context/debugging.context.md,445,augment,md,### 4. Print Debugging,"- **Advantages:** Visual debugging, variable inspection, call stack |  | ### 4. Print Debugging | ```python | # Quick and dirty debugging"
packages/universal-agent-context/.augment/context/debugging.context.md,447,augment,md,# Quick and dirty debugging,"### 4. Print Debugging | ```python | # Quick and dirty debugging | print(f""DEBUG: variable = {variable}"") | print(f""DEBUG: type = {type(variable)}"")"
packages/universal-agent-context/.augment/context/debugging.context.md,448,augment,md,"print(f""DEBUG: variable = {variable}"")","```python | # Quick and dirty debugging | print(f""DEBUG: variable = {variable}"") | print(f""DEBUG: type = {type(variable)}"") | print(f""DEBUG: dir = {dir(variable)}"")"
packages/universal-agent-context/.augment/context/debugging.context.md,449,augment,md,"print(f""DEBUG: type = {type(variable)}"")","# Quick and dirty debugging | print(f""DEBUG: variable = {variable}"") | print(f""DEBUG: type = {type(variable)}"") | print(f""DEBUG: dir = {dir(variable)}"") | ```"
packages/universal-agent-context/.augment/context/debugging.context.md,450,augment,md,"print(f""DEBUG: dir = {dir(variable)}"")","print(f""DEBUG: variable = {variable}"") | print(f""DEBUG: type = {type(variable)}"") | print(f""DEBUG: dir = {dir(variable)}"") | ``` | "
packages/universal-agent-context/.augment/context/debugging.context.md,458,augment,md,âœ… Reproduce the bug reliably, | ### DO: | âœ… Reproduce the bug reliably   | âœ… Add logging to understand flow   | âœ… Write test to catch regression  
packages/universal-agent-context/.augment/context/debugging.context.md,464,augment,md,âœ… Use debugger for complex issues,âœ… Document the fix   | âœ… Verify no regressions   | âœ… Use debugger for complex issues |  | ### DON'T:
packages/universal-agent-context/.augment/context/debugging.context.md,470,augment,md,"âŒ Commit debugging code (print statements, pdb)","âŒ Skip writing regression test   | âŒ Fix symptoms without understanding root cause   | âŒ Commit debugging code (print statements, pdb)   | âŒ Ignore related issues   | âŒ Skip verification step"
packages/universal-agent-context/.augment/context/debugging.context.md,484,augment,md,- Python Debugger: https://docs.python.org/3/library/pdb.html, | ### External Resources | - Python Debugger: https://docs.python.org/3/library/pdb.html | - pytest: https://docs.pytest.org/ | - Redis Debugging: https://redis.io/docs/manual/cli/
packages/universal-agent-context/.augment/context/debugging.context.md,486,augment,md,- Redis Debugging: https://redis.io/docs/manual/cli/,- Python Debugger: https://docs.python.org/3/library/pdb.html | - pytest: https://docs.pytest.org/ | - Redis Debugging: https://redis.io/docs/manual/cli/ | - Neo4j Debugging: https://neo4j.com/docs/cypher-manual/ | 
packages/universal-agent-context/.augment/context/debugging.context.md,487,augment,md,- Neo4j Debugging: https://neo4j.com/docs/cypher-manual/,- pytest: https://docs.pytest.org/ | - Redis Debugging: https://redis.io/docs/manual/cli/ | - Neo4j Debugging: https://neo4j.com/docs/cypher-manual/ |  | ---
packages/universal-agent-context/.augment/context/debugging.context.md,491,augment,md,"**Note:** Systematic debugging saves time. Follow the workflow, document findings, and add tests to prevent regressions.","--- |  | **Note:** Systematic debugging saves time. Follow the workflow, document findings, and add tests to prevent regressions. |  | "
packages/universal-agent-context/.augment/context/conversation_manager.py,150,augment,py,"logger.debug(f""Discovered {len(instruction_files)} instruction files"")"," |         instruction_files = list(self.instructions_dir.glob(""*.instructions.md"")) |         logger.debug(f""Discovered {len(instruction_files)} instruction files"") |         return instruction_files | "
packages/universal-agent-context/.augment/context/conversation_manager.py,319,augment,py,logger.debug(,"                relevant.append(parsed) |  |         logger.debug( |             f""Found {len(relevant)} relevant instructions for file: {current_file or 'global'}"" |         )"
packages/universal-agent-context/.augment/context/conversation_manager.py,360,augment,py,"logger.debug(f""Discovered {len(memory_files)} memory files"")","                memory_files.extend(subdir.glob(""*.memory.md"")) |  |         logger.debug(f""Discovered {len(memory_files)} memory files"") |         return memory_files | "
packages/universal-agent-context/.augment/context/conversation_manager.py,556,augment,py,logger.debug(,"        result = scored_memories[:max_memories] |  |         logger.debug( |             f""Found {len(result)} relevant memories (component={component}, tags={tags}, category={category})"" |         )"
packages/universal-agent-context/.augment/context/conversation_manager.py,679,augment,py,logger.debug(,"        context.current_tokens += tokens |  |         logger.debug( |             f""Added {role} message ({tokens} tokens) to {session_id}. "" |             f""Utilization: {context.utilization:.1%}"""
packages/universal-agent-context/.augment/context/security.context.md,276,augment,md,"logger.debug(f""API key: {api_key}"")","# Log sensitive data | logger.info(f""User login: {username}, password: {password}"") | logger.debug(f""API key: {api_key}"") | ``` | "
packages/universal-agent-context/.augment/context/security.context.md,283,augment,md,"logger.debug(f""API key: {'*' * 8}"")  # Redacted","# Never log sensitive data | logger.info(f""User login: {username}"") | logger.debug(f""API key: {'*' * 8}"")  # Redacted |  | # Use structured logging with redaction"
packages/universal-agent-context/.augment/context/security.context.md,543,augment,md,**Note:** Security is not a one-time task. Regular security reviews and updates are essential.,--- |  | **Note:** Security is not a one-time task. Regular security reviews and updates are essential. |  | 
packages/universal-agent-context/.augment/context/sessions/coverage-improvement-orchestration-2025-10-20.json,56,augment,json,"""content"": ""TASK COMPLETE: Orchestration coverage improvement finished. Final results: 21.4% \u2192 49.4% (+28%), 82 tests (100% pass rate), 3 test files created. Summary documented in docs/development/coverage-improvement-orchestration-summary.md. Component ready for dev stage. Staging requires additional 20.6% coverage. Demonstrated successful use of Priority 2 agentic primitives (QA chat mode, test-coverage workflow, AI context tracking, debugging helper)."",","    { |       ""role"": ""user"", |       ""content"": ""TASK COMPLETE: Orchestration coverage improvement finished. Final results: 21.4% \u2192 49.4% (+28%), 82 tests (100% pass rate), 3 test files created. Summary documented in docs/development/coverage-improvement-orchestration-summary.md. Component ready for dev stage. Staging requires additional 20.6% coverage. Demonstrated successful use of Priority 2 agentic primitives (QA chat mode, test-coverage workflow, AI context tracking, debugging helper)."", |       ""timestamp"": ""2025-10-20T20:54:38.976135"", |       ""metadata"": {},"
packages/universal-agent-context/.augment/context/sessions/integrated-workflow-2025-10-20.json,72,augment,json,"""content"": ""PRIORITY 2 ENHANCEMENTS COMPLETE: Created 5 chat modes (architect, backend-dev, frontend-dev, qa-engineer, devops), 5 context helpers (debugging, refactoring, performance, security, integration), and 5 agentic workflows (component-promotion, bug-fix, feature-implementation, test-coverage-improvement, quality-gate-fix). All files adapted to TTA's specific context including component maturity workflow, quality gates, Phase 1 primitives, and TTA tech stack. Total: 15 new files created for Priority 2 enhancements (~4,500 lines of comprehensive documentation and guidance)."",","    { |       ""role"": ""user"", |       ""content"": ""PRIORITY 2 ENHANCEMENTS COMPLETE: Created 5 chat modes (architect, backend-dev, frontend-dev, qa-engineer, devops), 5 context helpers (debugging, refactoring, performance, security, integration), and 5 agentic workflows (component-promotion, bug-fix, feature-implementation, test-coverage-improvement, quality-gate-fix). All files adapted to TTA's specific context including component maturity workflow, quality gates, Phase 1 primitives, and TTA tech stack. Total: 15 new files created for Priority 2 enhancements (~4,500 lines of comprehensive documentation and guidance)."", |       ""timestamp"": ""2025-10-20T20:09:26.157058"", |       ""metadata"": {},"
packages/universal-agent-context/.augment/context/sessions/integrated-workflow-2025-10-20.json,80,augment,json,"""content"": ""PRIORITY 2 ENHANCEMENTS COMPLETE: Created .augment/chatmodes/ directory with 5 chat mode files (architect, backend-dev, frontend-dev, qa-engineer, devops). Created .augment/context/ directory with 5 context helper files (debugging, refactoring, performance, security, integration). Created .augment/workflows/ directory with 5 agentic workflow files (component-promotion, bug-fix, feature-implementation, test-coverage-improvement, quality-gate-fix). All files adapted to TTA's specific context (component maturity workflow, quality gates, Phase 1 primitives, TTA tech stack). Total: 15 new files created for Priority 2 enhancements."",","    { |       ""role"": ""user"", |       ""content"": ""PRIORITY 2 ENHANCEMENTS COMPLETE: Created .augment/chatmodes/ directory with 5 chat mode files (architect, backend-dev, frontend-dev, qa-engineer, devops). Created .augment/context/ directory with 5 context helper files (debugging, refactoring, performance, security, integration). Created .augment/workflows/ directory with 5 agentic workflow files (component-promotion, bug-fix, feature-implementation, test-coverage-improvement, quality-gate-fix). All files adapted to TTA's specific context (component maturity workflow, quality gates, Phase 1 primitives, TTA tech stack). Total: 15 new files created for Priority 2 enhancements."", |       ""timestamp"": ""2025-10-20T20:27:54.359490"", |       ""metadata"": {},"
packages/universal-agent-context/.augment/memory/README.md,8,augment,md,"- **Implementation Failures**: Failed approaches, bugs, and mistakes to avoid"," | The memory system provides a structured way to document: | - **Implementation Failures**: Failed approaches, bugs, and mistakes to avoid | - **Successful Patterns**: Proven solutions, best practices, and effective techniques | - **Architectural Decisions**: Design choices, technology selections, and strategic directions"
packages/universal-agent-context/.augment/memory/README.md,33,augment,md,"**Purpose**: Document failed approaches, bugs, and mistakes to prevent repetition","### Implementation Failures |  | **Purpose**: Document failed approaches, bugs, and mistakes to prevent repetition |  | **When to Create**:"
packages/universal-agent-context/.augment/memory/README.md,36,augment,md,- After encountering a significant bug or error, | **When to Create**: | - After encountering a significant bug or error | - When an approach fails after substantial effort | - When discovering a common pitfall or anti-pattern
packages/universal-agent-context/.augment/memory/README.md,39,augment,md,- After debugging a complex issue,- When an approach fails after substantial effort | - When discovering a common pitfall or anti-pattern | - After debugging a complex issue |  | **What to Include**:
packages/universal-agent-context/.augment/memory/component-failures.memory.md,107,augment,md,- Treat test failures as bugs,- Never commit with failing tests | - Use CI/CD to catch failures early | - Treat test failures as bugs |  | **Example:**
packages/universal-agent-context/.augment/memory/component-failures.memory.md,238,augment,md,- Production bugs,- Integration issues discovered late | - Staging quality gates fail | - Production bugs |  | **Correct Approach:**
packages/universal-agent-context/.augment/memory/component-failures.memory.md,325,augment,md,- Error handling bugs in production, | **Why It Fails:** | - Error handling bugs in production | - Poor user experience | - Difficult to debug issues
packages/universal-agent-context/.augment/memory/component-failures.memory.md,327,augment,md,- Difficult to debug issues,- Error handling bugs in production | - Poor user experience | - Difficult to debug issues | - Low confidence in error recovery | 
packages/universal-agent-context/.augment/memory/component-failures.memory.md,448,augment,md,**Note:** This file should be updated whenever a component fails quality gates or when new anti-patterns are discovered.,--- |  | **Note:** This file should be updated whenever a component fails quality gates or when new anti-patterns are discovered. | 
packages/universal-agent-context/.augment/memory/testing-patterns.memory.md,586,augment,md,**Note:** This file should be updated with new testing patterns as they are discovered and validated.,--- |  | **Note:** This file should be updated with new testing patterns as they are discovered and validated. | 
packages/universal-agent-context/.augment/memory/workflow-learnings.memory.md,325,augment,md,**Note:** This file should be updated regularly with new learnings from workflow usage and development.,--- |  | **Note:** This file should be updated regularly with new learnings from workflow usage and development. | 
packages/universal-agent-context/.augment/memory/quality-gates.memory.md,150,augment,md,- **Production:** Maximize reliability and minimize bugs,"- **Development:** Focus on core functionality, allow rapid iteration | - **Staging:** Ensure integration points are tested | - **Production:** Maximize reliability and minimize bugs |  | **Adjustment Strategy:**"
packages/universal-agent-context/.augment/memory/quality-gates.memory.md,208,augment,md,- Reduces debugging time,"- Developers know exactly what failed | - Clear path to resolution | - Reduces debugging time |  | **Best Practice:** Always include threshold, actual value, and actionable details"
packages/universal-agent-context/.augment/memory/quality-gates.memory.md,465,augment,md,**Note:** This file should be updated with new quality gate insights and optimizations as they are discovered.,--- |  | **Note:** This file should be updated with new quality gate insights and optimizations as they are discovered. | 
packages/universal-agent-context/.augment/memory/successful-patterns/phase2-implementation-2025-10-22.memory.md,25,augment,md,"- **Benefit:** Faster implementation, consistent code style, reduced bugs","- Replicated proven patterns: caching, YAML parsing, file discovery | - Maintained consistency with existing codebase architecture | - **Benefit:** Faster implementation, consistent code style, reduced bugs |  | ### Pattern 2: Test-Driven Development"
packages/universal-agent-context/.augment/memory/successful-patterns/phase2-implementation-2025-10-22.memory.md,31,augment,md,"- **Benefit:** Caught bugs early, high confidence in implementation","- Tests written alongside implementation | - **Metrics:** 19/19 tests passing, >90% coverage, <5 min to fix issues | - **Benefit:** Caught bugs early, high confidence in implementation |  | ### Pattern 3: Incremental Quality Gate Validation"
packages/universal-agent-context/.augment/memory/successful-patterns/phase2-implementation-2025-10-22.memory.md,73,augment,md,2. Comprehensive tests caught bugs early,**What went well:** | 1. Following existing patterns accelerated implementation | 2. Comprehensive tests caught bugs early | 3. Incremental quality gates prevented technical debt | 4. Template-driven approach ensured consistency
packages/universal-agent-context/.augment/memory/successful-patterns/phase2-implementation-2025-10-22.memory.md,111,augment,md,- Reduced debugging time through captured learnings, | **Long-term:** | - Reduced debugging time through captured learnings | - Improved AI agent effectiveness through better context | - Knowledge preservation across sessions
packages/universal-agent-context/.augment/memory/architectural-decisions/agentic-primitives-implementation-2025-10-22.memory.md,41,augment,md,- Debugging guides,   - Testing commands and fixtures |    - Deployment procedures |    - Debugging guides |  | 4. **Chat Mode System** (`.chatmode.md` files)
packages/universal-agent-context/.augment/memory/architectural-decisions/agentic-primitives-implementation-2025-10-22.memory.md,142,augment,md,- Root causes of bugs and errors,1. **Implementation Failures**: Prevent repeating mistakes by documenting: |    - Failed approaches and why they failed |    - Root causes of bugs and errors |    - Resolutions and preventive measures | 
packages/universal-agent-context/.augment/memory/architectural-decisions/agentic-primitives-implementation-2025-10-22.memory.md,161,augment,md,- Debugging tools and techniques,   - Testing fixtures and markers |    - Deployment steps and environments |    - Debugging tools and techniques |  | 2. **Reduce Cognitive Load**: Eliminate need to:
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,6,augment,md,"tags: [agentic-primitives, phase2, memory-matching, linting, testing, debugging]","component: global | severity: medium | tags: [agentic-primitives, phase2, memory-matching, linting, testing, debugging] | --- | "
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,17,augment,md,**Total Debugging Time:** ~30 minutes,"**Timeline:** 2025-10-22 | **Component:** Agentic Primitives Phase 2 (Memory System, Context Helpers, Chat Modes) | **Total Debugging Time:** ~30 minutes |  | ## Challenge 1: Memory Matching with No Filters Returned Zero Results"
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,82,augment,md,1. Left debugging comment in code, | ### Root Cause | 1. Left debugging comment in code | 2. Early returns for validation created many return points | 3. Imported fixtures that weren't used in all test functions
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,120,augment,md,Comprehensive test suite catches bugs early. Writing tests alongside implementation is crucial., | ### Lesson Learned | Comprehensive test suite catches bugs early. Writing tests alongside implementation is crucial. |  | ## Challenge 4: Type Checking Warnings (Pre-existing)
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,151,augment,md,### Total Debugging Time: ~30 minutes,- **Low:** 1 (pre-existing type issues) |  | ### Total Debugging Time: ~30 minutes | - Memory matching: 7 minutes | - Linting: 3 minutes
packages/universal-agent-context/.augment/memory/implementation-failures/phase2-challenges-2025-10-22.memory.md,166,augment,md,1. **Test-driven development catches bugs early** - All issues caught by automated checks,"### Key Takeaways |  | 1. **Test-driven development catches bugs early** - All issues caught by automated checks | 2. **Incremental quality gates prevent accumulation** - Fixed issues immediately | 3. **Base case handling is critical** - Always consider ""no filter"" scenarios"
packages/universal-agent-context/.augment/chatmodes/devops.chatmode.md,486,augment,md,"**Note:** This chat mode focuses on deployment and infrastructure. For application code, delegate to backend-dev or frontend-dev. For testing, delegate to qa-engineer.","--- |  | **Note:** This chat mode focuses on deployment and infrastructure. For application code, delegate to backend-dev or frontend-dev. For testing, delegate to qa-engineer. |  | "
packages/universal-agent-context/.augment/chatmodes/backend-implementer.chatmode.md,79,augment,md,- âœ… Fix bugs and issues,- âœ… Execute development commands | - âœ… Search and analyze codebase | - âœ… Fix bugs and issues | - âœ… Refactor code | - âœ… Store implementation decisions
packages/universal-agent-context/.augment/chatmodes/backend-implementer.chatmode.md,171,augment,md,### Bug Fix,``` |  | ### Bug Fix | ```markdown | **Task**: Fix failing test
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,17,augment,md,- **Bug Detection:** Finding and documenting issues,"- **Test Automation:** Building automated test suites | - **Validation:** Verifying functionality, performance, security | - **Bug Detection:** Finding and documenting issues |  | ---"
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,163,augment,md,### 4. Bug Detection and Validation,"- ""Validate all quality gates pass before production"" |  | ### 4. Bug Detection and Validation | **When to engage:** | - Investigating bug reports"
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,165,augment,md,- Investigating bug reports,### 4. Bug Detection and Validation | **When to engage:** | - Investigating bug reports | - Validating bug fixes | - Regression testing
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,166,augment,md,- Validating bug fixes,**When to engage:** | - Investigating bug reports | - Validating bug fixes | - Regression testing | - Exploratory testing
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,171,augment,md,- Reproduce bug reliably, | **Key considerations:** | - Reproduce bug reliably | - Write test to catch regression | - Verify fix doesn't break other functionality
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,174,augment,md,- Document bug and fix,- Write test to catch regression | - Verify fix doesn't break other functionality | - Document bug and fix |  | **Example tasks:**
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,177,augment,md,"- ""Investigate session state corruption bug"""," | **Example tasks:** | - ""Investigate session state corruption bug"" | - ""Validate fix for AI response timeout"" | - ""Perform regression testing after refactoring"""
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,190,augment,md,âœ… Find and document bugs,âœ… Run quality gates   | âœ… Validate functionality   | âœ… Find and document bugs   | âœ… Improve test coverage   | âœ… Ensure quality standards  
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,199,augment,md,âŒ Fix implementation bugs (delegate to backend-dev/frontend-dev),âŒ Make architectural decisions (consult architect)   | âŒ Deploy to production (delegate to devops)   | âŒ Fix implementation bugs (delegate to backend-dev/frontend-dev)   | âŒ Design system architecture (consult architect) | 
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,204,augment,md,"- **Backend Dev:** Implementation details, bug fixes","### When to Consult: | - **Architect:** Testability requirements, integration test scenarios | - **Backend Dev:** Implementation details, bug fixes | - **Frontend Dev:** UI testing, accessibility testing | - **DevOps:** Test environment setup, CI/CD integration"
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,491,augment,md,# 3. Debug test,# AssertionError: assert None is not None |  | # 3. Debug test | uv run pytest tests/test_component.py::test_create_session -vv | 
packages/universal-agent-context/.augment/chatmodes/qa-engineer.chatmode.md,562,augment,md,"**Note:** This chat mode focuses on testing and quality assurance. For implementation fixes, delegate to backend-dev or frontend-dev. For deployment, delegate to devops.","--- |  | **Note:** This chat mode focuses on testing and quality assurance. For implementation fixes, delegate to backend-dev or frontend-dev. For deployment, delegate to devops. |  | "
packages/universal-agent-context/.augment/chatmodes/frontend-dev.chatmode.md,491,augment,md,1. Reproduce bug locally, | **Steps:** | 1. Reproduce bug locally | 2. Identify root cause | 3. Fix issue
packages/universal-agent-context/.augment/chatmodes/frontend-dev.chatmode.md,499,augment,md,// Bug: Narrative not updating after action,**Example:** | ```typescript | // Bug: Narrative not updating after action |  | // Before: Missing dependency
packages/universal-agent-context/.augment/chatmodes/frontend-dev.chatmode.md,564,augment,md,"**Note:** This chat mode focuses on frontend implementation. For backend APIs, consult the backend-dev chat mode. For deployment, consult the devops chat mode.","--- |  | **Note:** This chat mode focuses on frontend implementation. For backend APIs, consult the backend-dev chat mode. For deployment, consult the devops chat mode. |  | "
packages/universal-agent-context/.augment/chatmodes/backend-dev.chatmode.md,186,augment,md,âœ… Fix bugs and optimize performance,âœ… Integrate with Redis and Neo4j   | âœ… Write unit and integration tests   | âœ… Fix bugs and optimize performance   | âœ… Refactor code for maintainability   | âœ… Run linting and type checking  
packages/universal-agent-context/.augment/chatmodes/backend-dev.chatmode.md,528,augment,md,"**Note:** This chat mode focuses on backend implementation. For architecture decisions, consult the architect chat mode. For deployment, consult the devops chat mode.","--- |  | **Note:** This chat mode focuses on backend implementation. For architecture decisions, consult the architect chat mode. For deployment, consult the devops chat mode. |  | "
packages/universal-agent-context/.augment/chatmodes/architect.chatmode.md,178,augment,md,âŒ Fix bugs (unless architectural),âŒ Write tests   | âŒ Deploy to production   | âŒ Fix bugs (unless architectural)   | âŒ Optimize specific algorithms   | âŒ Write frontend code  
packages/universal-agent-context/.augment/chatmodes/architect.chatmode.md,187,augment,md,- **Bug fixes:** â†’ backend-dev (unless architectural issue),- **Testing:** â†’ qa-engineer | - **Deployment:** â†’ devops | - **Bug fixes:** â†’ backend-dev (unless architectural issue) | - **Performance tuning:** â†’ backend-dev (after architectural review) | 
packages/universal-agent-context/.augment/chatmodes/architect.chatmode.md,458,augment,md,"**Note:** This chat mode focuses on architecture and design. For implementation, testing, or deployment, switch to the appropriate specialized chat mode.","--- |  | **Note:** This chat mode focuses on architecture and design. For implementation, testing, or deployment, switch to the appropriate specialized chat mode. |  | "
packages/universal-agent-context/.github/copilot-instructions.md,121,config,md,- **bug-fix** - Structured debugging and remediation,- **test-coverage-improvement** - Systematic coverage enhancement | - **component-promotion** - Maturity advancement workflow | - **bug-fix** - Structured debugging and remediation | - **refactoring** - Safe architectural changes with validation | 
packages/universal-agent-context/.github/copilot-instructions.md,151,config,md,"# Redis MCP: Inspect session state, debug cache issues","# Use for multi-step orchestration changes, migration workflows |  | # Redis MCP: Inspect session state, debug cache issues | # Direct access to Redis keys for message coordination debugging | "
packages/universal-agent-context/.github/copilot-instructions.md,152,config,md,# Direct access to Redis keys for message coordination debugging," | # Redis MCP: Inspect session state, debug cache issues | # Direct access to Redis keys for message coordination debugging |  | # Serena Tools:"
packages/universal-agent-context/.github/instructions/data-separation-strategy.md,27,config,md,"Development data (test scenarios, debugging artifacts, experimental agent memories) must be completely isolated from testing, staging, and production environments to prevent:","**Concern**: ""I don't want our memories from the dev process clogging up TTA's agents."" |  | Development data (test scenarios, debugging artifacts, experimental agent memories) must be completely isolated from testing, staging, and production environments to prevent: | - Development noise contaminating AI agent learning | - Test data leaking into production workflows"
packages/universal-agent-context/.github/instructions/data-separation-strategy.md,31,config,md,- Debugging traces appearing in therapeutic sessions,- Test data leaking into production workflows | - Staging snapshots polluting real user experiences | - Debugging traces appearing in therapeutic sessions |  | ## Current State Analysis
packages/universal-agent-context/.github/instructions/data-separation-strategy.md,484,config,md,4. **Clear Debugging**: Know exactly which environment data came from,2. **Simultaneous Environments**: Run dev + test + staging at same time | 3. **Safe Experimentation**: Wipe dev data without fear | 4. **Clear Debugging**: Know exactly which environment data came from | 5. **Agent Purity**: Production agents never see dev test data | 6. **Easy Backup/Restore**: Per-environment snapshots
packages/universal-agent-context/.github/instructions/python-quality-standards.instructions.md,60,config,md,"""B"",    # flake8-bugbear","    ""F"",    # Pyflakes |     ""I"",    # isort |     ""B"",    # flake8-bugbear |     ""C4"",   # flake8-comprehensions |     ""UP"",   # pyupgrade"
packages/universal-agent-context/.github/instructions/ai-context-sessions.md,16,config,md,"**Auto-triggered when**: User mentions multi-session work, complex features, component development, refactoring, or debugging.","# AI Context Session Management |  | **Auto-triggered when**: User mentions multi-session work, complex features, component development, refactoring, or debugging. |  | **Detailed Workflow**: See `.augment/workflows/context-management.workflow.md` for step-by-step patterns."
packages/universal-agent-context/.github/instructions/ai-context-sessions.md,22,config,md,"âœ… **Use for**: Multi-session development, complex features, component development, refactoring, debugging","## When to Use |  | âœ… **Use for**: Multi-session development, complex features, component development, refactoring, debugging |  | âŒ **Don't use for**: Trivial tasks, quick queries, one-off operations, exploratory work, automated workflows"
packages/universal-agent-context/.github/instructions/ai-context-sessions.md,76,config,md,- Debugging across sessions,**See `.augment/workflows/context-management.workflow.md` for detailed patterns:** | - Feature development across multiple sessions | - Debugging across sessions | - Session naming conventions | - Best practices
packages/universal-agent-context/.github/instructions/docker-improvements.md,197,config,md,# Development (generous for debugging):, | ```yaml | # Development (generous for debugging): | deploy: |   resources:
packages/universal-agent-context/.github/instructions/docker-improvements.md,482,config,md,NEO4J_dbms_logs_debug_level: ${LOG_LEVEL:-INFO},      NEO4J_dbms_memory_heap_initial__size: 1G |       NEO4J_dbms_memory_heap_max__size: 2G |       NEO4J_dbms_logs_debug_level: ${LOG_LEVEL:-INFO} |     deploy: |       resources:
packages/universal-agent-context/.github/instructions/docker-improvements.md,562,config,md,NEO4J_dbms_logs_debug_level: WARN,      NEO4J_dbms_memory_heap_initial__size: ${NEO4J_HEAP_INITIAL:-2G} |       NEO4J_dbms_memory_heap_max__size: ${NEO4J_HEAP_MAX:-4G} |       NEO4J_dbms_logs_debug_level: WARN |     secrets: |       - neo4j_auth
packages/universal-agent-context/.github/instructions/graph-db.instructions.md,312,config,md,- **Log Query Failures**: Log failed queries for debugging,- **Retry Transient Errors**: Retry transient connection errors | - **Handle Constraint Violations**: Handle unique constraint violations gracefully | - **Log Query Failures**: Log failed queries for debugging | - **Monitor Performance**: Track query performance metrics | 
packages/universal-agent-context/.github/instructions/serena-code-navigation.md,47,config,md,"- **Example**: Find all pytest decorators, async functions, TODO comments","- **Use**: `search_for_pattern_Serena` for regex-based searches | - **When**: Looking for specific code patterns across files | - **Example**: Find all pytest decorators, async functions, TODO comments |  | ### 5. Precise Code Editing"
packages/universal-agent-context/.github/chatmodes/devops.chatmode.md,488,config,md,### TTA Research Notebook,"## Research Integration |  | ### TTA Research Notebook | Consult the research notebook for DevOps-specific AI tooling guidance: | - **Agent CLI Runtimes:** Execution outside IDE for CI/CD integration (""Outer Loop"")"
packages/universal-agent-context/.github/chatmodes/devops.chatmode.md,489,config,md,Consult the research notebook for DevOps-specific AI tooling guidance:," | ### TTA Research Notebook | Consult the research notebook for DevOps-specific AI tooling guidance: | - **Agent CLI Runtimes:** Execution outside IDE for CI/CD integration (""Outer Loop"") | - **Agent Package Manager (APM):** Managing and distributing agent primitives across teams"
packages/universal-agent-context/.github/chatmodes/devops.chatmode.md,495,config,md,**Query the research notebook:**,"- **Context Portability:** AGENTS.md standards for cross-tool compatibility |  | **Query the research notebook:** | ```bash | uv run python scripts/query_notebook_helper.py ""How should Agent CLI runtimes integrate with CI/CD?"""
packages/universal-agent-context/.github/chatmodes/devops.chatmode.md,497,config,md,"uv run python scripts/query_notebook_helper.py ""How should Agent CLI runtimes integrate with CI/CD?""","**Query the research notebook:** | ```bash | uv run python scripts/query_notebook_helper.py ""How should Agent CLI runtimes integrate with CI/CD?"" | ``` | "
packages/universal-agent-context/.github/chatmodes/devops.chatmode.md,522,config,md,"**Note:** This chat mode focuses on deployment and infrastructure. For application code, delegate to backend-dev or frontend-dev. For testing, delegate to qa-engineer.","--- |  | **Note:** This chat mode focuses on deployment and infrastructure. For application code, delegate to backend-dev or frontend-dev. For testing, delegate to qa-engineer. | "
packages/universal-agent-context/.github/chatmodes/backend-implementer.chatmode.md,79,config,md,- âœ… Fix bugs and issues,- âœ… Execute development commands | - âœ… Search and analyze codebase | - âœ… Fix bugs and issues | - âœ… Refactor code | - âœ… Store implementation decisions
packages/universal-agent-context/.github/chatmodes/backend-implementer.chatmode.md,171,config,md,### Bug Fix,``` |  | ### Bug Fix | ```markdown | **Task**: Fix failing test
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,31,config,md,- **Bug Detection:** Finding and documenting issues,"- **Test Automation:** Building automated test suites | - **Validation:** Verifying functionality, performance, security | - **Bug Detection:** Finding and documenting issues |  | ---"
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,177,config,md,### 4. Bug Detection and Validation,"- ""Validate all quality gates pass before production"" |  | ### 4. Bug Detection and Validation | **When to engage:** | - Investigating bug reports"
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,179,config,md,- Investigating bug reports,### 4. Bug Detection and Validation | **When to engage:** | - Investigating bug reports | - Validating bug fixes | - Regression testing
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,180,config,md,- Validating bug fixes,**When to engage:** | - Investigating bug reports | - Validating bug fixes | - Regression testing | - Exploratory testing
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,185,config,md,- Reproduce bug reliably, | **Key considerations:** | - Reproduce bug reliably | - Write test to catch regression | - Verify fix doesn't break other functionality
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,188,config,md,- Document bug and fix,- Write test to catch regression | - Verify fix doesn't break other functionality | - Document bug and fix |  | **Example tasks:**
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,191,config,md,"- ""Investigate session state corruption bug"""," | **Example tasks:** | - ""Investigate session state corruption bug"" | - ""Validate fix for AI response timeout"" | - ""Perform regression testing after refactoring"""
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,204,config,md,âœ… Find and document bugs,âœ… Run quality gates | âœ… Validate functionality | âœ… Find and document bugs | âœ… Improve test coverage | âœ… Ensure quality standards
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,213,config,md,âŒ Fix implementation bugs (delegate to backend-dev/frontend-dev),âŒ Make architectural decisions (consult architect) | âŒ Deploy to production (delegate to devops) | âŒ Fix implementation bugs (delegate to backend-dev/frontend-dev) | âŒ Design system architecture (consult architect) | 
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,218,config,md,"- **Backend Dev:** Implementation details, bug fixes","### When to Consult: | - **Architect:** Testability requirements, integration test scenarios | - **Backend Dev:** Implementation details, bug fixes | - **Frontend Dev:** UI testing, accessibility testing | - **DevOps:** Test environment setup, CI/CD integration"
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,505,config,md,# 3. Debug test,# AssertionError: assert None is not None |  | # 3. Debug test | uv run pytest tests/test_component.py::test_create_session -vv | 
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,556,config,md,### TTA Research Notebook,## Research Integration |  | ### TTA Research Notebook | Consult the research notebook for testing AI components: | - **Validation Gates:** Human oversight checkpoints in agentic workflows
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,557,config,md,Consult the research notebook for testing AI components:, | ### TTA Research Notebook | Consult the research notebook for testing AI components: | - **Validation Gates:** Human oversight checkpoints in agentic workflows | - **Agent Testing Patterns:** How to test AI agent behavior and outputs
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,566,config,md,"uv run python scripts/query_notebook_helper.py ""How should I test agent primitive workflows?""","```bash | # Testing patterns | uv run python scripts/query_notebook_helper.py ""How should I test agent primitive workflows?"" |  | # Validation strategies"
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,569,config,md,"uv run python scripts/query_notebook_helper.py ""What validation gates should agentic workflows include?"""," | # Validation strategies | uv run python scripts/query_notebook_helper.py ""What validation gates should agentic workflows include?"" | ``` | "
packages/universal-agent-context/.github/chatmodes/qa-engineer.chatmode.md,602,config,md,"**Note:** This chat mode focuses on testing and quality assurance. For implementation fixes, delegate to backend-dev or frontend-dev. For deployment, delegate to devops.","--- |  | **Note:** This chat mode focuses on testing and quality assurance. For implementation fixes, delegate to backend-dev or frontend-dev. For deployment, delegate to devops. | "
packages/universal-agent-context/.github/chatmodes/frontend-dev.chatmode.md,505,config,md,1. Reproduce bug locally, | **Steps:** | 1. Reproduce bug locally | 2. Identify root cause | 3. Fix issue
packages/universal-agent-context/.github/chatmodes/frontend-dev.chatmode.md,513,config,md,// Bug: Narrative not updating after action,**Example:** | ```typescript | // Bug: Narrative not updating after action |  | // Before: Missing dependency
packages/universal-agent-context/.github/chatmodes/frontend-dev.chatmode.md,578,config,md,"**Note:** This chat mode focuses on frontend implementation. For backend APIs, consult the backend-dev chat mode. For deployment, consult the devops chat mode.","--- |  | **Note:** This chat mode focuses on frontend implementation. For backend APIs, consult the backend-dev chat mode. For deployment, consult the devops chat mode. | "
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,200,config,md,âœ… Fix bugs and optimize performance,âœ… Integrate with Redis and Neo4j | âœ… Write unit and integration tests | âœ… Fix bugs and optimize performance | âœ… Refactor code for maintainability | âœ… Run linting and type checking
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,520,config,md,### TTA Research Notebook,"## Research Integration |  | ### TTA Research Notebook | Consult the research notebook for implementation best practices: | - **Agent Primitives Implementation:** How to build instructions, chatmodes, workflows, and specs"
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,521,config,md,Consult the research notebook for implementation best practices:," | ### TTA Research Notebook | Consult the research notebook for implementation best practices: | - **Agent Primitives Implementation:** How to build instructions, chatmodes, workflows, and specs | - **Markdown Prompt Engineering:** Structural patterns for AI interactions"
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,530,config,md,"uv run python scripts/query_notebook_helper.py ""How should I implement a new chatmode?""","```bash | # Implementation patterns | uv run python scripts/query_notebook_helper.py ""How should I implement a new chatmode?"" |  | # Context engineering"
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,533,config,md,"uv run python scripts/query_notebook_helper.py ""What context should I include in instruction files?"""," | # Context engineering | uv run python scripts/query_notebook_helper.py ""What context should I include in instruction files?"" | ``` | "
packages/universal-agent-context/.github/chatmodes/backend-dev.chatmode.md,568,config,md,"**Note:** This chat mode focuses on backend implementation. For architecture decisions, consult the architect chat mode. For deployment, consult the devops chat mode.","--- |  | **Note:** This chat mode focuses on backend implementation. For architecture decisions, consult the architect chat mode. For deployment, consult the devops chat mode. | "
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,193,config,md,âŒ Fix bugs (unless architectural),âŒ Write tests | âŒ Deploy to production | âŒ Fix bugs (unless architectural) | âŒ Optimize specific algorithms | âŒ Write frontend code
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,202,config,md,- **Bug fixes:** â†’ backend-dev (unless architectural issue),- **Testing:** â†’ qa-engineer | - **Deployment:** â†’ devops | - **Bug fixes:** â†’ backend-dev (unless architectural issue) | - **Performance tuning:** â†’ backend-dev (after architectural review) | 
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,460,config,md,### TTA Research Notebook,"## Research Integration |  | ### TTA Research Notebook | When making architectural decisions, consult the TTA research notebook for: | - **AI-Native Development Framework:** Three-layer approach (Prompt Engineering, Agent Primitives, Context Engineering)"
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,461,config,md,"When making architectural decisions, consult the TTA research notebook for:"," | ### TTA Research Notebook | When making architectural decisions, consult the TTA research notebook for: | - **AI-Native Development Framework:** Three-layer approach (Prompt Engineering, Agent Primitives, Context Engineering) | - **Agent Architecture Patterns:** Best practices for agent orchestration and coordination"
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,467,config,md,**To query the research notebook:**,- **MCP Integration Patterns:** Secure tool usage and boundary management |  | **To query the research notebook:** | ```bash | # From command line
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,470,config,md,"uv run python scripts/query_notebook_helper.py ""How should I design agent primitive interfaces?""","```bash | # From command line | uv run python scripts/query_notebook_helper.py ""How should I design agent primitive interfaces?"" |  | # From Python code"
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,473,config,md,from scripts.query_notebook_helper import query_notebook," | # From Python code | from scripts.query_notebook_helper import query_notebook | response = await query_notebook(""What are MCP security best practices?"") | ```"
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,474,config,md,"response = await query_notebook(""What are MCP security best practices?"")","# From Python code | from scripts.query_notebook_helper import query_notebook | response = await query_notebook(""What are MCP security best practices?"") | ``` | "
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,477,config,md,**When to consult the notebook:**,"``` |  | **When to consult the notebook:** | - Before designing new agent primitives (chatmodes, workflows, instructions) | - When planning MCP tool integrations"
packages/universal-agent-context/.github/chatmodes/architect.chatmode.md,500,config,md,"**Note:** This chat mode focuses on architecture and design. For implementation, testing, or deployment, switch to the appropriate specialized chat mode.","--- |  | **Note:** This chat mode focuses on architecture and design. For implementation, testing, or deployment, switch to the appropriate specialized chat mode. | "
packages/tta-observability-integration/src/observability_integration/primitives/timeout.py,179,code,py,logger.debug(,"                ) |             else: |                 logger.debug( |                     f""'{self.operation_name}' completed in {duration:.2f}s "" |                     f""(within timeout of {self.timeout_seconds}s)"""
packages/tta-observability-integration/src/observability_integration/primitives/cache.py,235,code,py,logger.debug(,"                        ) |  |                     logger.debug( |                         f""Cache HIT for '{self.operation_name}' "" |                         f""(key: {cache_key[:50]}..., latency: {duration * 1000:.1f}ms)"""
packages/tta-observability-integration/src/observability_integration/primitives/cache.py,256,code,py,"logger.debug(f""Cache MISS for '{self.operation_name}' (key: {cache_key[:50]}...)"")","                self._misses_counter.add(1, {""operation"": self.operation_name}) |  |             logger.debug(f""Cache MISS for '{self.operation_name}' (key: {cache_key[:50]}...)"") |  |         # Execute wrapped primitive"
packages/tta-observability-integration/src/observability_integration/primitives/cache.py,274,code,py,logger.debug(,"                ) |  |                 logger.debug( |                     f""Cached result for '{self.operation_name}' (TTL: {self.ttl_seconds}s)"" |                 )"
packages/tta-observability-integration/tests/unit/observability_integration/test_timeout_primitive.py,74,code,py,"""""""String representation for debugging."," |     def __repr__(self) -> str: |         """"""String representation for debugging. |  |         Returns:"
packages/tta-observability-integration/tests/unit/observability_integration/test_timeout_primitive.py,132,code,py,"""""""Test __repr__ provides useful debugging information."""""""," |     def test_repr_output(self): |         """"""Test __repr__ provides useful debugging information."""""" |         mock = MockPrimitive(name=""TestMock"", delay=0.5, raise_error=True) |         repr_str = repr(mock)"
packages/tta-observability-integration/tests/unit/observability_integration/test_cache_primitive.py,135,code,py,# Note: CachePrimitive replaces spaces with underscores in cache keys,"        # Cache key format: cache:{operation_name}:{user_key} |         # operation_name comes from primitive.__class__.__name__ = ""MockPrimitive"" |         # Note: CachePrimitive replaces spaces with underscores in cache keys |         cache_key = ""cache:MockPrimitive:cache:query:test_query"" |         cached_data = json.dumps(""expensive_result"").encode(""utf-8"")"
packages/tta-observability-integration/specs/observability-integration.md,672,other,md,**Notes:**,--- |  | **Notes:** | - This integration builds on existing monitoring infrastructure rather than replacing it | - Cost savings targets (40%) are based on GitHub's agentic primitives article projections
scripts/scan-codebase-todos.py,3,code,py,Codebase TODO Scanner,"#!/usr/bin/env python3 | """""" | Codebase TODO Scanner |  | Scans the entire codebase for TODO comments in code, documentation, and configuration files."
scripts/scan-codebase-todos.py,5,code,py,"Scans the entire codebase for TODO comments in code, documentation, and configuration files.","Codebase TODO Scanner |  | Scans the entire codebase for TODO comments in code, documentation, and configuration files. |  | Outputs:"
scripts/scan-codebase-todos.py,10,code,py,- Stale TODO detection (>30 days based on git blame),"- CSV with file, line, context | - Recommendations for Logseq migration | - Stale TODO detection (>30 days based on git blame) |  | Usage:"
scripts/scan-codebase-todos.py,13,code,py,uv run python scripts/scan-codebase-todos.py, | Usage: |     uv run python scripts/scan-codebase-todos.py |     uv run python scripts/scan-codebase-todos.py --output todos.csv |     uv run python scripts/scan-codebase-todos.py --json
scripts/scan-codebase-todos.py,14,code,py,uv run python scripts/scan-codebase-todos.py --output todos.csv,"Usage: |     uv run python scripts/scan-codebase-todos.py |     uv run python scripts/scan-codebase-todos.py --output todos.csv |     uv run python scripts/scan-codebase-todos.py --json | """""""
scripts/scan-codebase-todos.py,15,code,py,uv run python scripts/scan-codebase-todos.py --json,"    uv run python scripts/scan-codebase-todos.py |     uv run python scripts/scan-codebase-todos.py --output todos.csv |     uv run python scripts/scan-codebase-todos.py --json | """""" | "
scripts/scan-codebase-todos.py,28,code,py,class CodeTODO:," | @dataclass | class CodeTODO: |     """"""Represents a TODO found in code."""""" | "
scripts/scan-codebase-todos.py,29,code,py,"""""""Represents a TODO found in code.""""""","@dataclass | class CodeTODO: |     """"""Represents a TODO found in code."""""" |  |     file_path: Path"
scripts/scan-codebase-todos.py,33,code,py,todo_text: str,"    file_path: Path |     line_number: int |     todo_text: str |     context: str  # Surrounding lines |     file_type: str  # py, md, yml, etc."
scripts/scan-codebase-todos.py,41,code,py,"""""""Results of codebase TODO scan.""""""","@dataclass | class ScanResult: |     """"""Results of codebase TODO scan."""""" |  |     todos: list[CodeTODO] = field(default_factory=list)"
scripts/scan-codebase-todos.py,43,code,py,todos: list[CodeTODO] = field(default_factory=list),"    """"""Results of codebase TODO scan."""""" |  |     todos: list[CodeTODO] = field(default_factory=list) |     files_scanned: int = 0 |     files_with_todos: int = 0"
scripts/scan-codebase-todos.py,45,code,py,files_with_todos: int = 0,"    todos: list[CodeTODO] = field(default_factory=list) |     files_scanned: int = 0 |     files_with_todos: int = 0 |  |     def by_category(self) -> dict[str, list[CodeTODO]]:"
scripts/scan-codebase-todos.py,47,code,py,"def by_category(self) -> dict[str, list[CodeTODO]]:","    files_with_todos: int = 0 |  |     def by_category(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by category."""""" |         result: dict[str, list[CodeTODO]] = {}"
scripts/scan-codebase-todos.py,48,code,py,"""""""Group TODOs by category."""""""," |     def by_category(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by category."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos:"
scripts/scan-codebase-todos.py,49,code,py,"result: dict[str, list[CodeTODO]] = {}","    def by_category(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by category."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.category not in result:"
scripts/scan-codebase-todos.py,50,code,py,for todo in self.todos:,"        """"""Group TODOs by category."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.category not in result: |                 result[todo.category] = []"
scripts/scan-codebase-todos.py,51,code,py,if todo.category not in result:,"        result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.category not in result: |                 result[todo.category] = [] |             result[todo.category].append(todo)"
scripts/scan-codebase-todos.py,52,code,py,result[todo.category] = [],        for todo in self.todos: |             if todo.category not in result: |                 result[todo.category] = [] |             result[todo.category].append(todo) |         return result
scripts/scan-codebase-todos.py,53,code,py,result[todo.category].append(todo),            if todo.category not in result: |                 result[todo.category] = [] |             result[todo.category].append(todo) |         return result | 
scripts/scan-codebase-todos.py,56,code,py,"def by_file_type(self) -> dict[str, list[CodeTODO]]:","        return result |  |     def by_file_type(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by file type."""""" |         result: dict[str, list[CodeTODO]] = {}"
scripts/scan-codebase-todos.py,57,code,py,"""""""Group TODOs by file type."""""""," |     def by_file_type(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by file type."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos:"
scripts/scan-codebase-todos.py,58,code,py,"result: dict[str, list[CodeTODO]] = {}","    def by_file_type(self) -> dict[str, list[CodeTODO]]: |         """"""Group TODOs by file type."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.file_type not in result:"
scripts/scan-codebase-todos.py,59,code,py,for todo in self.todos:,"        """"""Group TODOs by file type."""""" |         result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.file_type not in result: |                 result[todo.file_type] = []"
scripts/scan-codebase-todos.py,60,code,py,if todo.file_type not in result:,"        result: dict[str, list[CodeTODO]] = {} |         for todo in self.todos: |             if todo.file_type not in result: |                 result[todo.file_type] = [] |             result[todo.file_type].append(todo)"
scripts/scan-codebase-todos.py,61,code,py,result[todo.file_type] = [],        for todo in self.todos: |             if todo.file_type not in result: |                 result[todo.file_type] = [] |             result[todo.file_type].append(todo) |         return result
scripts/scan-codebase-todos.py,62,code,py,result[todo.file_type].append(todo),            if todo.file_type not in result: |                 result[todo.file_type] = [] |             result[todo.file_type].append(todo) |         return result | 
scripts/scan-codebase-todos.py,67,code,py,"""""""Scans codebase for TODO comments."""""""," | class CodebaseScanner: |     """"""Scans codebase for TODO comments."""""" |  |     def __init__(self, root_dir: Path):"
scripts/scan-codebase-todos.py,108,code,py,# TODO patterns,"        } |  |         # TODO patterns |         self.todo_pattern = re.compile(r""(TODO|FIXME|XXX|HACK|NOTE|BUG)[\s:]*(.+)"", re.IGNORECASE) | "
scripts/scan-codebase-todos.py,109,code,py,"self.todo_pattern = re.compile(r""(TODO|FIXME|XXX|HACK|NOTE|BUG)[\s:]*(.+)"", re.IGNORECASE)"," |         # TODO patterns |         self.todo_pattern = re.compile(r""(TODO|FIXME|XXX|HACK|NOTE|BUG)[\s:]*(.+)"", re.IGNORECASE) |  |     def scan(self) -> ScanResult:"
scripts/scan-codebase-todos.py,112,code,py,"""""""Scan codebase for TODOs."""""""," |     def scan(self) -> ScanResult: |         """"""Scan codebase for TODOs."""""" |         result = ScanResult() | "
scripts/scan-codebase-todos.py,115,code,py,"print(""ðŸ” Scanning codebase for TODOs..."")","        result = ScanResult() |  |         print(""ðŸ” Scanning codebase for TODOs..."") |  |         for scan_dir in self.scan_dirs:"
scripts/scan-codebase-todos.py,126,code,py,"print(f""ðŸ“‹ Found {len(result.todos)} TODOs in {result.files_with_todos} files"")"," |         print(f""\nâœ… Scanned {result.files_scanned} files"") |         print(f""ðŸ“‹ Found {len(result.todos)} TODOs in {result.files_with_todos} files"") |  |         return result"
scripts/scan-codebase-todos.py,131,code,py,"""""""Recursively scan directory for TODOs."""""""," |     def _scan_directory(self, directory: Path, result: ScanResult) -> None: |         """"""Recursively scan directory for TODOs."""""" |         for item in directory.rglob(""*""): |             # Skip excluded directories"
scripts/scan-codebase-todos.py,146,code,py,todos_found = self._scan_file(item), |             result.files_scanned += 1 |             todos_found = self._scan_file(item) |  |             if todos_found:
scripts/scan-codebase-todos.py,148,code,py,if todos_found:,            todos_found = self._scan_file(item) |  |             if todos_found: |                 result.todos.extend(todos_found) |                 result.files_with_todos += 1
scripts/scan-codebase-todos.py,149,code,py,result.todos.extend(todos_found), |             if todos_found: |                 result.todos.extend(todos_found) |                 result.files_with_todos += 1 | 
scripts/scan-codebase-todos.py,150,code,py,result.files_with_todos += 1,"            if todos_found: |                 result.todos.extend(todos_found) |                 result.files_with_todos += 1 |  |     def _scan_file(self, file_path: Path) -> list[CodeTODO]:"
scripts/scan-codebase-todos.py,152,code,py,"def _scan_file(self, file_path: Path) -> list[CodeTODO]:","                result.files_with_todos += 1 |  |     def _scan_file(self, file_path: Path) -> list[CodeTODO]: |         """"""Scan a single file for TODOs."""""" |         todos = []"
scripts/scan-codebase-todos.py,153,code,py,"""""""Scan a single file for TODOs."""""""," |     def _scan_file(self, file_path: Path) -> list[CodeTODO]: |         """"""Scan a single file for TODOs."""""" |         todos = [] | "
scripts/scan-codebase-todos.py,154,code,py,todos = [],"    def _scan_file(self, file_path: Path) -> list[CodeTODO]: |         """"""Scan a single file for TODOs."""""" |         todos = [] |  |         try:"
scripts/scan-codebase-todos.py,161,code,py,match = self.todo_pattern.search(line)," |             for i, line in enumerate(lines): |                 match = self.todo_pattern.search(line) |                 if match: |                     todo_text_raw = line.strip()"
scripts/scan-codebase-todos.py,163,code,py,todo_text_raw = line.strip(),"                match = self.todo_pattern.search(line) |                 if match: |                     todo_text_raw = line.strip() |                     if ""#non-actionable"" in todo_text_raw.lower(): |                         continue"
scripts/scan-codebase-todos.py,175,code,py,todos.append(,"                    category = self._categorize_file(file_path) |  |                     todos.append( |                         CodeTODO( |                             file_path=file_path.relative_to(self.root_dir),"
scripts/scan-codebase-todos.py,176,code,py,CodeTODO(," |                     todos.append( |                         CodeTODO( |                             file_path=file_path.relative_to(self.root_dir), |                             line_number=i + 1,"
scripts/scan-codebase-todos.py,179,code,py,"todo_text=todo_text_raw,","                            file_path=file_path.relative_to(self.root_dir), |                             line_number=i + 1, |                             todo_text=todo_text_raw, |                             context=context, |                             file_type=file_path.suffix[1:] if file_path.suffix else ""txt"","
scripts/scan-codebase-todos.py,189,code,py,return todos,"            print(f""âš ï¸  Error scanning {file_path}: {e}"") |  |         return todos |  |     def _categorize_file(self, file_path: Path) -> str:"
scripts/scan-codebase-todos.py,210,code,py,"print(""ðŸ“Š CODEBASE TODO SCAN RESULTS"")","    """"""Print scan results in human-readable format."""""" |     print(""\n"" + ""="" * 80) |     print(""ðŸ“Š CODEBASE TODO SCAN RESULTS"") |     print(""="" * 80) | "
scripts/scan-codebase-todos.py,214,code,py,"print(f""  Total TODOs: {len(result.todos)}"")"," |     print(""\nðŸ“ˆ Summary:"") |     print(f""  Total TODOs: {len(result.todos)}"") |     print(f""  Files scanned: {result.files_scanned}"") |     print(f""  Files with TODOs: {result.files_with_todos}"")"
scripts/scan-codebase-todos.py,216,code,py,"print(f""  Files with TODOs: {result.files_with_todos}"")","    print(f""  Total TODOs: {len(result.todos)}"") |     print(f""  Files scanned: {result.files_scanned}"") |     print(f""  Files with TODOs: {result.files_with_todos}"") |  |     # By category"
scripts/scan-codebase-todos.py,221,code,py,"for category, todos in sorted(by_category.items(), key=lambda x: -len(x[1])):","    print(""\nðŸ“‚ By Category:"") |     by_category = result.by_category() |     for category, todos in sorted(by_category.items(), key=lambda x: -len(x[1])): |         print(f""  {category}: {len(todos)}"") | "
scripts/scan-codebase-todos.py,222,code,py,"print(f""  {category}: {len(todos)}"")","    by_category = result.by_category() |     for category, todos in sorted(by_category.items(), key=lambda x: -len(x[1])): |         print(f""  {category}: {len(todos)}"") |  |     # By file type"
scripts/scan-codebase-todos.py,227,code,py,"for file_type, todos in sorted(by_type.items(), key=lambda x: -len(x[1])):","    print(""\nðŸ“„ By File Type:"") |     by_type = result.by_file_type() |     for file_type, todos in sorted(by_type.items(), key=lambda x: -len(x[1])): |         print(f""  .{file_type}: {len(todos)}"") | "
scripts/scan-codebase-todos.py,228,code,py,"print(f""  .{file_type}: {len(todos)}"")","    by_type = result.by_file_type() |     for file_type, todos in sorted(by_type.items(), key=lambda x: -len(x[1])): |         print(f""  .{file_type}: {len(todos)}"") |  |     # Sample TODOs"
scripts/scan-codebase-todos.py,230,code,py,# Sample TODOs,"        print(f""  .{file_type}: {len(todos)}"") |  |     # Sample TODOs |     print(""\nðŸ“‹ Sample TODOs (first 10):"") |     for todo in result.todos[:10]:"
scripts/scan-codebase-todos.py,231,code,py,"print(""\nðŸ“‹ Sample TODOs (first 10):"")"," |     # Sample TODOs |     print(""\nðŸ“‹ Sample TODOs (first 10):"") |     for todo in result.todos[:10]: |         print(f""\n  {todo.file_path}:{todo.line_number}"")"
scripts/scan-codebase-todos.py,232,code,py,for todo in result.todos[:10]:,"    # Sample TODOs |     print(""\nðŸ“‹ Sample TODOs (first 10):"") |     for todo in result.todos[:10]: |         print(f""\n  {todo.file_path}:{todo.line_number}"") |         print(f""  {todo.todo_text}"")"
scripts/scan-codebase-todos.py,233,code,py,"print(f""\n  {todo.file_path}:{todo.line_number}"")","    print(""\nðŸ“‹ Sample TODOs (first 10):"") |     for todo in result.todos[:10]: |         print(f""\n  {todo.file_path}:{todo.line_number}"") |         print(f""  {todo.todo_text}"") | "
scripts/scan-codebase-todos.py,234,code,py,"print(f""  {todo.todo_text}"")","    for todo in result.todos[:10]: |         print(f""\n  {todo.file_path}:{todo.line_number}"") |         print(f""  {todo.todo_text}"") |  |     print(""\n"" + ""="" * 80)"
scripts/scan-codebase-todos.py,243,code,py,"writer.writerow([""File"", ""Line"", ""Category"", ""Type"", ""TODO Text"", ""Context""])","    with output_path.open(""w"", newline="""", encoding=""utf-8"") as f: |         writer = csv.writer(f) |         writer.writerow([""File"", ""Line"", ""Category"", ""Type"", ""TODO Text"", ""Context""]) |  |         for todo in result.todos:"
scripts/scan-codebase-todos.py,245,code,py,for todo in result.todos:,"        writer.writerow([""File"", ""Line"", ""Category"", ""Type"", ""TODO Text"", ""Context""]) |  |         for todo in result.todos: |             writer.writerow( |                 ["
scripts/scan-codebase-todos.py,248,code,py,"str(todo.file_path),","            writer.writerow( |                 [ |                     str(todo.file_path), |                     todo.line_number, |                     todo.category,"
scripts/scan-codebase-todos.py,249,code,py,"todo.line_number,","                [ |                     str(todo.file_path), |                     todo.line_number, |                     todo.category, |                     todo.file_type,"
scripts/scan-codebase-todos.py,250,code,py,"todo.category,","                    str(todo.file_path), |                     todo.line_number, |                     todo.category, |                     todo.file_type, |                     todo.todo_text,"
scripts/scan-codebase-todos.py,251,code,py,"todo.file_type,","                    todo.line_number, |                     todo.category, |                     todo.file_type, |                     todo.todo_text, |                     todo.context.replace(""\n"", "" | ""),"
scripts/scan-codebase-todos.py,252,code,py,"todo.todo_text,","                    todo.category, |                     todo.file_type, |                     todo.todo_text, |                     todo.context.replace(""\n"", "" | ""), |                 ]"
scripts/scan-codebase-todos.py,253,code,py,"todo.context.replace(""\n"", "" | ""),","                    todo.file_type, |                     todo.todo_text, |                     todo.context.replace(""\n"", "" | ""), |                 ] |             )"
scripts/scan-codebase-todos.py,264,code,py,"""total_todos"": len(result.todos),","    output = { |         ""summary"": { |             ""total_todos"": len(result.todos), |             ""files_scanned"": result.files_scanned, |             ""files_with_todos"": result.files_with_todos,"
scripts/scan-codebase-todos.py,266,code,py,"""files_with_todos"": result.files_with_todos,","            ""total_todos"": len(result.todos), |             ""files_scanned"": result.files_scanned, |             ""files_with_todos"": result.files_with_todos, |         }, |         ""by_category"": {cat: len(todos) for cat, todos in result.by_category().items()},"
scripts/scan-codebase-todos.py,268,code,py,"""by_category"": {cat: len(todos) for cat, todos in result.by_category().items()},","            ""files_with_todos"": result.files_with_todos, |         }, |         ""by_category"": {cat: len(todos) for cat, todos in result.by_category().items()}, |         ""by_file_type"": {ft: len(todos) for ft, todos in result.by_file_type().items()}, |         ""todos"": ["
scripts/scan-codebase-todos.py,269,code,py,"""by_file_type"": {ft: len(todos) for ft, todos in result.by_file_type().items()},","        }, |         ""by_category"": {cat: len(todos) for cat, todos in result.by_category().items()}, |         ""by_file_type"": {ft: len(todos) for ft, todos in result.by_file_type().items()}, |         ""todos"": [ |             {"
scripts/scan-codebase-todos.py,270,code,py,"""todos"": [","        ""by_category"": {cat: len(todos) for cat, todos in result.by_category().items()}, |         ""by_file_type"": {ft: len(todos) for ft, todos in result.by_file_type().items()}, |         ""todos"": [ |             { |                 ""file"": str(todo.file_path),"
scripts/scan-codebase-todos.py,272,code,py,"""file"": str(todo.file_path),","        ""todos"": [ |             { |                 ""file"": str(todo.file_path), |                 ""line"": todo.line_number, |                 ""category"": todo.category,"
scripts/scan-codebase-todos.py,273,code,py,"""line"": todo.line_number,","            { |                 ""file"": str(todo.file_path), |                 ""line"": todo.line_number, |                 ""category"": todo.category, |                 ""type"": todo.file_type,"
scripts/scan-codebase-todos.py,274,code,py,"""category"": todo.category,","                ""file"": str(todo.file_path), |                 ""line"": todo.line_number, |                 ""category"": todo.category, |                 ""type"": todo.file_type, |                 ""text"": todo.todo_text,"
scripts/scan-codebase-todos.py,275,code,py,"""type"": todo.file_type,","                ""line"": todo.line_number, |                 ""category"": todo.category, |                 ""type"": todo.file_type, |                 ""text"": todo.todo_text, |             }"
scripts/scan-codebase-todos.py,276,code,py,"""text"": todo.todo_text,","                ""category"": todo.category, |                 ""type"": todo.file_type, |                 ""text"": todo.todo_text, |             } |             for todo in result.todos"
scripts/scan-codebase-todos.py,278,code,py,for todo in result.todos,"                ""text"": todo.todo_text, |             } |             for todo in result.todos |         ], |     }"
scripts/scan-codebase-todos.py,287,code,py,"parser = argparse.ArgumentParser(description=""Scan codebase for TODOs"")","def main() -> int: |     """"""Main entry point."""""" |     parser = argparse.ArgumentParser(description=""Scan codebase for TODOs"") |     parser.add_argument( |         ""--root"","
scripts/verify-and-setup-persistence.sh,56,other,sh,"echo ""   Note: docker-compose.integration.yml needs restart policies""","else |     echo -e ""${RED}âŒ Not configured${NC}"" |     echo ""   Note: docker-compose.integration.yml needs restart policies"" |     ALL_GOOD=false | fi"
scripts/setup-agent-workspace.sh,354,other,sh,â€¢ TODO Management: logseq/pages/TODO Management System.md,ðŸ“š Documentation: |    â€¢ Agent Instructions: .github/copilot-instructions.md |    â€¢ TODO Management: logseq/pages/TODO Management System.md |    â€¢ Setup Troubleshooting: scripts/setup-agent-workspace.sh --help | 
scripts/PERSISTENCE_SETUP.md,206,other,md,## Notes,``` |  | ## Notes |  | - **Systemd service** runs as your user (`thein`) with your environment
scripts/test-gemini-api-key.sh,144,other,sh,"echo ""  â†’ Consider filing bug report or using direct API calls""","echo ""  â†’ API keys are valid"" | echo ""  â†’ Problem is with gemini-cli GitHub Action"" | echo ""  â†’ Consider filing bug report or using direct API calls"" | echo """" | echo ""If tests fail (âŒ):"""
scripts/improved_model_test.py,253,code,py,# Log attention mask info for debugging,"            ) |  |             # Log attention mask info for debugging |             logger.info(f""Input shape: {inputs['input_ids'].shape}"") |             logger.info(f""Attention mask shape: {inputs['attention_mask'].shape}"")"
scripts/extract-embedded-todos.py,2,code,py,"""""""Extract embedded TODOs from markdown files to Logseq journal.","#!/usr/bin/env python3 | """"""Extract embedded TODOs from markdown files to Logseq journal. |  | This script scans markdown files for TODO comments and creates properly"
scripts/extract-embedded-todos.py,4,code,py,This script scans markdown files for TODO comments and creates properly,"""""""Extract embedded TODOs from markdown files to Logseq journal. |  | This script scans markdown files for TODO comments and creates properly | formatted journal entries with all required properties. | "
scripts/extract-embedded-todos.py,8,code,py,uv run python scripts/extract-embedded-todos.py [--dir DIR] [--dry-run], | Usage: |     uv run python scripts/extract-embedded-todos.py [--dir DIR] [--dry-run] |  | Examples:
scripts/extract-embedded-todos.py,12,code,py,uv run python scripts/extract-embedded-todos.py,Examples: |     # Scan all markdown files |     uv run python scripts/extract-embedded-todos.py |  |     # Scan specific directory
scripts/extract-embedded-todos.py,15,code,py,uv run python scripts/extract-embedded-todos.py --dir docs/, |     # Scan specific directory |     uv run python scripts/extract-embedded-todos.py --dir docs/ |  |     # Show what would be extracted (don't modify files)
scripts/extract-embedded-todos.py,18,code,py,uv run python scripts/extract-embedded-todos.py --dry-run," |     # Show what would be extracted (don't modify files) |     uv run python scripts/extract-embedded-todos.py --dry-run | """""" | "
scripts/extract-embedded-todos.py,28,code,py,class TodoExtractor:," |  | class TodoExtractor: |     """"""Extract TODOs from markdown files and format for Logseq."""""" | "
scripts/extract-embedded-todos.py,29,code,py,"""""""Extract TODOs from markdown files and format for Logseq."""""""," | class TodoExtractor: |     """"""Extract TODOs from markdown files and format for Logseq."""""" |  |     TODO_PATTERN = re.compile("
scripts/extract-embedded-todos.py,31,code,py,TODO_PATTERN = re.compile(,"    """"""Extract TODOs from markdown files and format for Logseq."""""" |  |     TODO_PATTERN = re.compile( |         r""(?:<!--\s*)?TODO:?\s+(.+?)(?:\s*-->)?$"", re.MULTILINE | re.IGNORECASE |     )"
scripts/extract-embedded-todos.py,32,code,py,"r""(?:<!--\s*)?TODO:?\s+(.+?)(?:\s*-->)?$"", re.MULTILINE | re.IGNORECASE"," |     TODO_PATTERN = re.compile( |         r""(?:<!--\s*)?TODO:?\s+(.+?)(?:\s*-->)?$"", re.MULTILINE | re.IGNORECASE |     ) | "
scripts/extract-embedded-todos.py,38,code,py,"self.todos: list[dict[str, Any]] = []","        self.workspace_root = workspace_root |         self.logseq_journals = workspace_root / ""logseq"" / ""journals"" |         self.todos: list[dict[str, Any]] = [] |  |     def scan_directory(self, directory: Path, exclude_dirs: list[str] | None = None) -> None:"
scripts/extract-embedded-todos.py,41,code,py,"""""""Scan directory for markdown files with TODOs."""""""," |     def scan_directory(self, directory: Path, exclude_dirs: list[str] | None = None) -> None: |         """"""Scan directory for markdown files with TODOs."""""" |         if exclude_dirs is None: |             exclude_dirs = ["
scripts/extract-embedded-todos.py,60,code,py,"""""""Scan a single file for TODOs."""""""," |     def _scan_file(self, file_path: Path) -> None: |         """"""Scan a single file for TODOs."""""" |         try: |             content = file_path.read_text(encoding=""utf-8"")"
scripts/extract-embedded-todos.py,65,code,py,for match in self.TODO_PATTERN.finditer(content):,"            relative_path = file_path.relative_to(self.workspace_root) |  |             for match in self.TODO_PATTERN.finditer(content): |                 line_num = content[: match.start()].count(""\n"") + 1 |                 todo_text = match.group(1).strip()"
scripts/extract-embedded-todos.py,67,code,py,todo_text = match.group(1).strip(),"            for match in self.TODO_PATTERN.finditer(content): |                 line_num = content[: match.start()].count(""\n"") + 1 |                 todo_text = match.group(1).strip() |  |                 # Extract multi-line TODO if next lines are indented"
scripts/extract-embedded-todos.py,69,code,py,# Extract multi-line TODO if next lines are indented,"                todo_text = match.group(1).strip() |  |                 # Extract multi-line TODO if next lines are indented |                 lines = content.split(""\n"") |                 full_todo = [todo_text]"
scripts/extract-embedded-todos.py,71,code,py,full_todo = [todo_text],"                # Extract multi-line TODO if next lines are indented |                 lines = content.split(""\n"") |                 full_todo = [todo_text] |                 for i in range(line_num, len(lines)): |                     line = lines[i]"
scripts/extract-embedded-todos.py,75,code,py,full_todo.append(line.strip()),"                    line = lines[i] |                     if line.strip() and (line.startswith(""  "") or line.startswith(""-"")): |                         full_todo.append(line.strip()) |                     elif line.strip() and not line.startswith(""TODO""): |                         break"
scripts/extract-embedded-todos.py,76,code,py,"elif line.strip() and not line.startswith(""TODO""):","                    if line.strip() and (line.startswith(""  "") or line.startswith(""-"")): |                         full_todo.append(line.strip()) |                     elif line.strip() and not line.startswith(""TODO""): |                         break | "
scripts/extract-embedded-todos.py,79,code,py,self.todos.append(,"                        break |  |                 self.todos.append( |                     { |                         ""text"": ""\n  "".join(full_todo),"
scripts/extract-embedded-todos.py,81,code,py,"""text"": ""\n  "".join(full_todo),","                self.todos.append( |                     { |                         ""text"": ""\n  "".join(full_todo), |                         ""file"": str(relative_path), |                         ""line"": line_num,"
scripts/extract-embedded-todos.py,84,code,py,"""category"": self._infer_category(file_path, todo_text),","                        ""file"": str(relative_path), |                         ""line"": line_num, |                         ""category"": self._infer_category(file_path, todo_text), |                     } |                 )"
scripts/extract-embedded-todos.py,91,code,py,"def _infer_category(self, file_path: Path, todo_text: str) -> str:","            print(f""Warning: Could not scan {file_path}: {e}"") |  |     def _infer_category(self, file_path: Path, todo_text: str) -> str: |         """"""Infer TODO category from file location and content."""""" |         path_str = str(file_path).lower()"
scripts/extract-embedded-todos.py,92,code,py,"""""""Infer TODO category from file location and content."""""""," |     def _infer_category(self, file_path: Path, todo_text: str) -> str: |         """"""Infer TODO category from file location and content."""""" |         path_str = str(file_path).lower() |         text_lower = todo_text.lower()"
scripts/extract-embedded-todos.py,94,code,py,text_lower = todo_text.lower(),"        """"""Infer TODO category from file location and content."""""" |         path_str = str(file_path).lower() |         text_lower = todo_text.lower() |  |         # Check for explicit markers"
scripts/extract-embedded-todos.py,98,code,py,"return ""learning-todo""","        # Check for explicit markers |         if ""learning"" in text_lower or ""tutorial"" in text_lower or ""example"" in text_lower: |             return ""learning-todo"" |         if ""template"" in text_lower: |             return ""template-todo"""
scripts/extract-embedded-todos.py,100,code,py,"return ""template-todo""","            return ""learning-todo"" |         if ""template"" in text_lower: |             return ""template-todo"" |         if ""deploy"" in text_lower or ""ci/cd"" in text_lower or ""infrastructure"" in text_lower: |             return ""ops-todo"""
scripts/extract-embedded-todos.py,102,code,py,"return ""ops-todo""","            return ""template-todo"" |         if ""deploy"" in text_lower or ""ci/cd"" in text_lower or ""infrastructure"" in text_lower: |             return ""ops-todo"" |  |         # Infer from file location"
scripts/extract-embedded-todos.py,106,code,py,"return ""learning-todo""","        # Infer from file location |         if ""docs/examples"" in path_str or ""docs/guides"" in path_str: |             return ""learning-todo"" |         if ""templates"" in path_str: |             return ""template-todo"""
scripts/extract-embedded-todos.py,108,code,py,"return ""template-todo""","            return ""learning-todo"" |         if ""templates"" in path_str: |             return ""template-todo"" |         if "".github"" in path_str or ""scripts"" in path_str: |             return ""ops-todo"""
scripts/extract-embedded-todos.py,110,code,py,"return ""ops-todo""","            return ""template-todo"" |         if "".github"" in path_str or ""scripts"" in path_str: |             return ""ops-todo"" |  |         # Default to dev-todo"
scripts/extract-embedded-todos.py,113,code,py,"return ""dev-todo"""," |         # Default to dev-todo |         return ""dev-todo"" |  |     def _infer_package(self, file_path: Path) -> str | None:"
scripts/extract-embedded-todos.py,133,code,py,"""""""Infer TODO type from file path and category."""""""," |     def _infer_type(self, file_path: Path, category: str) -> str: |         """"""Infer TODO type from file path and category."""""" |         path_str = str(file_path).lower() | "
scripts/extract-embedded-todos.py,136,code,py,"if category == ""learning-todo"":","        path_str = str(file_path).lower() |  |         if category == ""learning-todo"": |             if ""tutorial"" in path_str: |                 return ""tutorial"""
scripts/extract-embedded-todos.py,143,code,py,"if category == ""template-todo"":","            return ""documentation"" |  |         if category == ""template-todo"": |             if ""primitive"" in path_str: |                 return ""primitive"""
scripts/extract-embedded-todos.py,150,code,py,"if category == ""ops-todo"":","            return ""workflow"" |  |         if category == ""ops-todo"": |             if ""deploy"" in path_str or ""ci"" in path_str: |                 return ""deployment"""
scripts/extract-embedded-todos.py,168,code,py,"""""""Format extracted TODOs as Logseq journal entries."""""""," |     def format_for_logseq(self) -> str: |         """"""Format extracted TODOs as Logseq journal entries."""""" |         if not self.todos: |             return """""
scripts/extract-embedded-todos.py,169,code,py,if not self.todos:,"    def format_for_logseq(self) -> str: |         """"""Format extracted TODOs as Logseq journal entries."""""" |         if not self.todos: |             return """" | "
scripts/extract-embedded-todos.py,174,code,py,"f""\n## ðŸ“ Extracted TODOs - {today.strftime('%B %d, %Y')}\n"",","        today = date.today() |         output = [ |             f""\n## ðŸ“ Extracted TODOs - {today.strftime('%B %d, %Y')}\n"", |             ""The following TODOs were found in markdown files:\n"", |         ]"
scripts/extract-embedded-todos.py,175,code,py,"""The following TODOs were found in markdown files:\n"",","        output = [ |             f""\n## ðŸ“ Extracted TODOs - {today.strftime('%B %d, %Y')}\n"", |             ""The following TODOs were found in markdown files:\n"", |         ] | "
scripts/extract-embedded-todos.py,178,code,py,for todo in self.todos:,"        ] |  |         for todo in self.todos: |             category = todo[""category""] |             file_path = todo[""file""]"
scripts/extract-embedded-todos.py,179,code,py,"category = todo[""category""]"," |         for todo in self.todos: |             category = todo[""category""] |             file_path = todo[""file""] |             line_num = todo[""line""]"
scripts/extract-embedded-todos.py,180,code,py,"file_path = todo[""file""]","        for todo in self.todos: |             category = todo[""category""] |             file_path = todo[""file""] |             line_num = todo[""line""] |             text = todo[""text""]"
scripts/extract-embedded-todos.py,181,code,py,"line_num = todo[""line""]","            category = todo[""category""] |             file_path = todo[""file""] |             line_num = todo[""line""] |             text = todo[""text""] | "
scripts/extract-embedded-todos.py,182,code,py,"text = todo[""text""]","            file_path = todo[""file""] |             line_num = todo[""line""] |             text = todo[""text""] |  |             # Build TODO entry"
scripts/extract-embedded-todos.py,184,code,py,# Build TODO entry,"            text = todo[""text""] |  |             # Build TODO entry |             entry = [ |                 f""- TODO {text} #{category}"","
scripts/extract-embedded-todos.py,186,code,py,"f""- TODO {text} #{category}"",","            # Build TODO entry |             entry = [ |                 f""- TODO {text} #{category}"", |             ] | "
scripts/extract-embedded-todos.py,192,code,py,"if category == ""dev-todo"":","            entry.append(f""  type:: {self._infer_type(Path(file_path), category)}"") |  |             if category == ""dev-todo"": |                 entry.append(""  priority:: medium"") |                 package = self._infer_package(Path(file_path))"
scripts/extract-embedded-todos.py,198,code,py,"elif category == ""learning-todo"":","                    entry.append(f""  package:: {package}"") |  |             elif category == ""learning-todo"": |                 entry.append(""  audience:: intermediate-users"") |                 entry.append(""  difficulty:: intermediate"")"
scripts/extract-embedded-todos.py,202,code,py,"elif category == ""template-todo"":","                entry.append(""  difficulty:: intermediate"") |  |             elif category == ""template-todo"": |                 entry.append(""  priority:: medium"") | "
scripts/extract-embedded-todos.py,205,code,py,"elif category == ""ops-todo"":","                entry.append(""  priority:: medium"") |  |             elif category == ""ops-todo"": |                 entry.append(""  priority:: medium"") | "
scripts/extract-embedded-todos.py,214,code,py,"output.append("""")  # Blank line between TODOs"," |             output.extend(entry) |             output.append("""")  # Blank line between TODOs |  |         return ""\n"".join(output)"
scripts/extract-embedded-todos.py,219,code,py,"""""""Write extracted TODOs to today's journal."""""""," |     def write_to_journal(self, dry_run: bool = False) -> Path: |         """"""Write extracted TODOs to today's journal."""""" |         today = date.today() |         journal_file = self.logseq_journals / f""{today.strftime('%Y_%m_%d')}.md"""
scripts/extract-embedded-todos.py,244,code,py,"description=""Extract embedded TODOs from markdown files to Logseq journal""","    """"""Main entry point."""""" |     parser = argparse.ArgumentParser( |         description=""Extract embedded TODOs from markdown files to Logseq journal"" |     ) |     parser.add_argument("
scripts/extract-embedded-todos.py,268,code,py,# Extract TODOs,"        return 1 |  |     # Extract TODOs |     extractor = TodoExtractor(workspace_root) |     print(f""Scanning {scan_dir} for embedded TODOs..."")"
scripts/extract-embedded-todos.py,269,code,py,extractor = TodoExtractor(workspace_root)," |     # Extract TODOs |     extractor = TodoExtractor(workspace_root) |     print(f""Scanning {scan_dir} for embedded TODOs..."") |     extractor.scan_directory(scan_dir)"
scripts/extract-embedded-todos.py,270,code,py,"print(f""Scanning {scan_dir} for embedded TODOs..."")","    # Extract TODOs |     extractor = TodoExtractor(workspace_root) |     print(f""Scanning {scan_dir} for embedded TODOs..."") |     extractor.scan_directory(scan_dir) | "
scripts/extract-embedded-todos.py,273,code,py,if not extractor.todos:,"    extractor.scan_directory(scan_dir) |  |     if not extractor.todos: |         print(""No TODOs found."") |         return 0"
scripts/extract-embedded-todos.py,274,code,py,"print(""No TODOs found."")"," |     if not extractor.todos: |         print(""No TODOs found."") |         return 0 | "
scripts/extract-embedded-todos.py,277,code,py,"print(f""\nFound {len(extractor.todos)} TODOs:"")","        return 0 |  |     print(f""\nFound {len(extractor.todos)} TODOs:"") |     for i, todo in enumerate(extractor.todos, 1): |         print(f""{i}. {todo['file']}:{todo['line']} - {todo['text'][:60]}..."")"
scripts/extract-embedded-todos.py,278,code,py,"for i, todo in enumerate(extractor.todos, 1):"," |     print(f""\nFound {len(extractor.todos)} TODOs:"") |     for i, todo in enumerate(extractor.todos, 1): |         print(f""{i}. {todo['file']}:{todo['line']} - {todo['text'][:60]}..."") | "
scripts/extract-embedded-todos.py,279,code,py,"print(f""{i}. {todo['file']}:{todo['line']} - {todo['text'][:60]}..."")","    print(f""\nFound {len(extractor.todos)} TODOs:"") |     for i, todo in enumerate(extractor.todos, 1): |         print(f""{i}. {todo['file']}:{todo['line']} - {todo['text'][:60]}..."") |  |     # Write to journal"
scripts/extract-embedded-todos.py,287,code,py,"print(f""\nâœ… TODOs written to {journal_file}"")","        print(f""\nWould write to: {journal_file}"") |     else: |         print(f""\nâœ… TODOs written to {journal_file}"") |  |     return 0"
scripts/setup-tta-audit-sandbox.sh,415,other,sh,**Update TODO:**,\`\`\` |  | **Update TODO:** | \`\`\`bash | cd ~/repos/TTA.dev
scripts/validate_secrets.py,66,code,py,"print(f""   Debug Mode: {config.get('debug', False)}"")","                print(""\nðŸ“‹ Configuration Summary:"") |                 print(f""   Environment: {config.get('environment', 'unknown')}"") |                 print(f""   Debug Mode: {config.get('debug', False)}"") |                 print(f""   Metrics Enabled: {config.get('metrics', {}).get('enabled', False)}"") |                 print(f""   Metrics Port: {config.get('metrics', {}).get('port', 'unknown')}"")"
scripts/link_orphans.py,28,code,py,"""logseq/pages/Example TODO.md"",","        ""logseq/pages/Docker.md"", |         ""logseq/pages/Documentation.md"", |         ""logseq/pages/Example TODO.md"", |         ""logseq/pages/Example.md"", |         ""logseq/pages/Examples.md"","
scripts/link_orphans.py,68,code,py,"""logseq/pages/TODO System Quickstart.md"",","        ""logseq/pages/Session Context___ CachePrimitive.md"", |         ""logseq/pages/Stable.md"", |         ""logseq/pages/TODO System Quickstart.md"", |         ""logseq/pages/TTA KB Automation___LinkValidator.md"", |         ""logseq/pages/TTA KB Automation___SessionContextBuilder.md"","
scripts/link_orphans.py,71,code,py,"""logseq/pages/TTA KB Automation___TODO Sync.md"",","        ""logseq/pages/TTA KB Automation___LinkValidator.md"", |         ""logseq/pages/TTA KB Automation___SessionContextBuilder.md"", |         ""logseq/pages/TTA KB Automation___TODO Sync.md"", |         ""logseq/pages/TTA Primitives___CachePrimitive.md"", |         ""logseq/pages/TTA Primitives___CompensationPrimitive.md"","
scripts/link_orphans.py,128,code,py,"""logseq/pages/TTA.dev___How-To___Debugging Workflows.md"",","        ""logseq/pages/TTA.dev___How-To___Building Reliable AI Workflows.md"", |         ""logseq/pages/TTA.dev___How-To___Custom Primitive Development.md"", |         ""logseq/pages/TTA.dev___How-To___Debugging Workflows.md"", |         ""logseq/pages/TTA.dev___How-To___Integrating External Services.md"", |         ""logseq/pages/TTA.dev___How-To___Performance Tuning.md"","
scripts/link_orphans.py,162,code,py,"""logseq/pages/Whiteboard - TODO Dependency Network.md"",","        ""logseq/pages/Whiteboard - Agentic Development Workflow.md"", |         ""logseq/pages/Whiteboard - Primitive Composition Patterns.md"", |         ""logseq/pages/Whiteboard - TODO Dependency Network.md"", |         ""logseq/pages/Whiteboard - Testing Architecture.md"", |         ""logseq/pages/Workflow.md"","
scripts/analyze_real_broken_links.py,54,code,py,"""TODO"",","        ""Public"", |         ""Private"", |         ""TODO"", |         ""DOING"", |         ""DONE"","
scripts/analyze_real_broken_links.py,67,code,py,"""Implementation TODO"",","        ""Performance"", |         ""Testing"", |         ""Implementation TODO"", |         ""Integration TODO"", |         ""Documentation TODO"","
scripts/analyze_real_broken_links.py,68,code,py,"""Integration TODO"",","        ""Testing"", |         ""Implementation TODO"", |         ""Integration TODO"", |         ""Documentation TODO"", |         ""Testing TODO"","
scripts/analyze_real_broken_links.py,69,code,py,"""Documentation TODO"",","        ""Implementation TODO"", |         ""Integration TODO"", |         ""Documentation TODO"", |         ""Testing TODO"", |     }"
scripts/analyze_real_broken_links.py,70,code,py,"""Testing TODO"",","        ""Integration TODO"", |         ""Documentation TODO"", |         ""Testing TODO"", |     } | "
scripts/analyze_real_broken_links.py,89,code,py,"""Installation TODO"",","        ""Document Type"", |         ""Getting Started"", |         ""Installation TODO"", |         ""Introduction TODO"", |         ""First Workflow TODO"","
scripts/analyze_real_broken_links.py,90,code,py,"""Introduction TODO"",","        ""Getting Started"", |         ""Installation TODO"", |         ""Introduction TODO"", |         ""First Workflow TODO"", |         ""Basic Primitives TODO"","
scripts/analyze_real_broken_links.py,91,code,py,"""First Workflow TODO"",","        ""Installation TODO"", |         ""Introduction TODO"", |         ""First Workflow TODO"", |         ""Basic Primitives TODO"", |     ]:"
scripts/analyze_real_broken_links.py,92,code,py,"""Basic Primitives TODO"",","        ""Introduction TODO"", |         ""First Workflow TODO"", |         ""Basic Primitives TODO"", |     ]: |         return True, ""generic_reference"""
scripts/setup-notebooklm-mcp.sh,2,other,sh,# Configure NotebookLM MCP Server for TTA Research Integration,#!/bin/bash | # Configure NotebookLM MCP Server for TTA Research Integration |  | MCP_CONFIG=~/.config/mcp/mcp_settings.json
scripts/setup-notebooklm-mcp.sh,7,other,sh,"echo ""ðŸ”§ Configuring NotebookLM MCP Server...""","GEMINI_KEY=$(grep GEMINI_API_KEY ~/repos/TTA.dev/.env | cut -d= -f2) |  | echo ""ðŸ”§ Configuring NotebookLM MCP Server..."" |  | # Backup existing config"
scripts/setup-notebooklm-mcp.sh,12,other,sh,# Update MCP config with NotebookLM server,"cp ""$MCP_CONFIG"" ""$MCP_CONFIG.backup.$(date +%Y%m%d_%H%M%S)"" |  | # Update MCP config with NotebookLM server | cat > /tmp/mcp_update.py << 'PYTHON' | import json"
scripts/setup-notebooklm-mcp.sh,24,other,sh,# Add NotebookLM server,"    config = json.load(f) |  | # Add NotebookLM server | config['mcpServers']['notebooklm'] = { |     ""command"": ""node"","
scripts/setup-notebooklm-mcp.sh,25,other,sh,config['mcpServers']['notebooklm'] = {," | # Add NotebookLM server | config['mcpServers']['notebooklm'] = { |     ""command"": ""node"", |     ""args"": ["
scripts/setup-notebooklm-mcp.sh,28,other,sh,"f""{os.path.expanduser('~/mcp-servers/notebooklm-mcp/dist/index.js')}""","    ""command"": ""node"", |     ""args"": [ |         f""{os.path.expanduser('~/mcp-servers/notebooklm-mcp/dist/index.js')}"" |     ], |     ""env"": {"
scripts/setup-notebooklm-mcp.sh,39,other,sh,"print(f""âœ… NotebookLM MCP server added to {config_path}"")","    json.dump(config, f, indent=4) |  | print(f""âœ… NotebookLM MCP server added to {config_path}"") | PYTHON | "
scripts/setup-notebooklm-mcp.sh,50,other,sh,"echo ""3. Test with: 'Query NotebookLM about TTA'""","echo ""1. Reload VS Code window (Ctrl+Shift+P â†’ 'Developer: Reload Window')"" | echo ""2. Check tools available in Copilot"" | echo ""3. Test with: 'Query NotebookLM about TTA'"" | "
scripts/manage_mcp_servers.py,88,code,py,# Debug flag,"    ) |  |     # Debug flag |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") | "
scripts/manage_mcp_servers.py,89,code,py,"parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"")"," |     # Debug flag |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") |  |     return parser.parse_args()"
scripts/manage_mcp_servers.py,231,code,py,if args.debug:," |     # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"")"
scripts/manage_mcp_servers.py,232,code,py,logging.getLogger().setLevel(logging.DEBUG),"    # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") | "
scripts/manage_mcp_servers.py,233,code,py,"logger.debug(""Debug logging enabled"")","    if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") |  |     # Create MCP server manager"
scripts/validate-todos.py,3,code,py,Logseq TODO Validation Script,"#!/usr/bin/env python3 | """""" | Logseq TODO Validation Script |  | Validates TODO compliance with the Logseq TODO Management System."
scripts/validate-todos.py,5,code,py,Validates TODO compliance with the Logseq TODO Management System.,Logseq TODO Validation Script |  | Validates TODO compliance with the Logseq TODO Management System. |  | Checks:
scripts/validate-todos.py,8,code,py,"- All TODOs have required properties (type::, priority::, etc.)"," | Checks: | - All TODOs have required properties (type::, priority::, etc.) | - Completed TODOs have completion dates | - TODOs are in correct journal files"
scripts/validate-todos.py,9,code,py,- Completed TODOs have completion dates,"Checks: | - All TODOs have required properties (type::, priority::, etc.) | - Completed TODOs have completion dates | - TODOs are in correct journal files | - KB page references exist"
scripts/validate-todos.py,10,code,py,- TODOs are in correct journal files,"- All TODOs have required properties (type::, priority::, etc.) | - Completed TODOs have completion dates | - TODOs are in correct journal files | - KB page references exist | - Task status is uppercase (TODO, DOING, DONE)"
scripts/validate-todos.py,12,code,py,"- Task status is uppercase (TODO, DOING, DONE)","- TODOs are in correct journal files | - KB page references exist | - Task status is uppercase (TODO, DOING, DONE) |  | Usage:"
scripts/validate-todos.py,15,code,py,uv run python scripts/validate-todos.py, | Usage: |     uv run python scripts/validate-todos.py |     uv run python scripts/validate-todos.py --fix  # Auto-fix issues |     uv run python scripts/validate-todos.py --json  # JSON output
scripts/validate-todos.py,16,code,py,uv run python scripts/validate-todos.py --fix  # Auto-fix issues,Usage: |     uv run python scripts/validate-todos.py |     uv run python scripts/validate-todos.py --fix  # Auto-fix issues |     uv run python scripts/validate-todos.py --json  # JSON output | 
scripts/validate-todos.py,17,code,py,uv run python scripts/validate-todos.py --json  # JSON output,    uv run python scripts/validate-todos.py |     uv run python scripts/validate-todos.py --fix  # Auto-fix issues |     uv run python scripts/validate-todos.py --json  # JSON output |  | Exit codes:
scripts/validate-todos.py,20,code,py,0 - All TODOs compliant, | Exit codes: |     0 - All TODOs compliant |     1 - Validation errors found |     2 - Script error
scripts/validate-todos.py,34,code,py,class TODOIssue:," | @dataclass | class TODOIssue: |     """"""Represents a TODO compliance issue."""""" | "
scripts/validate-todos.py,35,code,py,"""""""Represents a TODO compliance issue.""""""","@dataclass | class TODOIssue: |     """"""Represents a TODO compliance issue."""""" |  |     file_path: Path"
scripts/validate-todos.py,42,code,py,todo_text: str,"    severity: str  # error, warning, info |     message: str |     todo_text: str |     suggested_fix: str | None = None | "
scripts/validate-todos.py,48,code,py,"""""""Results of TODO validation.""""""","@dataclass | class ValidationResult: |     """"""Results of TODO validation."""""" |  |     total_todos: int = 0"
scripts/validate-todos.py,50,code,py,total_todos: int = 0,"    """"""Results of TODO validation."""""" |  |     total_todos: int = 0 |     compliant_todos: int = 0 |     issues: list[TODOIssue] = field(default_factory=list)"
scripts/validate-todos.py,51,code,py,compliant_todos: int = 0, |     total_todos: int = 0 |     compliant_todos: int = 0 |     issues: list[TODOIssue] = field(default_factory=list) |     missing_kb_pages: set[str] = field(default_factory=set)
scripts/validate-todos.py,52,code,py,issues: list[TODOIssue] = field(default_factory=list),    total_todos: int = 0 |     compliant_todos: int = 0 |     issues: list[TODOIssue] = field(default_factory=list) |     missing_kb_pages: set[str] = field(default_factory=set) | 
scripts/validate-todos.py,58,code,py,if self.total_todos == 0:,"    def compliance_rate(self) -> float: |         """"""Calculate compliance rate."""""" |         if self.total_todos == 0: |             return 100.0 |         return (self.compliant_todos / self.total_todos) * 100"
scripts/validate-todos.py,60,code,py,return (self.compliant_todos / self.total_todos) * 100,        if self.total_todos == 0: |             return 100.0 |         return (self.compliant_todos / self.total_todos) * 100 |  | 
scripts/validate-todos.py,63,code,py,class TODOValidator:," |  | class TODOValidator: |     """"""Validates Logseq TODOs against compliance rules."""""" | "
scripts/validate-todos.py,64,code,py,"""""""Validates Logseq TODOs against compliance rules."""""""," | class TODOValidator: |     """"""Validates Logseq TODOs against compliance rules."""""" |  |     def __init__(self, logseq_root: Path, quiet: bool = False):"
scripts/validate-todos.py,73,code,py,self.todo_pattern = re.compile(," |         # Regex patterns |         self.todo_pattern = re.compile( |             r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later|now|waiting)\s+(.+)"", |             re.MULTILINE,"
scripts/validate-todos.py,74,code,py,"r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later|now|waiting)\s+(.+)"",","        # Regex patterns |         self.todo_pattern = re.compile( |             r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later|now|waiting)\s+(.+)"", |             re.MULTILINE, |         )"
scripts/validate-todos.py,81,code,py,"""""""Validate all journal TODOs."""""""," |     def validate_journals(self) -> ValidationResult: |         """"""Validate all journal TODOs."""""" |         result = ValidationResult() | "
scripts/validate-todos.py,102,code,py,"""""""Validate TODOs in a single file."""""""," |     def _validate_file(self, file_path: Path, result: ValidationResult) -> None: |         """"""Validate TODOs in a single file."""""" |         try: |             content = file_path.read_text(encoding=""utf-8"")"
scripts/validate-todos.py,110,code,py,match = self.todo_pattern.match(line),            while i < len(lines): |                 line = lines[i] |                 match = self.todo_pattern.match(line) |  |                 if match:
scripts/validate-todos.py,113,code,py,result.total_todos += 1, |                 if match: |                     result.total_todos += 1 |                     status = match.group(1) |                     todo_text = match.group(2)
scripts/validate-todos.py,115,code,py,todo_text = match.group(2),                    result.total_todos += 1 |                     status = match.group(1) |                     todo_text = match.group(2) |  |                     # Check 1: Status case (should be uppercase)
scripts/validate-todos.py,120,code,py,TODOIssue(,"                    if status.lower() == status: |                         result.issues.append( |                             TODOIssue( |                                 file_path=file_path, |                                 line_number=i + 1,"
scripts/validate-todos.py,126,code,py,"todo_text=line.strip(),","                                severity=""error"", |                                 message=f""Task status should be uppercase: {status}"", |                                 todo_text=line.strip(), |                                 suggested_fix=line.replace(status, status.upper()), |                             )"
scripts/validate-todos.py,136,code,py,"file_path, i + 1, line, todo_text, properties, result","                        # Check 2: Required properties |                         is_compliant = self._check_required_properties( |                             file_path, i + 1, line, todo_text, properties, result |                         ) | "
scripts/validate-todos.py,140,code,py,"self._check_kb_references(todo_text, result)"," |                         # Check 3: KB page references |                         self._check_kb_references(todo_text, result) |  |                         if is_compliant:"
scripts/validate-todos.py,143,code,py,result.compliant_todos += 1, |                         if is_compliant: |                             result.compliant_todos += 1 |  |                 i += 1
scripts/validate-todos.py,151,code,py,"""""""Parse properties following a TODO line."""""""," |     def _parse_properties(self, lines: list[str], start_idx: int) -> dict[str, str]: |         """"""Parse properties following a TODO line."""""" |         properties = {} |         i = start_idx"
scripts/validate-todos.py,173,code,py,"todo_text: str,","        line_number: int, |         line: str, |         todo_text: str, |         properties: dict[str, str], |         result: ValidationResult,"
scripts/validate-todos.py,177,code,py,"""""""Check if TODO has required properties.""""""","        result: ValidationResult, |     ) -> bool: |         """"""Check if TODO has required properties."""""" |         is_compliant = True | "
scripts/validate-todos.py,180,code,py,# Determine TODO category,"        is_compliant = True |  |         # Determine TODO category |         is_dev_todo = ""#dev-todo"" in todo_text |         is_user_todo = ""#user-todo"" in todo_text"
scripts/validate-todos.py,181,code,py,"is_dev_todo = ""#dev-todo"" in todo_text"," |         # Determine TODO category |         is_dev_todo = ""#dev-todo"" in todo_text |         is_user_todo = ""#user-todo"" in todo_text | "
scripts/validate-todos.py,182,code,py,"is_user_todo = ""#user-todo"" in todo_text","        # Determine TODO category |         is_dev_todo = ""#dev-todo"" in todo_text |         is_user_todo = ""#user-todo"" in todo_text |  |         if not is_dev_todo and not is_user_todo:"
scripts/validate-todos.py,184,code,py,if not is_dev_todo and not is_user_todo:,"        is_user_todo = ""#user-todo"" in todo_text |  |         if not is_dev_todo and not is_user_todo: |             result.issues.append( |                 TODOIssue("
scripts/validate-todos.py,186,code,py,TODOIssue(,"        if not is_dev_todo and not is_user_todo: |             result.issues.append( |                 TODOIssue( |                     file_path=file_path, |                     line_number=line_number,"
scripts/validate-todos.py,191,code,py,"message=""TODO missing category tag (#dev-todo or #user-todo)"",","                    issue_type=""missing_tag"", |                     severity=""error"", |                     message=""TODO missing category tag (#dev-todo or #user-todo)"", |                     todo_text=line.strip(), |                     suggested_fix=f""{line.strip()} #dev-todo"","
scripts/validate-todos.py,192,code,py,"todo_text=line.strip(),","                    severity=""error"", |                     message=""TODO missing category tag (#dev-todo or #user-todo)"", |                     todo_text=line.strip(), |                     suggested_fix=f""{line.strip()} #dev-todo"", |                 )"
scripts/validate-todos.py,193,code,py,"suggested_fix=f""{line.strip()} #dev-todo"",","                    message=""TODO missing category tag (#dev-todo or #user-todo)"", |                     todo_text=line.strip(), |                     suggested_fix=f""{line.strip()} #dev-todo"", |                 ) |             )"
scripts/validate-todos.py,199,code,py,if is_dev_todo:," |         # Check required properties for dev-todo |         if is_dev_todo: |             if ""type"" not in properties: |                 result.issues.append("
scripts/validate-todos.py,202,code,py,TODOIssue(,"            if ""type"" not in properties: |                 result.issues.append( |                     TODOIssue( |                         file_path=file_path, |                         line_number=line_number,"
scripts/validate-todos.py,208,code,py,"todo_text=line.strip(),","                        severity=""error"", |                         message=""Missing required property: type::"", |                         todo_text=line.strip(), |                         suggested_fix=""  type:: implementation"", |                     )"
scripts/validate-todos.py,216,code,py,TODOIssue(,"            if ""priority"" not in properties: |                 result.issues.append( |                     TODOIssue( |                         file_path=file_path, |                         line_number=line_number,"
scripts/validate-todos.py,222,code,py,"todo_text=line.strip(),","                        severity=""error"", |                         message=""Missing required property: priority::"", |                         todo_text=line.strip(), |                         suggested_fix=""  priority:: medium"", |                     )"
scripts/validate-todos.py,229,code,py,if is_user_todo:," |         # Check required properties for user-todo |         if is_user_todo: |             if ""type"" not in properties: |                 result.issues.append("
scripts/validate-todos.py,232,code,py,TODOIssue(,"            if ""type"" not in properties: |                 result.issues.append( |                     TODOIssue( |                         file_path=file_path, |                         line_number=line_number,"
scripts/validate-todos.py,238,code,py,"todo_text=line.strip(),","                        severity=""error"", |                         message=""Missing required property: type::"", |                         todo_text=line.strip(), |                         suggested_fix=""  type:: learning"", |                     )"
scripts/validate-todos.py,246,code,py,TODOIssue(,"            if ""audience"" not in properties: |                 result.issues.append( |                     TODOIssue( |                         file_path=file_path, |                         line_number=line_number,"
scripts/validate-todos.py,252,code,py,"todo_text=line.strip(),","                        severity=""warning"", |                         message=""Missing recommended property: audience::"", |                         todo_text=line.strip(), |                         suggested_fix=""  audience:: intermediate-users"", |                     )"
scripts/validate-todos.py,260,code,py,TODOIssue(,"        if ""DONE"" in line and ""completed"" not in properties: |             result.issues.append( |                 TODOIssue( |                     file_path=file_path, |                     line_number=line_number,"
scripts/validate-todos.py,266,code,py,"todo_text=line.strip(),","                    severity=""warning"", |                     message=""DONE task missing completed:: date"", |                     todo_text=line.strip(), |                     suggested_fix=""  completed:: [[2025-10-31]]"", |                 )"
scripts/validate-todos.py,273,code,py,"def _check_kb_references(self, todo_text: str, result: ValidationResult) -> None:","        return is_compliant |  |     def _check_kb_references(self, todo_text: str, result: ValidationResult) -> None: |         """"""Check if KB page references exist."""""" |         matches = self.kb_link_pattern.findall(todo_text)"
scripts/validate-todos.py,275,code,py,matches = self.kb_link_pattern.findall(todo_text),"    def _check_kb_references(self, todo_text: str, result: ValidationResult) -> None: |         """"""Check if KB page references exist."""""" |         matches = self.kb_link_pattern.findall(todo_text) |  |         for page_name in matches:"
scripts/validate-todos.py,290,code,py,"print(""ðŸ“Š TODO VALIDATION RESULTS"")","    """"""Print validation results in human-readable format."""""" |     print(""\n"" + ""="" * 80) |     print(""ðŸ“Š TODO VALIDATION RESULTS"") |     print(""="" * 80) | "
scripts/validate-todos.py,293,code,py,"print(f""\nâœ… Total TODOs found: {result.total_todos}"")","    print(""="" * 80) |  |     print(f""\nâœ… Total TODOs found: {result.total_todos}"") |     print(f""âœ… Compliant TODOs: {result.compliant_todos}"") |     print(f""âŒ Non-compliant TODOs: {result.total_todos - result.compliant_todos}"")"
scripts/validate-todos.py,294,code,py,"print(f""âœ… Compliant TODOs: {result.compliant_todos}"")"," |     print(f""\nâœ… Total TODOs found: {result.total_todos}"") |     print(f""âœ… Compliant TODOs: {result.compliant_todos}"") |     print(f""âŒ Non-compliant TODOs: {result.total_todos - result.compliant_todos}"") |     print(f""ðŸ“ˆ Compliance rate: {result.compliance_rate:.1f}%"")"
scripts/validate-todos.py,295,code,py,"print(f""âŒ Non-compliant TODOs: {result.total_todos - result.compliant_todos}"")","    print(f""\nâœ… Total TODOs found: {result.total_todos}"") |     print(f""âœ… Compliant TODOs: {result.compliant_todos}"") |     print(f""âŒ Non-compliant TODOs: {result.total_todos - result.compliant_todos}"") |     print(f""ðŸ“ˆ Compliance rate: {result.compliance_rate:.1f}%"") | "
scripts/validate-todos.py,309,code,py,"print(f""    TODO: {issue.todo_text}"")","            for issue in errors[:10]:  # Show first 10 |                 print(f""  {issue.file_path.name}:{issue.line_number} - {issue.message}"") |                 print(f""    TODO: {issue.todo_text}"") |                 if issue.suggested_fix: |                     print(f""    Fix: {issue.suggested_fix}"")"
scripts/validate-todos.py,318,code,py,"print(f""    TODO: {issue.todo_text}"")","            for issue in warnings[:10]:  # Show first 10 |                 print(f""  {issue.file_path.name}:{issue.line_number} - {issue.message}"") |                 print(f""    TODO: {issue.todo_text}"") |                 print() | "
scripts/validate-todos.py,331,code,py,"parser = argparse.ArgumentParser(description=""Validate Logseq TODOs"")","def main() -> int: |     """"""Main entry point."""""" |     parser = argparse.ArgumentParser(description=""Validate Logseq TODOs"") |     parser.add_argument( |         ""--logseq-root"","
scripts/validate-todos.py,350,code,py,"validator = TODOValidator(args.logseq_root, quiet=args.json)","        return 2 |  |     validator = TODOValidator(args.logseq_root, quiet=args.json) |     result = validator.validate_journals() | "
scripts/validate-todos.py,356,code,py,"""total_todos"": result.total_todos,","        # JSON output for CI/CD |         output = { |             ""total_todos"": result.total_todos, |             ""compliant_todos"": result.compliant_todos, |             ""compliance_rate"": result.compliance_rate,"
scripts/validate-todos.py,357,code,py,"""compliant_todos"": result.compliant_todos,","        output = { |             ""total_todos"": result.total_todos, |             ""compliant_todos"": result.compliant_todos, |             ""compliance_rate"": result.compliance_rate, |             ""issues_count"": len(result.issues),"
scripts/start_mcp_servers.py,47,code,py,"parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"")","    ) |  |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") |  |     return parser.parse_args()"
scripts/start_mcp_servers.py,58,code,py,if args.debug:," |     # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"")"
scripts/start_mcp_servers.py,59,code,py,logging.getLogger().setLevel(logging.DEBUG),"    # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") | "
scripts/start_mcp_servers.py,60,code,py,"logger.debug(""Debug logging enabled"")","    if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") |  |     # Create MCP configuration"
scripts/validate-package.sh,156,other,sh,"grep -v -E ""(test|mock|example|TODO|FIXME)"" | grep -q .; then","# Check for common secrets patterns | if grep -r -i -E ""(api[_-]?key|password|secret|token)"" packages/$PACKAGE/src/ --exclude-dir=__pycache__ | \ |    grep -v -E ""(test|mock|example|TODO|FIXME)"" | grep -q .; then |   echo -e ""${YELLOW}  âš ${NC}  Potential secrets found (review manually)"" | else"
scripts/mcp/manage_mcp_servers.py,88,code,py,# Debug flag,"    ) |  |     # Debug flag |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") | "
scripts/mcp/manage_mcp_servers.py,89,code,py,"parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"")"," |     # Debug flag |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") |  |     return parser.parse_args()"
scripts/mcp/manage_mcp_servers.py,231,code,py,if args.debug:," |     # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"")"
scripts/mcp/manage_mcp_servers.py,232,code,py,logging.getLogger().setLevel(logging.DEBUG),"    # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") | "
scripts/mcp/manage_mcp_servers.py,233,code,py,"logger.debug(""Debug logging enabled"")","    if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") |  |     # Create MCP server manager"
scripts/mcp/start_mcp_servers.py,47,code,py,"parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"")","    ) |  |     parser.add_argument(""--debug"", action=""store_true"", help=""Enable debug logging"") |  |     return parser.parse_args()"
scripts/mcp/start_mcp_servers.py,58,code,py,if args.debug:," |     # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"")"
scripts/mcp/start_mcp_servers.py,59,code,py,logging.getLogger().setLevel(logging.DEBUG),"    # Configure logging |     if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") | "
scripts/mcp/start_mcp_servers.py,60,code,py,"logger.debug(""Debug logging enabled"")","    if args.debug: |         logging.getLogger().setLevel(logging.DEBUG) |         logger.debug(""Debug logging enabled"") |  |     # Create MCP configuration"
scripts/setup/cline-agent.sh,268,other,sh,### Debugging Issues,7. Update catalog and documentation |  | ### Debugging Issues | 1. Use Pylance MCP for syntax/import analysis | 2. Check observability data with Grafana MCP
scripts/config/generate_assistant_configs.py,54,code,py,# Note: agent_instructions_file removed - AGENTS.md is now workspace-wide hub,"    output_dir: str = Field(..., description=""Output directory for generated files"") |     repository_wide_file: str | None = Field(None, description=""Repository-wide instructions file"") |     # Note: agent_instructions_file removed - AGENTS.md is now workspace-wide hub |     path_specific_dir: str | None = Field(None, description=""Directory for path-specific rules"") |     path_specific_extension: str = Field("
scripts/config/generate_assistant_configs.py,436,code,py,"> **Note**: This file provides Claude-specific guidance. For general agent behavior applicable to all AI assistants, see [`AGENTS.md`](./AGENTS.md).","        hub_header = """"""# Claude-Specific Instructions |  | > **Note**: This file provides Claude-specific guidance. For general agent behavior applicable to all AI assistants, see [`AGENTS.md`](./AGENTS.md). |  | ## Purpose"
scripts/config/generate_assistant_configs.py,501,code,py,**Note**: Do not edit this file directly. Make changes in `.universal-instructions/claude-specific/` and regenerate.,"**Last Updated**: {current_date} |  | **Note**: Do not edit this file directly. Make changes in `.universal-instructions/claude-specific/` and regenerate. | """""" | "
scripts/config/generate_assistant_configs.py,636,code,py,# Note: Agent instructions now generated as workspace-wide AGENTS.md hub (not per-tool),"        # Create workflow generators |         repo_gen = GenerateRepositoryWidePrimitive(self.universal_dir) |         # Note: Agent instructions now generated as workspace-wide AGENTS.md hub (not per-tool) |         path_gen = GenerateAllPathSpecificPrimitive(self.universal_dir, self.rules) | "
scripts/from_root/validate_templates.py,129,code,py,"print(""ðŸ”§ Action needed: Debug ML template configuration"")","    elif default_success and not ml_success: |         print(""\nâš ï¸ CONCLUSION: ML template has issues, default works"") |         print(""ðŸ”§ Action needed: Debug ML template configuration"") |  |     elif not default_success and not ml_success:"
scripts/from_root/launch-n8n-advanced.sh,110,other,sh,# Note: n8n API import requires authentication and is complex,"  echo -e ""${YELLOW}ðŸ“¥ Importing: ${workflow_name}${NC}"" |  |   # Note: n8n API import requires authentication and is complex |   # For now, we'll provide instructions for manual import |   # Future enhancement: Use n8n API with proper authentication"
scripts/docs/README.md,49,non-actionable,md,**Note**: Actual execution of code blocks requires `RUN_DOCS_CODE=true` and is intended for CI environments only.,\`\`\` |  | **Note**: Actual execution of code blocks requires `RUN_DOCS_CODE=true` and is intended for CI environments only. |  | ### Exclusions
scripts/docs/check_md.py,266,non-actionable,py,# TODO: Implement safe code block execution with timeouts and mocking," |             print(""\nðŸš€ Running code blocks..."") |             # TODO: Implement safe code block execution with timeouts and mocking |             print(""âš ï¸  Code execution not yet implemented - use with caution in CI only"") |             return 1"
scripts/validation/validate-package.sh,156,other,sh,"grep -v -E ""(test|mock|example|TODO|FIXME)"" | grep -q .; then","# Check for common secrets patterns | if grep -r -i -E ""(api[_-]?key|password|secret|token)"" packages/$PACKAGE/src/ --exclude-dir=__pycache__ | \ |    grep -v -E ""(test|mock|example|TODO|FIXME)"" | grep -q .; then |   echo -e ""${YELLOW}  âš ${NC}  Potential secrets found (review manually)"" | else"
scripts/cline/review-diff.sh,160,other,sh,- Potential bugs,   - Documentation gaps |    - TTA.dev pattern violations |    - Potential bugs |  | 2. Provide:
scripts/cline/review-diff.sh,184,other,sh,- Obvious bugs or errors, | Focus on: | - Obvious bugs or errors | - Breaking changes | - Security issues
local/README.md,3,other,md,"**Purpose:** Personal workspace for experimental code, session notes, and temporary files","# local/ Directory |  | **Purpose:** Personal workspace for experimental code, session notes, and temporary files |  | **NOT for production code** - See organization guide below"
local/README.md,22,other,md,- Logseq knowledge base (use separate TTA-notes repo),- Production code (use `packages/` or `src/`) | - Public documentation (use `docs/`) | - Logseq knowledge base (use separate TTA-notes repo) | - Quick reference guides (keep in repository root if referenced by AGENTS.md) | 
local/README.md,27,other,md,- Session notes and completion reports,## âœ… What to Put Here |  | - Session notes and completion reports | - Temporary analysis documents | - Planning docs for features in progress
local/README.md,42,other,md,**Note:** This directory is gitignored. Content here is local to your machine only.,--- |  | **Note:** This directory is gitignored. Content here is local to your machine only. | 
local/session-reports/LOGSEQ_COMPLETE_PACKAGE.md,114,other,md,# All TODO tasks this week,{{query (and (page-property type [[Primitive]]) (page-property status [[Stable]]))}} |  | # All TODO tasks this week | {{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}} | 
local/session-reports/LOGSEQ_COMPLETE_PACKAGE.md,115,other,md,{{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}}, | # All TODO tasks this week | {{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}} |  | # All examples using RouterPrimitive
local/session-reports/DAY_2_COMPLETION_REPORT.md,74,other,md,"db = SupabasePrimitive(url=""https://xxx.supabase.co"", key=""your-key"")"," | # Create primitive | db = SupabasePrimitive(url=""https://xxx.supabase.co"", key=""your-key"") |  | # Select with filters"
local/session-reports/LOGSEQ_MIGRATION_SESSION_COMPLETE.md,58,other,md,{{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}}, | # Current sprint tasks | {{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}} |  | # Recently completed
local/session-reports/LOGSEQ_MIGRATION_SESSION_COMPLETE.md,105,other,md,â”‚   â””â”€â”€ ... (7 more TODO),â”‚   â”œâ”€â”€ RouterPrimitive âœ… | â”‚   â”œâ”€â”€ RetryPrimitive âœ… | â”‚   â””â”€â”€ ... (7 more TODO) | â”œâ”€â”€ Guides/ | â”‚   â”œâ”€â”€ Getting Started âœ…
local/session-reports/LOGSEQ_MIGRATION_SESSION_COMPLETE.md,108,other,md,â”‚   â””â”€â”€ ... (14 more TODO),â”œâ”€â”€ Guides/ | â”‚   â”œâ”€â”€ Getting Started âœ… | â”‚   â””â”€â”€ ... (14 more TODO) | â”œâ”€â”€ Packages/ | â”‚   â”œâ”€â”€ tta-dev-primitives
local/session-reports/LOGSEQ_MIGRATION_SESSION_COMPLETE.md,147,other,md,- Task lists (TODO/DOING/DONE),"   - Phase completion status |    - Statistics (coverage, quality metrics) |    - Task lists (TODO/DOING/DONE) |    - Next actions | "
local/session-reports/LOGSEQ_MIGRATION_SESSION_COMPLETE.md,411,other,md,{{query (task TODO DOING)}},{{query (and [[Tag1]] [[Tag2]])}} | {{query (page-property type [[Primitive]])}} | {{query (task TODO DOING)}} |  | # Tables v2
local/session-reports/SESSION_5_COMPLETION_REPORT.md,41,other,md,5. **Debugging Workflows** (~800 lines),"   - Monitoring: Prometheus metrics with request_duration histogram, memory_usage gauge, cache_hit_rate gauge |  | 5. **Debugging Workflows** (~800 lines) |    - File: `TTA.dev___How-To___Debugging Workflows.md` |    - Content: Debugging strategies (context checkpoints, structured logging, distributed tracing), common issues (workflow hangs, inconsistent results, memory leaks), debugging tools (logging, OpenTelemetry, debugger, pytest)"
local/session-reports/SESSION_5_COMPLETION_REPORT.md,42,other,md,- File: `TTA.dev___How-To___Debugging Workflows.md`," | 5. **Debugging Workflows** (~800 lines) |    - File: `TTA.dev___How-To___Debugging Workflows.md` |    - Content: Debugging strategies (context checkpoints, structured logging, distributed tracing), common issues (workflow hangs, inconsistent results, memory leaks), debugging tools (logging, OpenTelemetry, debugger, pytest) |    - Techniques: 7 techniques (context checkpoints, structured logging, request tracing, state inspection, input/output validation, replay and testing, differential debugging)"
local/session-reports/SESSION_5_COMPLETION_REPORT.md,43,other,md,"- Content: Debugging strategies (context checkpoints, structured logging, distributed tracing), common issues (workflow hangs, inconsistent results, memory leaks), debugging tools (logging, OpenTelemetry, debugger, pytest)","5. **Debugging Workflows** (~800 lines) |    - File: `TTA.dev___How-To___Debugging Workflows.md` |    - Content: Debugging strategies (context checkpoints, structured logging, distributed tracing), common issues (workflow hangs, inconsistent results, memory leaks), debugging tools (logging, OpenTelemetry, debugger, pytest) |    - Techniques: 7 techniques (context checkpoints, structured logging, request tracing, state inspection, input/output validation, replay and testing, differential debugging) |    - Troubleshooting: 3 issues (hangs, inconsistency, memory leaks) with symptoms and solutions"
local/session-reports/SESSION_5_COMPLETION_REPORT.md,44,other,md,"- Techniques: 7 techniques (context checkpoints, structured logging, request tracing, state inspection, input/output validation, replay and testing, differential debugging)","   - File: `TTA.dev___How-To___Debugging Workflows.md` |    - Content: Debugging strategies (context checkpoints, structured logging, distributed tracing), common issues (workflow hangs, inconsistent results, memory leaks), debugging tools (logging, OpenTelemetry, debugger, pytest) |    - Techniques: 7 techniques (context checkpoints, structured logging, request tracing, state inspection, input/output validation, replay and testing, differential debugging) |    - Troubleshooting: 3 issues (hangs, inconsistency, memory leaks) with symptoms and solutions | "
local/session-reports/SESSION_5_COMPLETION_REPORT.md,80,other,md,> **CRITICAL RULE:** `.md` files without Logseq properties MAY BE DELETED at any time as temporary notes. Only Logseq-formatted files are permanent documentation., | **Core Principle:** | > **CRITICAL RULE:** `.md` files without Logseq properties MAY BE DELETED at any time as temporary notes. Only Logseq-formatted files are permanent documentation. |  | **Content:**
local/session-reports/SESSION_5_COMPLETION_REPORT.md,169,other,md,5. âœ… Debugging Workflows,3. âœ… Custom Primitive Development | 4. âœ… Performance Tuning | 5. âœ… Debugging Workflows |  | **Agent Standards (1/1):**
local/session-reports/SESSION_5_COMPLETION_REPORT.md,185,other,md,- **Debugging:** Systematic debugging techniques,- **Extension:** Custom primitive development | - **Performance:** Profiling and optimization | - **Debugging:** Systematic debugging techniques |  | ### 2. Architecture Pattern Catalog
local/session-reports/SESSION_5_COMPLETION_REPORT.md,230,other,md,- Debugging Workflows: ~800 lines,"- Custom Primitive Development: ~920 lines | - Performance Tuning: ~800 lines | - Debugging Workflows: ~800 lines | - Logseq Documentation Standards: ~1,000 lines | - Validation script: ~200 lines"
local/session-reports/SESSION_5_COMPLETION_REPORT.md,336,other,md,### Debugging Techniques Documented,- OpenTelemetry for distributed tracing |  | ### Debugging Techniques Documented |  | **7 Systematic techniques:**
local/session-reports/SESSION_5_COMPLETION_REPORT.md,345,other,md,7. Differential debugging - Compare execution paths,5. Input/output validation - Pydantic models | 6. Replay and testing - Record/replay executions | 7. Differential debugging - Compare execution paths |  | **3 Common issues:**
local/session-reports/SESSION_5_COMPLETION_REPORT.md,383,other,md,- **Debugging playbook:** Systematic debugging techniques,"- **Complete How-To coverage:** Step-by-step guides for all production scenarios | - **Architecture patterns:** Proven patterns with decision framework | - **Debugging playbook:** Systematic debugging techniques | - **Performance optimization:** Profiling and tuning strategies | - **Integration patterns:** REST, DB, queue, webhook examples"
local/session-reports/SESSION_5_COMPLETION_REPORT.md,389,other,md,- **Debugging:** Systematic techniques reduce debugging time 50%+,**Time savings:** | - **Building workflows:** Architecture patterns provide ready templates | - **Debugging:** Systematic techniques reduce debugging time 50%+ | - **Optimization:** Profiling tools identify bottlenecks quickly | - **Integration:** Complete examples eliminate guesswork
local/session-reports/SESSION_5_COMPLETION_REPORT.md,547,other,md,- **7 debugging techniques** systematically documented,"- **33 files created** across 5 sessions | - **8 architecture patterns** with case studies | - **7 debugging techniques** systematically documented | - **1,000-line** agent standards guide | "
local/session-reports/SESSION_5_COMPLETION_REPORT.md,574,other,md,6. **Debugging Workflows:** `TTA.dev___How-To___Debugging Workflows.md`,4. **Custom Primitive Development:** `TTA.dev___How-To___Custom Primitive Development.md` | 5. **Performance Tuning:** `TTA.dev___How-To___Performance Tuning.md` | 6. **Debugging Workflows:** `TTA.dev___How-To___Debugging Workflows.md` | 7. **Logseq Documentation Standards:** `TTA.dev___Guides___Logseq Documentation Standards for Agents.md` | 8. **Validation Script:** `scripts/validate-logseq-docs.py`
local/session-reports/SESSION_5_COMPLETION_REPORT.md,597,other,md,5. Debugging Workflows,3. Custom Primitive Development | 4. Performance Tuning | 5. Debugging Workflows |  | **Agent Standards:**
local/session-reports/SESSION_5_COMPLETION_REPORT.md,614,other,md,- âœ… 7 debugging techniques,- âœ… 11 primitives documented | - âœ… 8 architecture patterns | - âœ… 7 debugging techniques | - âœ… 5 How-To guides | 
local/session-reports/SESSION_5_COMPLETION_REPORT.md,622,other,md,- âœ… Systematic debugging approaches,- âœ… Practical examples with working code | - âœ… Real-world metrics and performance data | - âœ… Systematic debugging approaches | - âœ… Clear agent workflow integration | - âœ… Validation and enforcement mechanisms
local/session-reports/2025-01-16-docker-expert-complete.md,82,other,md,### 3. Debugging Journey,   - Validation passes for valid inputs |  | ### 3. Debugging Journey |  | **Issues Encountered & Solutions**:
local/session-reports/2025-01-16-docker-expert-complete.md,328,other,md,5. **Debugging Excellence**: Systematically identified and fixed 5 major test issues,"3. **Type Safety Champion**: Consistent use of dataclasses for return types | 4. **Test Pattern Consistency**: All 3 components (2 L3 experts, 3 L4 wrappers) follow same testing pattern | 5. **Debugging Excellence**: Systematically identified and fixed 5 major test issues | 6. **Documentation Quality**: Comprehensive progress reports, session summaries, inline comments | "
local/session-reports/2025-01-16-docker-expert-complete.md,338,other,md,- Systematic debugging approach identified all issues efficiently, | - Mocking strategy from GitHubExpert applied successfully to DockerExpert | - Systematic debugging approach identified all issues efficiently | - Test suite structure is consistent and maintainable | - Primitive composition patterns are clear and reusable
local/session-reports/2025-10-31-quality-verification-phase12.md,22,other,md,| Package | Tests Passing | Status | Notes |,"**Test Results Summary:** |  | | Package | Tests Passing | Status | Notes | | |---------|---------------|--------|-------| | | **tta-dev-primitives** | 170/188 | âœ… Excellent | 18 skipped (external service integrations), 1 optional dependency missing (groq) |"
local/session-reports/2025-10-31-quality-verification-phase12.md,118,other,md,- Updated TODO list with completion status,**Tracking:** | - Created GitHub issue template: `.github/ISSUE_TEMPLATE/file-watcher-implementation.md` | - Updated TODO list with completion status | - Documented integration requirements | 
local/session-reports/2025-10-31-quality-verification-phase12.md,123,other,md,## ðŸ“ Updated TODO Status,--- |  | ## ðŸ“ Updated TODO Status |  | - âœ… **Phase 1.1:** tta-documentation-primitives package - COMPLETE
local/session-reports/2025-10-31-quality-verification-phase12.md,265,other,md,4. TODO list updated via manage_todo_list,   - Listed integration requirements |  | 4. TODO list updated via manage_todo_list |  | ---
local/session-reports/2025-11-04-docker-expert-complete.md,221,other,md,- âœ… TODO list: DockerExpert marked complete,### Updated |  | - âœ… TODO list: DockerExpert marked complete | - â³ ATOMIC_DEVOPS_PROGRESS.md: Pending update | 
local/session-reports/2025-11-04-docker-expert-complete.md,266,other,md,- **Package TODOs:** `logseq/pages/TTA.dev/Packages/tta-agent-coordination/TODOs.md`,- **Progress Tracking:** `docs/ATOMIC_DEVOPS_PROGRESS.md` | - **LogSeq Journal:** `logseq/journals/2025_11_04.md` | - **Package TODOs:** `logseq/pages/TTA.dev/Packages/tta-agent-coordination/TODOs.md` |  | ---
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,15,other,md,- **Private by design** - Separate git repository for notes (not in main repo),### Key Features |  | - **Private by design** - Separate git repository for notes (not in main repo) | - **Symlink integration** - Easy access from main project without pollution | - **Auto-sync ready** - GitHub Personal Access Token + logseq-git plugin
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,51,other,md,"# Create new PRIVATE repo: ""TTA-notes""","```bash | # On GitHub.com | # Create new PRIVATE repo: ""TTA-notes"" | # (Do NOT initialize with README) | ```"
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,60,other,md,git clone https://github.com/theinterneti/TTA-notes.git,# Clone the private repo | cd ~ | git clone https://github.com/theinterneti/TTA-notes.git |  | # Move logseq folder contents
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,63,other,md,mv ~/repos/TTA.dev/logseq/* ~/TTA-notes/, | # Move logseq folder contents | mv ~/repos/TTA.dev/logseq/* ~/TTA-notes/ | mv ~/repos/TTA.dev/logseq/.gitignore ~/TTA-notes/ | rmdir ~/repos/TTA.dev/logseq
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,64,other,md,mv ~/repos/TTA.dev/logseq/.gitignore ~/TTA-notes/,# Move logseq folder contents | mv ~/repos/TTA.dev/logseq/* ~/TTA-notes/ | mv ~/repos/TTA.dev/logseq/.gitignore ~/TTA-notes/ | rmdir ~/repos/TTA.dev/logseq | 
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,68,other,md,ln -s ~/TTA-notes ~/repos/TTA.dev/logseq, | # Create symlink | ln -s ~/TTA-notes ~/repos/TTA.dev/logseq |  | # Commit to private repo
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,71,other,md,cd ~/TTA-notes," | # Commit to private repo | cd ~/TTA-notes | git add . | git commit -m ""Initial Logseq knowledge base for TTA.dev"""
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,81,other,md,"3. ""Add a new graph"" â†’ Select `~/TTA-notes`","1. Download Logseq: <https://logseq.com> | 2. Open the app | 3. ""Add a new graph"" â†’ Select `~/TTA-notes` | 4. Dashboard opens automatically | "
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,101,other,md,- **Open Tasks:** All TODO/DOING items across projects,On `[[TTA.dev (Meta-Project)]]` page: |  | - **Open Tasks:** All TODO/DOING items across projects | - **Completed This Week:** Recent completions | - **High Priority:** Priority A tasks
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,110,other,md,"- **AI Research** - Research notes, patterns, and decision logs","- **TTA.dev (Meta-Project)** - Master dashboard with live queries | - **TTA Primitives** - Complete primitives catalog with links to code | - **AI Research** - Research notes, patterns, and decision logs |  | ### Daily Journal"
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,116,other,md,"- Task syntax: `TODO`, `DOING`, `DONE`, `LATER`","- **2025_10_30** - Today's work log with tasks and links | - Auto-created daily pages | - Task syntax: `TODO`, `DOING`, `DONE`, `LATER` |  | ### Configuration"
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,132,other,md,- TODO Fix [[RouterPrimitive]] memory leak, | ```markdown | - TODO Fix [[RouterPrimitive]] memory leak |   related:: [[TTA Primitives]] |   code:: [router.py](../packages/tta-dev-primitives/src/tta_dev_primitives/core/router.py)
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,147,other,md,## Bug: Memory Leak in Sequential Primitive, | ```markdown | ## Bug: Memory Leak in Sequential Primitive |  | ### Location
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,182,other,md,| Public Docs (in repo) | Private Notes (in Logseq) |,### With TTA.dev Repository |  | | Public Docs (in repo) | Private Notes (in Logseq) | | |----------------------|---------------------------| | | `docs/` - User guides | Daily journals |
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,185,other,md,| `AGENTS.md` - AI instructions | Research notes |,|----------------------|---------------------------| | | `docs/` - User guides | Daily journals | | | `AGENTS.md` - AI instructions | Research notes | | | `README.md` - Public overview | Decision logs | | | Package READMEs | Task tracking |
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,195,other,md,"2. **During work:** Log tasks, bugs, and ideas in journal"," | 1. **Morning:** Review Logseq dashboard for priorities | 2. **During work:** Log tasks, bugs, and ideas in journal | 3. **Code changes:** Link to journal entries from commit messages | 4. **Evening:** Mark tasks DONE, reflect, plan tomorrow"
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,219,other,md,- **Task tracking:** Visual TODO list with automatic queries, | - **Brain dump:** Capture ideas without context switching | - **Task tracking:** Visual TODO list with automatic queries | - **Research log:** Link experiments to implementations | - **Decision history:** Never forget why you did something
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,233,other,md,- **Debugging:** Historical context for why code exists, | - **Onboarding:** New developers read journals to understand project evolution | - **Debugging:** Historical context for why code exists | - **Refactoring:** Know what was tried before and why it failed | - **Documentation:** Generate docs from Logseq content
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,244,other,md,- Research notes and experiments, | - Daily journals (your work log) | - Research notes and experiments | - Decision rationale and debates | - Task lists and priorities
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,258,other,md,- âœ… Use private TTA-notes repo,### Best Practices |  | - âœ… Use private TTA-notes repo | - âœ… Rotate GitHub PAT every 90 days | - âœ… Never commit logseq/ to main repo
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,261,other,md,- âŒ Don't put secrets/credentials in notes,- âœ… Rotate GitHub PAT every 90 days | - âœ… Never commit logseq/ to main repo | - âŒ Don't put secrets/credentials in notes | - âŒ Don't put company IP in public examples | 
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,310,other,md,{{query (and (task TODO DOING) (between -7d today))}},```markdown | ## This Sprint | {{query (and (task TODO DOING) (between -7d today))}} |  | ## Blocked Tasks
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,313,other,md,{{query (and (task TODO) (property blocked))}}, | ## Blocked Tasks | {{query (and (task TODO) (property blocked))}} |  | ## Priority A Items
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,316,other,md,{{query (and (task TODO) (priority A))}}, | ## Priority A Items | {{query (and (task TODO) (priority A))}} |  | ## Research by Topic
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,326,other,md,- Bug reports,Create templates for: |  | - Bug reports | - Feature proposals | - Weekly reviews
local/session-reports/LOGSEQ_INTEGRATION_COMPLETE.md,409,other,md,- Log tasks and notes in journal," | - Open Logseq, review dashboard | - Log tasks and notes in journal | - Mark tasks DONE as you complete them | "
local/session-reports/SESSION_3_QUICK_START.md,140,other,md,### Speed Hacks,## Pro Tips |  | ### Speed Hacks |  | âœ… **Read the source file first** - Understand the primitive before documenting
local/session-reports/COMMIT_GUIDE.md,162,other,md,1. âœ… **Fix tests first** - Clean separation of bugfix,**Use Option 2 (Separate Commits)** for better Git history: |  | 1. âœ… **Fix tests first** - Clean separation of bugfix | 2. âœ… **Add new package** - Feature addition clearly documented | 3. âœ… **Document work** - Session reports and tracking
local/session-reports/COMMIT_GUIDE.md,192,other,md,- **TODO List:** Updated via manage_todo_list,- **Current Branch:** `fix/gemini-cli-write-permissions` | - **Active PR:** #76 (fix: complete write permissions fix for Gemini CLI) | - **TODO List:** Updated via manage_todo_list | - **GitHub Issue Template:** `.github/ISSUE_TEMPLATE/file-watcher-implementation.md` | 
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,81,other,md,- TODO [[TTA.dev/Primitives/WorkflowPrimitive]] - Base class (foundational), | **Remaining (4):** | - TODO [[TTA.dev/Primitives/WorkflowPrimitive]] - Base class (foundational) | - TODO [[TTA.dev/Primitives/ConditionalPrimitive]] - Conditional branching | - TODO [[TTA.dev/Primitives/TimeoutPrimitive]] - Circuit breaker
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,82,other,md,- TODO [[TTA.dev/Primitives/ConditionalPrimitive]] - Conditional branching,**Remaining (4):** | - TODO [[TTA.dev/Primitives/WorkflowPrimitive]] - Base class (foundational) | - TODO [[TTA.dev/Primitives/ConditionalPrimitive]] - Conditional branching | - TODO [[TTA.dev/Primitives/TimeoutPrimitive]] - Circuit breaker | - TODO [[TTA.dev/Primitives/CompensationPrimitive]] - Saga pattern
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,83,other,md,- TODO [[TTA.dev/Primitives/TimeoutPrimitive]] - Circuit breaker,- TODO [[TTA.dev/Primitives/WorkflowPrimitive]] - Base class (foundational) | - TODO [[TTA.dev/Primitives/ConditionalPrimitive]] - Conditional branching | - TODO [[TTA.dev/Primitives/TimeoutPrimitive]] - Circuit breaker | - TODO [[TTA.dev/Primitives/CompensationPrimitive]] - Saga pattern | 
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,84,other,md,- TODO [[TTA.dev/Primitives/CompensationPrimitive]] - Saga pattern,- TODO [[TTA.dev/Primitives/ConditionalPrimitive]] - Conditional branching | - TODO [[TTA.dev/Primitives/TimeoutPrimitive]] - Circuit breaker | - TODO [[TTA.dev/Primitives/CompensationPrimitive]] - Saga pattern |  | ### Guides (13% Complete - 2/15) ðŸ“š
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,93,other,md,- TODO [[TTA.dev/Guides/Agentic Primitives]] - Core concepts, | **High Priority Remaining (5):** | - TODO [[TTA.dev/Guides/Agentic Primitives]] - Core concepts | - TODO [[TTA.dev/Guides/Workflow Composition]] - Combining primitives | - TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,94,other,md,- TODO [[TTA.dev/Guides/Workflow Composition]] - Combining primitives,**High Priority Remaining (5):** | - TODO [[TTA.dev/Guides/Agentic Primitives]] - Core concepts | - TODO [[TTA.dev/Guides/Workflow Composition]] - Combining primitives | - TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing | - TODO [[TTA.dev/Guides/Cost Optimization]] - Reducing LLM costs
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,95,other,md,- TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing,- TODO [[TTA.dev/Guides/Agentic Primitives]] - Core concepts | - TODO [[TTA.dev/Guides/Workflow Composition]] - Combining primitives | - TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing | - TODO [[TTA.dev/Guides/Cost Optimization]] - Reducing LLM costs | - TODO [[TTA.dev/Guides/Testing Workflows]] - Testing strategies
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,96,other,md,- TODO [[TTA.dev/Guides/Cost Optimization]] - Reducing LLM costs,- TODO [[TTA.dev/Guides/Workflow Composition]] - Combining primitives | - TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing | - TODO [[TTA.dev/Guides/Cost Optimization]] - Reducing LLM costs | - TODO [[TTA.dev/Guides/Testing Workflows]] - Testing strategies | 
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,97,other,md,- TODO [[TTA.dev/Guides/Testing Workflows]] - Testing strategies,- TODO [[TTA.dev/Guides/Observability]] - Monitoring and tracing | - TODO [[TTA.dev/Guides/Cost Optimization]] - Reducing LLM costs | - TODO [[TTA.dev/Guides/Testing Workflows]] - Testing strategies |  | **Additional Remaining (8):**
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,100,other,md,- TODO Beginner Quickstart, | **Additional Remaining (8):** | - TODO Beginner Quickstart | - TODO Building Reliable AI Workflows | - TODO Production Deployment
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,101,other,md,- TODO Building Reliable AI Workflows,**Additional Remaining (8):** | - TODO Beginner Quickstart | - TODO Building Reliable AI Workflows | - TODO Production Deployment | - TODO Architecture Patterns
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,102,other,md,- TODO Production Deployment,- TODO Beginner Quickstart | - TODO Building Reliable AI Workflows | - TODO Production Deployment | - TODO Architecture Patterns | - TODO 4 How-To guides
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,103,other,md,- TODO Architecture Patterns,- TODO Building Reliable AI Workflows | - TODO Production Deployment | - TODO Architecture Patterns | - TODO 4 How-To guides | 
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,104,other,md,- TODO 4 How-To guides,- TODO Production Deployment | - TODO Architecture Patterns | - TODO 4 How-To guides |  | ### Other Content (0% Complete)
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,108,other,md,- TODO Examples namespace (15 examples),### Other Content (0% Complete) |  | - TODO Examples namespace (15 examples) | - TODO Architecture namespace (10 ADRs) | - TODO Package-specific pages (5 packages)
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,109,other,md,- TODO Architecture namespace (10 ADRs), | - TODO Examples namespace (15 examples) | - TODO Architecture namespace (10 ADRs) | - TODO Package-specific pages (5 packages) | - TODO Whiteboards (visual diagrams)
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,110,other,md,- TODO Package-specific pages (5 packages),- TODO Examples namespace (15 examples) | - TODO Architecture namespace (10 ADRs) | - TODO Package-specific pages (5 packages) | - TODO Whiteboards (visual diagrams) | 
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,111,other,md,- TODO Whiteboards (visual diagrams),- TODO Architecture namespace (10 ADRs) | - TODO Package-specific pages (5 packages) | - TODO Whiteboards (visual diagrams) |  | ---
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,196,other,md,- **Compensation** - TODO (Saga pattern),- **Fallback** - Service outages | - **Timeout** - Prevent hanging | - **Compensation** - TODO (Saga pattern) |  | ### 2. Performance Optimization Documented
local/session-reports/LOGSEQ_MIGRATION_SESSION_2_COMPLETE.md,332,other,md,- TODO 5 critical guides needed,- âœ… Getting Started guide complete | - âœ… Error Handling Patterns complete | - TODO 5 critical guides needed |  | **Priority Guides:**
local/summaries/INTEGRATION_ANALYSIS_SUMMARY.md,85,other,md,- Higher bug risk,"**Why:** | - Reinventing the wheel | - Higher bug risk | - More maintenance burden | - Missing features (rate limiting, retries, etc.)"
local/summaries/INTEGRATION_ANALYSIS_SUMMARY.md,137,other,md,| Bug fixes | All on us | âœ… Shared |,| API updates | Manual tracking | âœ… Automatic | | | Community support | None | âœ… Large | | | Bug fixes | All on us | âœ… Shared | |  | ---
local/summaries/logseq-docs-integration-summary.md,34,non-actionable,md,2. **`local/planning/logseq-docs-integration-todos.md`** (700+ lines),   - Example workflows |  | 2. **`local/planning/logseq-docs-integration-todos.md`** (700+ lines) |    - 40+ detailed TODOs across 5 phases |    - Time estimates (74-92 hours total)
local/summaries/logseq-docs-integration-summary.md,35,non-actionable,md,- 40+ detailed TODOs across 5 phases, | 2. **`local/planning/logseq-docs-integration-todos.md`** (700+ lines) |    - 40+ detailed TODOs across 5 phases |    - Time estimates (74-92 hours total) |    - Success criteria
local/summaries/logseq-docs-integration-summary.md,41,non-actionable,md,- All TODOs added to today's journal, | 3. **`logseq/journals/2025_10_31.md`** (updated) |    - All TODOs added to today's journal |    - Proper Logseq format with properties |    - Tagged with #dev-todo
local/summaries/logseq-docs-integration-summary.md,331,non-actionable,md,"""title"": ""How to Debug Workflows"",","# Agent generates documentation | result = await doc_workflow.execute({ |     ""title"": ""How to Debug Workflows"", |     ""category"": ""guides"", |     ""content"": generated_content,"
local/summaries/logseq-docs-integration-summary.md,338,non-actionable,md,# âœ… docs/guides/how-to-debug-workflows.md created, | # Result: | # âœ… docs/guides/how-to-debug-workflows.md created | # âœ… logseq/pages/How to Debug Workflows.md created | # âœ… AI metadata generated
local/summaries/logseq-docs-integration-summary.md,339,non-actionable,md,# âœ… logseq/pages/How to Debug Workflows.md created,# Result: | # âœ… docs/guides/how-to-debug-workflows.md created | # âœ… logseq/pages/How to Debug Workflows.md created | # âœ… AI metadata generated | # âœ… Links to related pages added
local/summaries/logseq-docs-integration-summary.md,373,non-actionable,md,- **TODOs:** `local/planning/logseq-docs-integration-todos.md`, | - **Design:** `local/planning/logseq-docs-db-integration-design.md` | - **TODOs:** `local/planning/logseq-docs-integration-todos.md` | - **Journal:** `logseq/journals/2025_10_31.md` (updated) | - **Architecture:** [[TTA.dev/Architecture]]
local/summaries/logseq-docs-integration-summary.md,415,non-actionable,md,- âœ… 40+ TODOs across 5 phases,- âœ… Complete architecture design (800+ lines) | - âœ… Detailed implementation plan (700+ lines) | - âœ… 40+ TODOs across 5 phases | - âœ… Time estimates (74-92 hours) | - âœ… Clear success criteria
local/summaries/phase4-next-steps-quickref.md,260,other,md,- [Logseq TODO System](../../logseq/pages/TODO%20Management%20System.md),- [AGENTS.md](../../AGENTS.md) | - [PRIMITIVES_CATALOG.md](../../PRIMITIVES_CATALOG.md) | - [Logseq TODO System](../../logseq/pages/TODO%20Management%20System.md) |  | ### Tracking
local/summaries/phase1-1-complete.md,121,other,md,## Technical Notes,--- |  | ## Technical Notes |  | ### Lint Warnings (Non-Blocking)
local/summaries/phase4-progress-2025-10-31.md,86,other,md,- Updated `logseq/journals/2025_10_31.md` with structured TODOs,"### 4. Today's Journal Updated |  | - Updated `logseq/journals/2025_10_31.md` with structured TODOs | - All tasks tagged with #dev-todo | - Proper priority, status, and metadata"
local/summaries/phase4-progress-2025-10-31.md,218,other,md,- [x] Update journal with structured TODOs,- [x] Write 2 How-To guides | - [x] Set up package decision tracking | - [x] Update journal with structured TODOs |  | ### Day 2 (November 1) - Planned
local/summaries/phase4-progress-2025-10-31.md,255,other,md,1. `logseq/journals/2025_10_31.md` (added Phase 4 TODOs)," | ### Updated Files (1) | 1. `logseq/journals/2025_10_31.md` (added Phase 4 TODOs) |  | **Total Lines Added:** ~2,500 lines of documentation"
local/summaries/phase4-progress-2025-10-31.md,284,other,md,4. **TODO integration** - Following Logseq TODO Management System,2. **Comprehensive guides** - 600+ line guides with examples and troubleshooting | 3. **Structured tracking** - Decision tracking page with clear criteria | 4. **TODO integration** - Following Logseq TODO Management System |  | ### Challenges
local/summaries/phase4-progress-2025-10-31.md,303,other,md,- [[TODO Management System]],- [[TTA.dev/Architecture]] | - [[TTA Primitives]] | - [[TODO Management System]] | - [[2025_10_31]] (Today's journal) | 
local/summaries/phase4-progress-2025-10-31.md,334,other,md,- [x] TODOs added to journal with proper tags, | - [x] All files follow markdown standards | - [x] TODOs added to journal with proper tags | - [x] Links between pages working | - [x] Code examples tested (conceptually)
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,248,other,md,## Implementation Notes,- Composition examples |  | ## Implementation Notes | - Performance considerations | - Edge cases
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,369,other,md,## All TODO Tasks Across Documentation, | ```markdown | ## All TODO Tasks Across Documentation | {{query (task TODO DOING)}} | 
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,370,other,md,{{query (task TODO DOING)}},```markdown | ## All TODO Tasks Across Documentation | {{query (task TODO DOING)}} |  | ## All Examples Using RouterPrimitive
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,454,other,md,{{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}}, | ### Current Sprint Tasks | {{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}} |  | ### Recently Completed
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,460,other,md,{{query (and (task TODO) (property blocked true))}}, | ### Blocked Items | {{query (and (task TODO) (property blocked true))}} | ``` | 
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,487,other,md,## Implementation Notes,- |  | ## Implementation Notes | - | ```
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,511,other,md,| File | Target Logseq Page | Notes |,### Priority 1: Essential Documentation (Do First) |  | | File | Target Logseq Page | Notes | | |------|-------------------|-------| | | `README.md` | `[[TTA.dev]]` | Main hub page |
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,521,other,md,| File | Target Logseq Page | Notes |,### Priority 2: User Guides (Do Second) |  | | File | Target Logseq Page | Notes | | |------|-------------------|-------| | | `docs/guides/BEGINNER_QUICKSTART.md` | `[[TTA.dev/Guides/Beginner Quickstart]]` | Entry point |
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,530,other,md,| Directory | Target Namespace | Notes |,### Priority 3: Architecture & Technical (Do Third) |  | | Directory | Target Namespace | Notes | | |-----------|------------------|-------| | | `docs/architecture/` | `[[TTA.dev/Architecture/]]` | ADRs and patterns |
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,538,other,md,| Package | Target Namespace | Notes |,### Priority 4: Package Documentation (Do Fourth) |  | | Package | Target Namespace | Notes | | |---------|------------------|-------| | | `packages/tta-dev-primitives/` | `[[TTA.dev/Packages/tta-dev-primitives/]]` | Core package |
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,545,other,md,| Category | Target Namespace | Notes |,### Priority 5: Archive & Status (Do Last) |  | | Category | Target Namespace | Notes | | |----------|------------------|-------| | | Status reports | `[[TTA.dev/Archive/Status/]]` | Historical records |
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,558,other,md,# In your Logseq graph (~/TTA-notes or ~/repos/TTA.dev/logseq), | ```bash | # In your Logseq graph (~/TTA-notes or ~/repos/TTA.dev/logseq) | cd ~/repos/TTA.dev/logseq/pages | 
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,623,other,md,{{query (and (task TODO DOING) [[TTA.dev]])}}, | ### Active Work | {{query (and (task TODO DOING) [[TTA.dev]])}} |  | ### Recent Completions
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,647,other,md,- TODO: {{query (task TODO [[TTA.dev]])}}, | ### Task Status | - TODO: {{query (task TODO [[TTA.dev]])}} | - DOING: {{query (task DOING [[TTA.dev]])}} | - DONE (this week): {{query (and (task DONE) (between -7d today))}}
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,753,other,md,## Implementation Notes,- |  | ## Implementation Notes | - | 
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,822,other,md,## ðŸ“ Notes & Considerations,--- |  | ## ðŸ“ Notes & Considerations |  | ### Advantages of Logseq Approach
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,829,other,md,4. **Task Management:** TODO/DOING/DONE integrated with documentation,"2. **Automatic Backlinks:** Every mention creates a bidirectional connection | 3. **Dynamic Discovery:** Queries find related content automatically | 4. **Task Management:** TODO/DOING/DONE integrated with documentation | 5. **Flexible Organization:** Namespaces + properties + links = multiple ways to navigate | 6. **Version Control:** Still markdown files, still git-trackable"
local/planning/LOGSEQ_DOCUMENTATION_PLAN.md,832,other,md,7. **Search:** Full-text search across all notes and blocks,"5. **Flexible Organization:** Namespaces + properties + links = multiple ways to navigate | 6. **Version Control:** Still markdown files, still git-trackable | 7. **Search:** Full-text search across all notes and blocks |  | ### Challenges to Address"
local/planning/logseq-docs-db-integration-design.md,504,non-actionable,md,"""title"": ""How to Debug Workflows"",","# Agent generates doc | result = await doc_workflow.execute({ |     ""title"": ""How to Debug Workflows"", |     ""category"": ""guides"", |     ""content"": generated_content,"
local/planning/logseq-docs-db-integration-design.md,511,non-actionable,md,# âœ… docs/guides/how-to-debug-workflows.md created, | # Result: | # âœ… docs/guides/how-to-debug-workflows.md created | # âœ… logseq/pages/How to Debug Workflows.md created | # âœ… AI metadata generated
local/planning/logseq-docs-db-integration-design.md,512,non-actionable,md,# âœ… logseq/pages/How to Debug Workflows.md created,# Result: | # âœ… docs/guides/how-to-debug-workflows.md created | # âœ… logseq/pages/How to Debug Workflows.md created | # âœ… AI metadata generated | # âœ… Links to related pages added
local/planning/logseq-docs-db-integration-design.md,635,non-actionable,md,See: `local/planning/logseq-docs-integration-todos.md`,## ðŸ“ Next Steps |  | See: `local/planning/logseq-docs-integration-todos.md` |  | ---
local/planning/logseq-docs-db-integration-design.md,651,non-actionable,md,**Next:** Create TODO list and start Phase 1,"**Last Updated:** October 31, 2025 | **Status:** Design Phase | **Next:** Create TODO list and start Phase 1 | "
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,116,other,md,{{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}}, | ### Current Sprint | {{query (and (task TODO DOING) (between [[2025-10-28]] [[2025-11-03]]))}} |  | ### Recently Completed
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,292,other,md,## Implementation Notes,--- |  | ## Implementation Notes |  | - id:: sequential-implementation-notes
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,294,other,md,- id:: sequential-implementation-notes,## Implementation Notes |  | - id:: sequential-implementation-notes |  | ### Performance
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,422,other,md,{{query (and (task TODO DOING) [[TTA.dev]] (between [[2025-10-28]] [[2025-11-03]]))}}, | ### Current Sprint Tasks | {{query (and (task TODO DOING) [[TTA.dev]] (between [[2025-10-28]] [[2025-11-03]]))}} |  | ### Blocked Items
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,425,other,md,{{query (and (task TODO) (property blocked true))}}, | ### Blocked Items | {{query (and (task TODO) (property blocked true))}} |  | ---
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,515,other,md,"**Note:** Each cell is a link, click through to the full documentation!","``` |  | **Note:** Each cell is a link, click through to the full documentation! |  | ---"
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,545,other,md,1. **Task dashboard** - All TODO/DOING across project,"### Enhance Queries |  | 1. **Task dashboard** - All TODO/DOING across project | 2. **Coverage report** - Missing documentation | 3. **Quality metrics** - Test coverage, update frequency"
local/planning/LOGSEQ_MIGRATION_QUICKSTART.md,559,other,md,3. **Journals** - Daily development notes linked to pages,1. **Linked References** - See what references each page | 2. **Graph View** - Visualize entire knowledge graph | 3. **Journals** - Daily development notes linked to pages | 4. **Templates** - Custom templates for recurring patterns | 
local/planning/AGENTS_HUB_IMPLEMENTATION.md,160,other,md,**NOTE**: The repository previously had two packages (`tta-workflow-primitives` and `dev-primitives`) which were **consolidated into `tta-dev-primitives`** on 2025-10-28. All workflow primitives are now in the single `tta-dev-primitives` package.,### Package Structure |  | **NOTE**: The repository previously had two packages (`tta-workflow-primitives` and `dev-primitives`) which were **consolidated into `tta-dev-primitives`** on 2025-10-28. All workflow primitives are now in the single `tta-dev-primitives` package. |  | ### Legacy Code (DO NOT USE)
local/planning/AGENTS_HUB_IMPLEMENTATION.md,209,other,md,## Debugging Tips,"5. Use Conventional Commits format: `feat:`, `fix:`, `docs:`, `refactor:`, `test:`, `chore:` |  | ## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives"
local/planning/AGENTS_HUB_IMPLEMENTATION.md,211,other,md,- Use `WorkflowContext.metadata` for debugging state across primitives,"## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected`"
local/planning/AGENTS_HUB_IMPLEMENTATION.md,212,other,md,"- Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")`"," | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected` | - For async issues, ensure `@pytest.mark.asyncio` decorator present"
local/planning/AGENTS_HUB_IMPLEMENTATION.md,352,other,md,# TODO: Add tests later,"âŒ **BAD**: | ```python | # TODO: Add tests later | class NewFeature(WorkflowPrimitive[dict, dict]): |     ..."
local/planning/PROMPT_LIBRARY_COMPLETE.md,82,other,md,- Usage notes,- Content guidelines | - Writing style guide | - Usage notes |  | ---
local/planning/PROMPT_LIBRARY_COMPLETE.md,109,other,md,â”œâ”€â”€ notebooks/,â”œâ”€â”€ prototypes/ | â”œâ”€â”€ logseq-tools/      # â† Works WITH prompts | â”œâ”€â”€ notebooks/ | â””â”€â”€ data/ | ```
local/planning/PROMPT_LIBRARY_COMPLETE.md,221,other,md,"Also check for [custom rule], like ""all TODO items should have a related:: property"""," | ```text | Also check for [custom rule], like ""all TODO items should have a related:: property"" | ``` | "
local/planning/PROMPT_LIBRARY_COMPLETE.md,263,other,md,- `task_case`: Task status not uppercase (todo â†’ TODO), | **Errors (Fix Immediately):** | - `task_case`: Task status not uppercase (todo â†’ TODO) | - `heading_format`: Missing space after # in headings | - `code_unclosed`: Unclosed code blocks
local/planning/logseq-docs-integration-todos.md,1,non-actionable,md,# Logseq-Docs Integration TODOs,"# Logseq-Docs Integration TODOs |  | **Date:** October 31, 2025"
local/planning/logseq-docs-integration-todos.md,19,non-actionable,md,### TODO 1.1: Create Package Structure,## ðŸ“‹ Phase 1: Foundation (Week 1) |  | ### TODO 1.1: Create Package Structure |  | - [ ] **Create `tta-documentation-primitives` package** #dev-todo
local/planning/logseq-docs-integration-todos.md,42,non-actionable,md,### TODO 1.2: Implement File Watcher,  - `src/tta_documentation_primitives/sync_service.py` |  | ### TODO 1.2: Implement File Watcher |  | - [ ] **Build file watcher service using watchdog** #dev-todo
local/planning/logseq-docs-integration-todos.md,68,non-actionable,md,### TODO 1.3: Basic Markdown â†’ Logseq Converter,  - Rapid edits â†’ debounced to single sync |  | ### TODO 1.3: Basic Markdown â†’ Logseq Converter |  | - [ ] **Create markdown to Logseq format converter** #dev-todo
local/planning/logseq-docs-integration-todos.md,92,non-actionable,md,### TODO 1.4: Manual Sync Command,  - Properties added |  | ### TODO 1.4: Manual Sync Command |  | - [ ] **Implement `tta-docs sync` CLI command** #dev-todo
local/planning/logseq-docs-integration-todos.md,113,non-actionable,md,### TODO 1.5: Configuration System,  ``` |  | ### TODO 1.5: Configuration System |  | - [ ] **Create configuration management** #dev-todo
local/planning/logseq-docs-integration-todos.md,135,non-actionable,md,### TODO 2.1: Gemini Flash Integration,## ðŸ“‹ Phase 2: AI Integration (Week 2) |  | ### TODO 2.1: Gemini Flash Integration |  | - [ ] **Integrate Google Gemini Flash API** #dev-todo
local/planning/logseq-docs-integration-todos.md,161,non-actionable,md,### TODO 2.2: Property Extraction,  - `categorize(content)` â†’ category string |  | ### TODO 2.2: Property Extraction |  | - [ ] **Implement AI-powered property extraction** #dev-todo
local/planning/logseq-docs-integration-todos.md,184,non-actionable,md,### TODO 2.3: Link Suggestion Engine,  ``` |  | ### TODO 2.3: Link Suggestion Engine |  | - [ ] **Build intelligent link suggestion** #dev-todo
local/planning/logseq-docs-integration-todos.md,203,non-actionable,md,### TODO 2.4: AI-Optimized Section Generator,  4. Return top N suggestions |  | ### TODO 2.4: AI-Optimized Section Generator |  | - [ ] **Generate AI-optimized metadata sections** #dev-todo
local/planning/logseq-docs-integration-todos.md,224,non-actionable,md,### TODO 2.5: Ollama Local Fallback,  ``` |  | ### TODO 2.5: Ollama Local Fallback |  | - [ ] **Add Ollama local AI support** #dev-todo
local/planning/logseq-docs-integration-todos.md,246,non-actionable,md,### TODO 3.1: DocumentationPrimitive,## ðŸ“‹ Phase 3: TTA.dev Primitives (Week 3) |  | ### TODO 3.1: DocumentationPrimitive |  | - [ ] **Create `DocumentationPrimitive` class** #dev-todo
local/planning/logseq-docs-integration-todos.md,278,non-actionable,md,### TODO 3.2: LogseqSyncPrimitive,  ``` |  | ### TODO 3.2: LogseqSyncPrimitive |  | - [ ] **Create `LogseqSyncPrimitive` class** #dev-todo
local/planning/logseq-docs-integration-todos.md,301,non-actionable,md,### TODO 3.3: KnowledgeBaseIndexPrimitive,  ``` |  | ### TODO 3.3: KnowledgeBaseIndexPrimitive |  | - [ ] **Create `KnowledgeBaseIndexPrimitive` class** #dev-todo
local/planning/logseq-docs-integration-todos.md,314,non-actionable,md,### TODO 3.4: Testing Suite,  - Maintain topic hierarchies |  | ### TODO 3.4: Testing Suite |  | - [ ] **Write comprehensive tests** #dev-todo
local/planning/logseq-docs-integration-todos.md,330,non-actionable,md,### TODO 3.5: Example Workflows,  **Target:** 90%+ coverage |  | ### TODO 3.5: Example Workflows |  | - [ ] **Create example workflows** #dev-todo
local/planning/logseq-docs-integration-todos.md,346,non-actionable,md,### TODO 4.1: VS Code Extension Integration,## ðŸ“‹ Phase 4: Automation (Week 4) |  | ### TODO 4.1: VS Code Extension Integration |  | - [ ] **Add VS Code save hook** #dev-todo
local/planning/logseq-docs-integration-todos.md,360,non-actionable,md,### TODO 4.2: Background Sync Service,  **Preferred:** External watcher (simpler) |  | ### TODO 4.2: Background Sync Service |  | - [ ] **Create background daemon** #dev-todo
local/planning/logseq-docs-integration-todos.md,381,non-actionable,md,### TODO 4.3: Bidirectional Sync (Logseq â†’ Docs),  - Auto-restart on error |  | ### TODO 4.3: Bidirectional Sync (Logseq â†’ Docs) |  | - [ ] **Implement reverse sync** #dev-todo
local/planning/logseq-docs-integration-todos.md,397,non-actionable,md,### TODO 4.4: Conflict Resolution,  5. Preserve front matter |  | ### TODO 4.4: Conflict Resolution |  | - [ ] **Handle sync conflicts** #dev-todo
local/planning/logseq-docs-integration-todos.md,414,non-actionable,md,### TODO 4.5: Notification System,  - Option to always prefer docs/ or logseq/ |  | ### TODO 4.5: Notification System |  | - [ ] **Add sync notifications** #dev-todo
local/planning/logseq-docs-integration-todos.md,435,non-actionable,md,### TODO 5.1: Update Copilot Instructions,## ðŸ“‹ Phase 5: Agent Integration (Week 5) |  | ### TODO 5.1: Update Copilot Instructions |  | - [ ] **Add to `.github/copilot-instructions.md`** #dev-todo
local/planning/logseq-docs-integration-todos.md,448,non-actionable,md,### TODO 5.2: Documentation Templates,  - Example usage |  | ### TODO 5.2: Documentation Templates |  | - [ ] **Create doc templates** #dev-todo
local/planning/logseq-docs-integration-todos.md,461,non-actionable,md,### TODO 5.3: Agent Workflow Examples,  - `templates/architecture-decision.md` |  | ### TODO 5.3: Agent Workflow Examples |  | - [ ] **Write agent integration examples** #dev-todo
local/planning/logseq-docs-integration-todos.md,474,non-actionable,md,### TODO 5.4: MCP Server Integration,  - Agent batch-syncs workspace |  | ### TODO 5.4: MCP Server Integration |  | - [ ] **Add documentation tools to MCP server** #dev-todo
local/planning/logseq-docs-integration-todos.md,487,non-actionable,md,### TODO 5.5: Production Testing,  - `get_related_docs` - Find related documentation |  | ### TODO 5.5: Production Testing |  | - [ ] **Test with real agent workflows** #dev-todo
local/planning/logseq-docs-integration-todos.md,505,non-actionable,md,### TODO 6.1: CI/CD Integration,## ðŸ“‹ Infrastructure & Polish |  | ### TODO 6.1: CI/CD Integration |  | - [ ] **Add sync validation to CI** #dev-todo
local/planning/logseq-docs-integration-todos.md,518,non-actionable,md,### TODO 6.2: Performance Optimization,  - No sync conflicts |  | ### TODO 6.2: Performance Optimization |  | - [ ] **Optimize sync performance** #dev-todo
local/planning/logseq-docs-integration-todos.md,535,non-actionable,md,### TODO 6.3: Error Handling & Recovery,  - Incremental sync |  | ### TODO 6.3: Error Handling & Recovery |  | - [ ] **Robust error handling** #dev-todo
local/planning/logseq-docs-integration-todos.md,549,non-actionable,md,### TODO 6.4: Documentation,  - Encoding issues |  | ### TODO 6.4: Documentation |  | - [ ] **Write comprehensive docs** #dev-todo
local/planning/logseq-docs-integration-todos.md,563,non-actionable,md,### TODO 6.5: User Onboarding,  - Troubleshooting guide |  | ### TODO 6.5: User Onboarding |  | - [ ] **Create setup wizard** #dev-todo
local/planning/logseq-docs-integration-todos.md,636,non-actionable,md,**Note:** ~2-3 weeks full-time or 4-6 weeks part-time,| **Total** | **74-92 hours** | | |  | **Note:** ~2-3 weeks full-time or 4-6 weeks part-time |  | ---
local/planning/logseq-docs-integration-todos.md,666,non-actionable,md,## ðŸ“ Notes,--- |  | ## ðŸ“ Notes |  | ### Design Decisions
local/planning/logseq-docs-integration-todos.md,698,non-actionable,md,**Status:** Active TODO list,"**Created:** October 31, 2025 | **Last Updated:** October 31, 2025 | **Status:** Active TODO list | **Next Action:** Start Phase 1.1 - Create package structure | "
local/planning/phase1-2-workflow.md,238,other,md,## ðŸ“ Implementation Notes,--- |  | ## ðŸ“ Implementation Notes |  | ### Debouncing Strategy
local/analysis/USER_JOURNEY_VIBE_CODER_ANALYSIS.md,41,other,md,- Debugging obscure infrastructure issues,"- Spending weeks on setup and configuration | - Learning DevOps, Kubernetes, Docker, etc. | - Debugging obscure infrastructure issues | - Reading 100-page documentation before starting | - Getting stuck in ""tutorial hell"""
local/analysis/USER_JOURNEY_ANALYSIS.md,107,other,md,- âœ… Can debug observability issues,  - âœ… Understands type system and generics |   - âœ… Can contribute primitives |   - âœ… Can debug observability issues |   - âš ï¸ **Gap: Contributing guidelines** (need CONTRIBUTING.md improvements) |   - ðŸ’¡ **Solution: Advanced architecture docs**
local/analysis/USER_JOURNEY_ANALYSIS.md,586,other,md,- ðŸ› **Faster debugging** (distributed tracing shows exact failure point), | - ðŸ’° **30-40% cost reduction** (via RouterPrimitive + CachePrimitive) | - ðŸ› **Faster debugging** (distributed tracing shows exact failure point) | - ðŸ“ˆ **Production monitoring** (Prometheus metrics â†’ Grafana dashboards) | 
local/analysis/USER_JOURNEY_SECOND_PERSPECTIVE.md,278,other,md,"### 1. **Beginner Gap May Be a Feature, Not a Bug**","## ðŸ” Alternative Interpretations |  | ### 1. **Beginner Gap May Be a Feature, Not a Bug** |  | **Current View:** Beginner experience (66/100) is a problem to fix."
local/logseq-tools/README.md,16,other,md,- **Checking** task syntax (TODO/DOING/DONE),- **Detecting** formatting problems (MD linting) | - **Finding** broken page links | - **Checking** task syntax (TODO/DOING/DONE) | - **Validating** code blocks and structure | - **Scoring** documentation quality (0-100)
local/logseq-tools/README.md,115,other,md,- âœ… Uppercase status: `TODO` not `todo`,"### Task Syntax |  | - âœ… Uppercase status: `TODO` not `todo` | - âœ… Valid statuses: TODO, DOING, DONE, LATER, NOW, WAITING | - âœ… Proper formatting"
local/logseq-tools/README.md,116,other,md,"- âœ… Valid statuses: TODO, DOING, DONE, LATER, NOW, WAITING"," | - âœ… Uppercase status: `TODO` not `todo` | - âœ… Valid statuses: TODO, DOING, DONE, LATER, NOW, WAITING | - âœ… Proper formatting | "
local/logseq-tools/doc_assistant.py,197,code,py,"# Match: ""- TODO"" or ""  - TODO"" but NOT ""**Status:** TODO""","        for i, line in enumerate(lines, 1): |             # Check for task markers (only in list items, not bold text) |             # Match: ""- TODO"" or ""  - TODO"" but NOT ""**Status:** TODO"" |             task_match = re.match( |                 r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later)\s"","
local/logseq-tools/doc_assistant.py,199,code,py,"r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later)\s"",","            # Match: ""- TODO"" or ""  - TODO"" but NOT ""**Status:** TODO"" |             task_match = re.match( |                 r""^\s*[-*+]\s+(TODO|DOING|DONE|LATER|NOW|WAITING|todo|doing|done|later)\s"", |                 line, |             )"
local/.prompts/README.md,228,other,md,2. Note what worked/didn't work, | 1. Use prompt in session | 2. Note what worked/didn't work | 3. Update prompt file | 4. Increment version
local/.prompts/README.md,277,other,md,5. **Document gaps**: Note missing capabilities,3. **Archive obsolete**: Move to `archive/` if no longer relevant | 4. **Cross-reference**: Link related prompts | 5. **Document gaps**: Note missing capabilities |  | ---
local/.prompts/README.md,309,other,md,2. Note improvements needed, | 1. Use prompt in session | 2. Note improvements needed | 3. Update prompt file | 4. Increment version
local/.prompts/logseq-doc-expert.md,116,other,md,- **task_case**: Task status not uppercase (todo â†’ TODO), | ### Errors (Fix Immediately) | - **task_case**: Task status not uppercase (todo â†’ TODO) | - **heading_format**: Missing space after # in headings | - **code_unclosed**: Unclosed code blocks
local/.prompts/logseq-doc-expert.md,146,other,md,"- **Suggest fix**: ""Change `todo` to `TODO`""","- **Show context**: Include the problematic line | - **Explain why**: ""This breaks Logseq's task queries"" | - **Suggest fix**: ""Change `todo` to `TODO`"" |  | ### 3. Fixing"
local/.prompts/logseq-doc-expert.md,225,other,md,Current: `- todo Research new LLM routing`,ðŸ”´ Errors (Fix Required): | 1. Line 42: Task status lowercase |    Current: `- todo Research new LLM routing` |    Fix: `- TODO Research new LLM routing` | 
local/.prompts/logseq-doc-expert.md,226,other,md,Fix: `- TODO Research new LLM routing`,1. Line 42: Task status lowercase |    Current: `- todo Research new LLM routing` |    Fix: `- TODO Research new LLM routing` |  | 2. Line 67: Task status lowercase
local/.prompts/logseq-doc-expert.md,298,other,md,"Also check for [custom rule], like ""all TODO items should have a related:: property"""," | ``` | Also check for [custom rule], like ""all TODO items should have a related:: property"" | ``` | "
local/.prompts/logseq-doc-expert.md,335,other,md,"- Task statuses: Always UPPERCASE (TODO, DOING, DONE, LATER)","### Logseq Best Practices |  | - Task statuses: Always UPPERCASE (TODO, DOING, DONE, LATER) | - Lists: Blank line before and after | - Code blocks: Always specify language"
local/.prompts/templates/prompt-template.md,354,other,md,## ðŸ“ Template Usage Notes,--- |  | ## ðŸ“ Template Usage Notes |  | ### Before Publishing
local/.prompts/templates/prompt-template.md,365,other,md,"- [ ] Remove this ""Template Usage Notes"" section","- [ ] Specify correct category and difficulty | - [ ] Add version and creation date | - [ ] Remove this ""Template Usage Notes"" section |  | ### Content Guidelines"
.augment/rules/package-source.instructions.md,25,augment,md,- âœ… Zero known critical bugs,- âœ… Real-world usage validation | - âœ… Comprehensive documentation | - âœ… Zero known critical bugs |  | **Philosophy:** Only proven code following production-quality standards enters this repository.
.augment/rules/package-source.instructions.md,233,augment,md,- âœ… No known critical bugs,- âœ… Ruff + Pyright checks pass | - âœ… Real-world usage validation | - âœ… No known critical bugs |  | ### Contribution Workflow
.augment/rules/package-source.instructions.md,549,augment,md,## Debugging Tips,"5. Use Conventional Commits format: `feat:`, `fix:`, `docs:`, `refactor:`, `test:`, `chore:` |  | ## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives"
.augment/rules/package-source.instructions.md,551,augment,md,- Use `WorkflowContext.metadata` for debugging state across primitives,"## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected`"
.augment/rules/package-source.instructions.md,552,augment,md,"- Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")`"," | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected` | - For async issues, ensure `@pytest.mark.asyncio` decorator present"
.augment/rules/documentation.instructions.md,230,augment,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
.github/PULL_REQUEST_TEMPLATE.md,8,config,md,- [ ] `fix`: Bug fix, | - [ ] `feat`: New feature | - [ ] `fix`: Bug fix | - [ ] `docs`: Documentation update | - [ ] `refactor`: Code refactoring
.github/PULL_REQUEST_TEMPLATE.md,57,config,md,## Deployment Notes,<!-- Add screenshots for UI changes --> |  | ## Deployment Notes |  | <!-- Any special deployment considerations? -->
.github/copilot-instructions.md,74,config,md,### ï¿½ðŸ“‹ TODO Management (Required for All Agents),--- |  | ### ï¿½ðŸ“‹ TODO Management (Required for All Agents) |  | **ALL agents must use the Logseq TODO management system:**
.github/copilot-instructions.md,76,config,md,**ALL agents must use the Logseq TODO management system:**,### ï¿½ðŸ“‹ TODO Management (Required for All Agents) |  | **ALL agents must use the Logseq TODO management system:** |  | - **System Documentation:** `logseq/pages/TODO Management System.md`
.github/copilot-instructions.md,78,config,md,- **System Documentation:** `logseq/pages/TODO Management System.md`,**ALL agents must use the Logseq TODO management system:** |  | - **System Documentation:** `logseq/pages/TODO Management System.md` | - **Daily Journals:** `logseq/journals/YYYY_MM_DD.md` | - **Tag Convention:**
.github/copilot-instructions.md,81,config,md,"- `#dev-todo` - Development tasks (code, tests, CI/CD, infrastructure)","- **Daily Journals:** `logseq/journals/YYYY_MM_DD.md` | - **Tag Convention:** |   - `#dev-todo` - Development tasks (code, tests, CI/CD, infrastructure) |   - `#user-todo` - User/agent tasks (learning, onboarding, examples) | "
.github/copilot-instructions.md,82,config,md,"- `#user-todo` - User/agent tasks (learning, onboarding, examples)","- **Tag Convention:** |   - `#dev-todo` - Development tasks (code, tests, CI/CD, infrastructure) |   - `#user-todo` - User/agent tasks (learning, onboarding, examples) |  | **Agent Requirements:**"
.github/copilot-instructions.md,86,config,md,"1. **Add TODOs:** When creating work items, add to today's journal with proper tags/properties","**Agent Requirements:** |  | 1. **Add TODOs:** When creating work items, add to today's journal with proper tags/properties | 2. **Update Status:** Mark tasks as DOING when starting, DONE when complete | 3. **Link Context:** Use `related::` property to link Logseq pages"
.github/copilot-instructions.md,90,config,md,5. **Daily Review:** Check TODO dashboards before/after work sessions,3. **Link Context:** Use `related::` property to link Logseq pages | 4. **Document Blockers:** Use `blocked::` and `blocker::` properties | 5. **Daily Review:** Check TODO dashboards before/after work sessions |  | **Properties to Use:**
.github/copilot-instructions.md,95,config,md,- TODO [Task] #dev-todo, | ```markdown | - TODO [Task] #dev-todo |   type:: implementation | testing | documentation | infrastructure |   priority:: high | medium | low
.github/copilot-instructions.md,361,config,md,"| `**` (all files) | `logseq-knowledge-base.instructions.md` | Use Logseq for TODOs, journals, and knowledge management |","| `scripts/**/*.py` | `scripts.instructions.md` | Use primitives for orchestration, clear documentation | | | `**/*.md`, `**/README.md` | `documentation.instructions.md` | Clear, actionable, with code examples | | | `**` (all files) | `logseq-knowledge-base.instructions.md` | Use Logseq for TODOs, journals, and knowledge management | |  | **Always check the relevant instruction file** before editing files of that type."
.github/copilot-instructions.md,616,config,md,# Debug with pdb,uv run pytest packages/tta-dev-primitives/tests/test_sequential.py -v |  | # Debug with pdb | uv run pytest --pdb | ```
.github/copilot-instructions.md,640,config,md,- `fix/` - Bug fixes, | - `feature/` - New features | - `fix/` - Bug fixes | - `docs/` - Documentation updates | - `refactor/` - Code refactoring
.github/copilot-instructions.md,854,config,md,### Verification and Debugging,"> ""The test suite is timing out after 45 minutes. I recommend upgrading to `ubuntu-4-core` runner for faster parallel test execution. Update `.github/workflows/copilot-setup-steps.yml` line 29 to `runs-on: ubuntu-4-core`."" |  | ### Verification and Debugging |  | **Check your environment:**"
.github/copilot-instructions.md,908,config,md,- **TODO Management:** [`logseq/pages/TODO Management System.md`](../logseq/pages/TODO Management System.md) - Required for all agents,- **Toolsets Guide:** [`docs/guides/copilot-toolsets-guide.md`](../docs/guides/copilot-toolsets-guide.md) | - **Getting Started:** [`GETTING_STARTED.md`](../GETTING_STARTED.md) | - **TODO Management:** [`logseq/pages/TODO Management System.md`](../logseq/pages/TODO Management System.md) - Required for all agents | - **Logseq Guide:** [`logseq/ADVANCED_FEATURES.md`](../logseq/ADVANCED_FEATURES.md) - Knowledge base features | 
.github/AGENT_CHECKLIST.md,87,config,md,- [ ] Log levels appropriate (DEBUG/INFO/WARNING/ERROR),"- [ ] Structured logging used (not print statements) | - [ ] Log messages include context (correlation_id, trace_id) | - [ ] Log levels appropriate (DEBUG/INFO/WARNING/ERROR) | - [ ] No sensitive data in logs | "
.github/AGENT_CHECKLIST.md,117,config,md,- [ ] No `TODO` or `FIXME` comments in committed code,### Manual Verification |  | - [ ] No `TODO` or `FIXME` comments in committed code | - [ ] No debug print statements | - [ ] No commented-out code blocks
.github/AGENT_CHECKLIST.md,118,config,md,- [ ] No debug print statements, | - [ ] No `TODO` or `FIXME` comments in committed code | - [ ] No debug print statements | - [ ] No commented-out code blocks | - [ ] No merge conflict markers
.github/workflows/test-gemini-keys.yml,187,config,yml,"echo ""**Note**: This key also works as a fallback"" >> $GITHUB_STEP_SUMMARY","            echo ""**Status**: Working"" >> $GITHUB_STEP_SUMMARY |             echo """" >> $GITHUB_STEP_SUMMARY |             echo ""**Note**: This key also works as a fallback"" >> $GITHUB_STEP_SUMMARY |           else |             echo ""### âŒ Legacy Key (GEMINI_API_KEY)"" >> $GITHUB_STEP_SUMMARY"
.github/workflows/test-gemini-keys.yml,205,config,yml,"echo ""   - File bug report with gemini-cli maintainers"" >> $GITHUB_STEP_SUMMARY","            echo ""3. ðŸ”§ Options:"" >> $GITHUB_STEP_SUMMARY |             echo ""   - Implement direct API calls in workflow"" >> $GITHUB_STEP_SUMMARY |             echo ""   - File bug report with gemini-cli maintainers"" >> $GITHUB_STEP_SUMMARY |             echo ""   - Try alternative Gemini GitHub Actions"" >> $GITHUB_STEP_SUMMARY |           else"
.github/workflows/gemini-dispatch.yml,26,config,yml,debugger:, | jobs: |   debugger: |     if: |- |      ${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }}
.github/workflows/gemini-dispatch.yml,28,config,yml,${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }},  debugger: |     if: |- |      ${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }} |     runs-on: 'ubuntu-latest' |     permissions:
.github/workflows/gemini-dispatch.yml,33,config,yml,- name: 'Print context for debugging',      contents: 'read' |     steps: |       - name: 'Print context for debugging' |         env: |           DEBUG_event_name: '${{ github.event_name }}'
.github/workflows/gemini-dispatch.yml,35,config,yml,DEBUG_event_name: '${{ github.event_name }}',      - name: 'Print context for debugging' |         env: |           DEBUG_event_name: '${{ github.event_name }}' |           DEBUG_event__action: '${{ github.event.action }}' |           DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}'
.github/workflows/gemini-dispatch.yml,36,config,yml,DEBUG_event__action: '${{ github.event.action }}',        env: |           DEBUG_event_name: '${{ github.event_name }}' |           DEBUG_event__action: '${{ github.event.action }}' |           DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}' |           DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}'
.github/workflows/gemini-dispatch.yml,37,config,yml,DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}',          DEBUG_event_name: '${{ github.event_name }}' |           DEBUG_event__action: '${{ github.event.action }}' |           DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}' |           DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}' |           DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}'
.github/workflows/gemini-dispatch.yml,38,config,yml,DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}',          DEBUG_event__action: '${{ github.event.action }}' |           DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}' |           DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}' |           DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}' |           DEBUG_event__review__author_association: '${{ github.event.review.author_association }}'
.github/workflows/gemini-dispatch.yml,39,config,yml,DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}',          DEBUG_event__comment__author_association: '${{ github.event.comment.author_association }}' |           DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}' |           DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}' |           DEBUG_event__review__author_association: '${{ github.event.review.author_association }}' |           DEBUG_event: '${{ toJSON(github.event) }}'
.github/workflows/gemini-dispatch.yml,40,config,yml,DEBUG_event__review__author_association: '${{ github.event.review.author_association }}',          DEBUG_event__issue__author_association: '${{ github.event.issue.author_association }}' |           DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}' |           DEBUG_event__review__author_association: '${{ github.event.review.author_association }}' |           DEBUG_event: '${{ toJSON(github.event) }}' |         run: |-
.github/workflows/gemini-dispatch.yml,41,config,yml,DEBUG_event: '${{ toJSON(github.event) }}',          DEBUG_event__pull_request__author_association: '${{ github.event.pull_request.author_association }}' |           DEBUG_event__review__author_association: '${{ github.event.review.author_association }}' |           DEBUG_event: '${{ toJSON(github.event) }}' |         run: |- |           env | grep '^DEBUG_'
.github/workflows/gemini-dispatch.yml,43,config,yml,env | grep '^DEBUG_',          DEBUG_event: '${{ toJSON(github.event) }}' |         run: |- |           env | grep '^DEBUG_' |  |   dispatch:
.github/workflows/gemini-test-minimal.yml,26,config,yml,gemini_debug: true,          gemini_api_key: '${{ secrets.GEMINI_API_KEY }}' |           gemini_model: 'gemini-1.5-flash' |           gemini_debug: true |           settings: |- |             {
.github/workflows/gemini-invoke.yml,73,config,yml,# Debug output,"          RESPONSE=$(jq -r '.response // empty' gemini_output.json) |  |           # Debug output |           echo ""Response length: ${#RESPONSE}"" |           echo ""Response preview: ${RESPONSE:0:200}"""
.github/workflows/gemini-invoke.yml,84,config,yml,# Also save full JSON for debugging,"          } >> ""${GITHUB_OUTPUT}"" |  |           # Also save full JSON for debugging |           echo ""Full JSON output:"" |           cat gemini_output.json"
.github/workflows/gemini-invoke.yml,89,config,yml,"if: always()  # Always run to debug, will check response inside script"," |       - name: 'Post Gemini Response' |         if: always()  # Always run to debug, will check response inside script |         uses: 'actions/github-script@v7' |         env:"
.github/workflows/gemini-invoke.yml,99,config,yml,"console.log('DEBUG: Response length:', response.length);","            const issueNumber = ${{ inputs.issue_number || 0 }}; |  |             console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Response preview:', response.substring(0, 100)); |             console.log('DEBUG: Issue number:', issueNumber);"
.github/workflows/gemini-invoke.yml,100,config,yml,"console.log('DEBUG: Response preview:', response.substring(0, 100));"," |             console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Response preview:', response.substring(0, 100)); |             console.log('DEBUG: Issue number:', issueNumber); | "
.github/workflows/gemini-invoke.yml,101,config,yml,"console.log('DEBUG: Issue number:', issueNumber);","            console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Response preview:', response.substring(0, 100)); |             console.log('DEBUG: Issue number:', issueNumber); |  |             if (!response || response.trim() === '') {"
.github/workflows/validate-todos.yml,1,config,yml,name: TODO Compliance Validation,name: TODO Compliance Validation |  | on:
.github/workflows/validate-todos.yml,9,config,yml,- 'scripts/validate-todos.py',      - 'logseq/journals/**' |       - 'logseq/pages/**' |       - 'scripts/validate-todos.py' |   push: |     branches: [main]
.github/workflows/validate-todos.yml,15,config,yml,- 'scripts/validate-todos.py',      - 'logseq/journals/**' |       - 'logseq/pages/**' |       - 'scripts/validate-todos.py' |  | jobs:
.github/workflows/validate-todos.yml,18,config,yml,validate-todos:, | jobs: |   validate-todos: |     runs-on: ubuntu-latest |     name: Validate Logseq TODO Compliance
.github/workflows/validate-todos.yml,20,config,yml,name: Validate Logseq TODO Compliance,  validate-todos: |     runs-on: ubuntu-latest |     name: Validate Logseq TODO Compliance |  |     steps:
.github/workflows/validate-todos.yml,40,config,yml,- name: Run TODO validation,        run: uv sync --all-extras |  |       - name: Run TODO validation |         id: validate |         run: |
.github/workflows/validate-todos.yml,43,config,yml,"echo ""Running TODO validation...""","        id: validate |         run: | |           echo ""Running TODO validation..."" |           uv run python scripts/validate-todos.py --json > validation-result.json |           cat validation-result.json"
.github/workflows/validate-todos.yml,44,config,yml,uv run python scripts/validate-todos.py --json > validation-result.json,"        run: | |           echo ""Running TODO validation..."" |           uv run python scripts/validate-todos.py --json > validation-result.json |           cat validation-result.json |           "
.github/workflows/validate-todos.yml,49,config,yml,TOTAL=$(jq -r '.total_todos' validation-result.json),          # Extract compliance rate |           COMPLIANCE=$(jq -r '.compliance_rate' validation-result.json) |           TOTAL=$(jq -r '.total_todos' validation-result.json) |           COMPLIANT=$(jq -r '.compliant_todos' validation-result.json) |           ISSUES=$(jq -r '.issues_count' validation-result.json)
.github/workflows/validate-todos.yml,50,config,yml,COMPLIANT=$(jq -r '.compliant_todos' validation-result.json),          COMPLIANCE=$(jq -r '.compliance_rate' validation-result.json) |           TOTAL=$(jq -r '.total_todos' validation-result.json) |           COMPLIANT=$(jq -r '.compliant_todos' validation-result.json) |           ISSUES=$(jq -r '.issues_count' validation-result.json) |           MISSING_PAGES=$(jq -r '.missing_kb_pages_count' validation-result.json)
.github/workflows/validate-todos.yml,55,config,yml,"echo ""total_todos=$TOTAL"" >> $GITHUB_OUTPUT","           |           echo ""compliance_rate=$COMPLIANCE"" >> $GITHUB_OUTPUT |           echo ""total_todos=$TOTAL"" >> $GITHUB_OUTPUT |           echo ""compliant_todos=$COMPLIANT"" >> $GITHUB_OUTPUT |           echo ""issues_count=$ISSUES"" >> $GITHUB_OUTPUT"
.github/workflows/validate-todos.yml,56,config,yml,"echo ""compliant_todos=$COMPLIANT"" >> $GITHUB_OUTPUT","          echo ""compliance_rate=$COMPLIANCE"" >> $GITHUB_OUTPUT |           echo ""total_todos=$TOTAL"" >> $GITHUB_OUTPUT |           echo ""compliant_todos=$COMPLIANT"" >> $GITHUB_OUTPUT |           echo ""issues_count=$ISSUES"" >> $GITHUB_OUTPUT |           echo ""missing_kb_pages=$MISSING_PAGES"" >> $GITHUB_OUTPUT"
.github/workflows/validate-todos.yml,62,config,yml,"echo ""âŒ TODO compliance is $COMPLIANCE%, expected 100%""","          # Check if compliance is 100% |           if [ ""$COMPLIANCE"" != ""100.0"" ]; then |             echo ""âŒ TODO compliance is $COMPLIANCE%, expected 100%"" |             exit 1 |           fi"
.github/workflows/validate-todos.yml,66,config,yml,"echo ""âœ… TODO compliance: 100% ($COMPLIANT/$TOTAL TODOs)""","          fi |            |           echo ""âœ… TODO compliance: 100% ($COMPLIANT/$TOTAL TODOs)"" |  |       - name: Comment PR with validation results"
.github/workflows/validate-todos.yml,77,config,yml,const total = result.total_todos;,             |             const compliance = result.compliance_rate; |             const total = result.total_todos; |             const compliant = result.compliant_todos; |             const issues = result.issues_count;
.github/workflows/validate-todos.yml,78,config,yml,const compliant = result.compliant_todos;,            const compliance = result.compliance_rate; |             const total = result.total_todos; |             const compliant = result.compliant_todos; |             const issues = result.issues_count; |             const missingPages = result.missing_kb_pages_count;
.github/workflows/validate-todos.yml,85,config,yml,let body = `## ${status} TODO Compliance Validation - ${statusText}\n\n`;,            const statusText = compliance === 100 ? 'PASSED' : 'FAILED'; |              |             let body = `## ${status} TODO Compliance Validation - ${statusText}\n\n`; |             body += `**Compliance Rate:** ${compliance}%\n`; |             body += `**TODOs:** ${compliant}/${total} compliant\n`;
.github/workflows/validate-todos.yml,87,config,yml,body += `**TODOs:** ${compliant}/${total} compliant\n`;,            let body = `## ${status} TODO Compliance Validation - ${statusText}\n\n`; |             body += `**Compliance Rate:** ${compliance}%\n`; |             body += `**TODOs:** ${compliant}/${total} compliant\n`; |              |             if (issues > 0) {
.github/workflows/validate-todos.yml,98,config,yml,body += `\nâœ… All TODOs are properly formatted with required tags and properties!\n`;,             |             if (compliance === 100) { |               body += `\nâœ… All TODOs are properly formatted with required tags and properties!\n`; |             } else { |               body += `\nâŒ Some TODOs are missing required tags or properties.\n`;
.github/workflows/validate-todos.yml,100,config,yml,body += `\nâŒ Some TODOs are missing required tags or properties.\n`;,              body += `\nâœ… All TODOs are properly formatted with required tags and properties!\n`; |             } else { |               body += `\nâŒ Some TODOs are missing required tags or properties.\n`; |               body += `\nPlease run \`uv run python scripts/validate-todos.py\` locally to see detailed issues.\n`; |               body += `\n**Required for all TODOs:**\n`;
.github/workflows/validate-todos.yml,101,config,yml,body += `\nPlease run \`uv run python scripts/validate-todos.py\` locally to see detailed issues.\n`;,            } else { |               body += `\nâŒ Some TODOs are missing required tags or properties.\n`; |               body += `\nPlease run \`uv run python scripts/validate-todos.py\` locally to see detailed issues.\n`; |               body += `\n**Required for all TODOs:**\n`; |               body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`;
.github/workflows/validate-todos.yml,102,config,yml,body += `\n**Required for all TODOs:**\n`;,"              body += `\nâŒ Some TODOs are missing required tags or properties.\n`; |               body += `\nPlease run \`uv run python scripts/validate-todos.py\` locally to see detailed issues.\n`; |               body += `\n**Required for all TODOs:**\n`; |               body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`; |               body += `- For \`#dev-todo\`: \`type::\`, \`priority::\`, \`package::\` properties\n`;"
.github/workflows/validate-todos.yml,103,config,yml,body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`;,"              body += `\nPlease run \`uv run python scripts/validate-todos.py\` locally to see detailed issues.\n`; |               body += `\n**Required for all TODOs:**\n`; |               body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`; |               body += `- For \`#dev-todo\`: \`type::\`, \`priority::\`, \`package::\` properties\n`; |               body += `- For \`#user-todo\`: \`type::\`, \`audience::\`, \`difficulty::\` properties\n`;"
.github/workflows/validate-todos.yml,104,config,yml,"body += `- For \`#dev-todo\`: \`type::\`, \`priority::\`, \`package::\` properties\n`;","              body += `\n**Required for all TODOs:**\n`; |               body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`; |               body += `- For \`#dev-todo\`: \`type::\`, \`priority::\`, \`package::\` properties\n`; |               body += `- For \`#user-todo\`: \`type::\`, \`audience::\`, \`difficulty::\` properties\n`; |             }"
.github/workflows/validate-todos.yml,105,config,yml,"body += `- For \`#user-todo\`: \`type::\`, \`audience::\`, \`difficulty::\` properties\n`;","              body += `- Category tag: \`#dev-todo\` or \`#user-todo\`\n`; |               body += `- For \`#dev-todo\`: \`type::\`, \`priority::\`, \`package::\` properties\n`; |               body += `- For \`#user-todo\`: \`type::\`, \`audience::\`, \`difficulty::\` properties\n`; |             } |             "
.github/workflows/validate-todos.yml,119,config,yml,name: todo-validation-results,        uses: actions/upload-artifact@v4 |         with: |           name: todo-validation-results |           path: validation-result.json |           retention-days: 30
.github/workflows/auto-assign-copilot.yml,65,config,yml,console.log('Note: Copilot may need to be added as a collaborator to the repository');,"              // If the error is about Copilot not being a collaborator, provide helpful info |               if (error.message.includes('not a collaborator')) { |                 console.log('Note: Copilot may need to be added as a collaborator to the repository'); |                 console.log('Alternatively, ensure CODEOWNERS file is properly configured'); |               }"
.github/workflows/gemini-triage.yml,36,config,yml,# NOTE: we intentionally do not use the given token. The default,        uses: 'actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea' # ratchet:actions/github-script@v7.0.1 |         with: |           # NOTE: we intentionally do not use the given token. The default |           # GITHUB_TOKEN provided by the action has enough permissions to read |           # the labels.
.github/workflows/gemini-triage.yml,69,config,yml,gemini_debug: '${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }}',          gemini_api_key: '${{ secrets.GEMINI_API_KEY }}' |           gemini_cli_version: '${{ vars.GEMINI_CLI_VERSION }}' |           gemini_debug: '${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }}' |           gemini_model: '${{ vars.GEMINI_MODEL }}' |           google_api_key: '${{ secrets.GOOGLE_API_KEY }}'
.github/workflows/gemini-triage.yml,141,config,yml,"echo ""SELECTED_LABELS=bug,enhancement"" >> ""/tmp/runner/env"""," |                 ``` |                 echo ""SELECTED_LABELS=bug,enhancement"" >> ""/tmp/runner/env"" |                 ``` | "
.github/workflows/test-mcp-versions.yml,44,config,yml,gemini_debug: true,          use_vertex_ai: false |           use_gemini_code_assist: false |           gemini_debug: true |           prompt: '${{ inputs.command }}' |           settings: |-
.github/workflows/gemini-review.yml,61,config,yml,gemini_debug: '${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }}',          gemini_api_key: '${{ secrets.GEMINI_API_KEY }}' |           gemini_cli_version: '${{ vars.GEMINI_CLI_VERSION }}' |           gemini_debug: '${{ fromJSON(vars.DEBUG || vars.ACTIONS_STEP_DEBUG || false) }}' |           gemini_model: '${{ vars.GEMINI_MODEL }}' |           google_api_key: '${{ secrets.GOOGLE_API_KEY }}'
.github/workflows/gemini-review.yml,130,config,yml,"5. **Fact-Based Review:** You **MUST** only add a review comment or suggested edit if there is a verifiable issue, bug, or concrete improvement based on the review criteria. **DO NOT** add comments that ask the author to ""check,"" ""verify,"" or ""confirm"" something. **DO NOT** add comments that simply explain or validate what the code does.","            4. **Tool Exclusivity:** All interactions with GitHub **MUST** be performed using the provided `mcp__github__*` tools. |  |             5. **Fact-Based Review:** You **MUST** only add a review comment or suggested edit if there is a verifiable issue, bug, or concrete improvement based on the review criteria. **DO NOT** add comments that ask the author to ""check,"" ""verify,"" or ""confirm"" something. **DO NOT** add comments that simply explain or validate what the code does. |  |             6. **Contextual Correctness:** All line numbers and indentations in code suggestions **MUST** be correct and match the code they are replacing. Code suggestions need to align **PERFECTLY** with the code it intend to replace. Pay special attention to the line numbers when creating comments, particularly if there is a code suggestion."
.github/workflows/gemini-review.yml,215,config,yml,"- `ðŸŸ `: High - the issue could cause significant problems, bugs, or performance degradation in the future. It should be addressed before merge.","            - `ðŸ”´`: Critical - the issue will cause a production failure, security breach, data corruption, or other catastrophic outcomes. It **MUST** be fixed before merge. |  |             - `ðŸŸ `: High - the issue could cause significant problems, bugs, or performance degradation in the future. It should be addressed before merge. |  |             - `ðŸŸ¡`: Medium - the issue represents a deviation from best practices or introduces technical debt. It should be considered for improvement."
.github/workflows/test-gemini-cli-no-mcp.yml,30,config,yml,gemini_debug: true,          use_vertex_ai: false |           use_gemini_code_assist: false |           gemini_debug: true |           prompt: '${{ inputs.command }}' |           # NO MCP server configuration
.github/workflows/gemini-invoke-advanced.yml,73,config,yml,# Debug output,"            RESPONSE=$(jq -r '.response // empty' gemini_output.json) |  |             # Debug output |             echo ""Response length: ${#RESPONSE}"" |             echo ""Response preview: ${RESPONSE:0:200}..."""
.github/workflows/gemini-invoke-advanced.yml,84,config,yml,# Show full JSON for debugging,"            } >> ""${GITHUB_OUTPUT}"" |  |             # Show full JSON for debugging |             echo ""Full JSON output:"" |             cat gemini_output.json"
.github/workflows/gemini-invoke-advanced.yml,102,config,yml,"console.log('DEBUG: Response length:', response.length);","            const isPR = ${{ inputs.is_pull_request }}; |  |             console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Issue/PR number:', issueNumber); |             console.log('DEBUG: Is Pull Request:', isPR);"
.github/workflows/gemini-invoke-advanced.yml,103,config,yml,"console.log('DEBUG: Issue/PR number:', issueNumber);"," |             console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Issue/PR number:', issueNumber); |             console.log('DEBUG: Is Pull Request:', isPR); | "
.github/workflows/gemini-invoke-advanced.yml,104,config,yml,"console.log('DEBUG: Is Pull Request:', isPR);","            console.log('DEBUG: Response length:', response.length); |             console.log('DEBUG: Issue/PR number:', issueNumber); |             console.log('DEBUG: Is Pull Request:', isPR); |  |             if (!response || response.trim() === '') {"
.github/workflows/gemini-invoke-advanced.yml,135,config,yml,apm-debug.log,          path: | |             gemini_output.json |             apm-debug.log |           retention-days: 7 | 
.github/workflows/secrets-validation.yml,31,config,yml,DEBUG: false,        CACHE_METRICS_ENABLED: false |         CACHE_METRICS_PORT: 9090 |         DEBUG: false |         ENVIRONMENT: development |       run: |
.github/workflows/secrets-validation.yml,44,config,yml,DEBUG: false,        CACHE_METRICS_ENABLED: false |         CACHE_METRICS_PORT: 9090 |         DEBUG: false |         ENVIRONMENT: development |         PYTEST_CURRENT_TEST: true
.github/workflows/kb-validation.yml,209,config,yml,"""logseq/pages/TODO Management System.md""","          # Check for critical KB pages |           required_pages=( |             ""logseq/pages/TODO Management System.md"" |             ""logseq/pages/TTA.dev___TODO Architecture.md"" |             ""logseq/pages/TODO Templates.md"""
.github/workflows/kb-validation.yml,210,config,yml,"""logseq/pages/TTA.dev___TODO Architecture.md""","          required_pages=( |             ""logseq/pages/TODO Management System.md"" |             ""logseq/pages/TTA.dev___TODO Architecture.md"" |             ""logseq/pages/TODO Templates.md"" |           )"
.github/workflows/kb-validation.yml,211,config,yml,"""logseq/pages/TODO Templates.md""","            ""logseq/pages/TODO Management System.md"" |             ""logseq/pages/TTA.dev___TODO Architecture.md"" |             ""logseq/pages/TODO Templates.md"" |           ) | "
.github/workflows/kb-validation.yml,250,config,yml,kb-todo-sync:,          fi |  |   kb-todo-sync: |     name: KB TODO Sync Check |     runs-on: ubuntu-latest
.github/workflows/kb-validation.yml,251,config,yml,name: KB TODO Sync Check, |   kb-todo-sync: |     name: KB TODO Sync Check |     runs-on: ubuntu-latest |     timeout-minutes: 10
.github/workflows/kb-validation.yml,277,config,yml,- name: Check for new TODOs in code,          uv pip install -e packages/tta-kb-automation |  |       - name: Check for new TODOs in code |         run: | |           # Get changed Python files
.github/workflows/kb-validation.yml,283,config,yml,"echo ""No Python files changed, skipping TODO sync check"""," |           if [ ! -s changed_files.txt ]; then |             echo ""No Python files changed, skipping TODO sync check"" |             exit 0 |           fi"
.github/workflows/kb-validation.yml,287,config,yml,"echo ""Checking for TODOs in changed files:""","          fi |  |           echo ""Checking for TODOs in changed files:"" |           cat changed_files.txt | "
.github/workflows/kb-validation.yml,290,config,yml,# Run TODO extraction on changed files,"          cat changed_files.txt |  |           # Run TODO extraction on changed files |           uv run python -c "" |           import asyncio"
.github/workflows/kb-validation.yml,294,config,yml,"from tta_kb_automation import ExtractTODOs, WorkflowContext","          import asyncio |           from pathlib import Path |           from tta_kb_automation import ExtractTODOs, WorkflowContext |  |           async def main():"
.github/workflows/kb-validation.yml,304,config,yml,extractor = ExtractTODOs(),                  return |  |               extractor = ExtractTODOs() |               context = WorkflowContext(workflow_id='ci-todo-check') | 
.github/workflows/kb-validation.yml,305,config,yml,context = WorkflowContext(workflow_id='ci-todo-check'), |               extractor = ExtractTODOs() |               context = WorkflowContext(workflow_id='ci-todo-check') |  |               # ExtractTODOs expects {'files': [list of paths]}
.github/workflows/kb-validation.yml,307,config,yml,# ExtractTODOs expects {'files': [list of paths]},"              context = WorkflowContext(workflow_id='ci-todo-check') |  |               # ExtractTODOs expects {'files': [list of paths]} |               result = await extractor.execute({'files': changed_files}, context) |               all_todos = result['todos']"
.github/workflows/kb-validation.yml,309,config,yml,all_todos = result['todos'],"              # ExtractTODOs expects {'files': [list of paths]} |               result = await extractor.execute({'files': changed_files}, context) |               all_todos = result['todos'] |  |               if all_todos:"
.github/workflows/kb-validation.yml,311,config,yml,if all_todos:,              all_todos = result['todos'] |  |               if all_todos: |                   print(f'âš ï¸  Found {len(all_todos)} TODOs in changed files:') |                   for todo in all_todos[:5]:
.github/workflows/kb-validation.yml,312,config,yml,print(f'âš ï¸  Found {len(all_todos)} TODOs in changed files:')," |               if all_todos: |                   print(f'âš ï¸  Found {len(all_todos)} TODOs in changed files:') |                   for todo in all_todos[:5]: |                       print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...')"
.github/workflows/kb-validation.yml,313,config,yml,for todo in all_todos[:5]:,"              if all_todos: |                   print(f'âš ï¸  Found {len(all_todos)} TODOs in changed files:') |                   for todo in all_todos[:5]: |                       print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...') |                   if len(all_todos) > 5:"
.github/workflows/kb-validation.yml,314,config,yml,"print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...')","                  print(f'âš ï¸  Found {len(all_todos)} TODOs in changed files:') |                   for todo in all_todos[:5]: |                       print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...') |                   if len(all_todos) > 5: |                       print(f'  ... and {len(all_todos) - 5} more')"
.github/workflows/kb-validation.yml,315,config,yml,if len(all_todos) > 5:,"                  for todo in all_todos[:5]: |                       print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...') |                   if len(all_todos) > 5: |                       print(f'  ... and {len(all_todos) - 5} more') |                   print('')"
.github/workflows/kb-validation.yml,316,config,yml,print(f'  ... and {len(all_todos) - 5} more'),"                      print(f'  - {todo[\""file\""]}:{todo[\""line_number\""]}: {todo[\""todo_text\""][:60]}...') |                   if len(all_todos) > 5: |                       print(f'  ... and {len(all_todos) - 5} more') |                   print('') |                   print('ðŸ’¡ Consider syncing these TODOs to today\\'s journal entry.')"
.github/workflows/kb-validation.yml,318,config,yml,print('ðŸ’¡ Consider syncing these TODOs to today\\'s journal entry.'),                      print(f'  ... and {len(all_todos) - 5} more') |                   print('') |                   print('ðŸ’¡ Consider syncing these TODOs to today\\'s journal entry.') |               else: |                   print('âœ… No TODOs found in changed files')
.github/workflows/kb-validation.yml,320,config,yml,print('âœ… No TODOs found in changed files'),                  print('ðŸ’¡ Consider syncing these TODOs to today\\'s journal entry.') |               else: |                   print('âœ… No TODOs found in changed files') |  |           asyncio.run(main())
.github/prompts/triage-issue.prompt.md,7,config,md,Read GEMINI.md for project overview and GITHUB_ISSUE_TODO_MAPPING.md for issue organization patterns.,## Context |  | Read GEMINI.md for project overview and GITHUB_ISSUE_TODO_MAPPING.md for issue organization patterns. |  | ## Your Task
.github/prompts/triage-issue.prompt.md,14,config,md,- Type: bug | feature | documentation | refactor | question, | 1. **Classification** |    - Type: bug | feature | documentation | refactor | question |    - Priority: critical | high | medium | low |    - Complexity: trivial | simple | moderate | complex
.github/prompts/triage-issue.prompt.md,27,config,md,"- `bug`, `feature`, `documentation`, `refactor`","2. **Labels to Add** |    Suggest appropriate labels: |    - `bug`, `feature`, `documentation`, `refactor` |    - `good-first-issue`, `help-wanted` |    - `priority:high`, `priority:medium`, `priority:low`"
.github/prompts/triage-issue.prompt.md,64,config,md,- Type: [bug|feature|documentation|refactor|question], | **Classification:** | - Type: [bug|feature|documentation|refactor|question] | - Priority: [critical|high|medium|low] | - Complexity: [trivial|simple|moderate|complex]
.github/prompts/triage-issue.prompt.md,87,config,md,**Additional Notes:**,3. ... |  | **Additional Notes:** | [Any other relevant information] | ```
.github/instructions/package-source.instructions.instructions.md,25,config,md,- âœ… Zero known critical bugs,- âœ… Real-world usage validation | - âœ… Comprehensive documentation | - âœ… Zero known critical bugs |  | **Philosophy:** Only proven code following production-quality standards enters this repository.
.github/instructions/package-source.instructions.instructions.md,233,config,md,- âœ… No known critical bugs,- âœ… Ruff + Pyright checks pass | - âœ… Real-world usage validation | - âœ… No known critical bugs |  | ### Contribution Workflow
.github/instructions/package-source.instructions.instructions.md,549,config,md,## Debugging Tips,"5. Use Conventional Commits format: `feat:`, `fix:`, `docs:`, `refactor:`, `test:`, `chore:` |  | ## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives"
.github/instructions/package-source.instructions.instructions.md,551,config,md,- Use `WorkflowContext.metadata` for debugging state across primitives,"## Debugging Tips |  | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected`"
.github/instructions/package-source.instructions.instructions.md,552,config,md,"- Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")`"," | - Use `WorkflowContext.metadata` for debugging state across primitives | - Enable structured logging: `from tta_workflow_primitives.observability import setup_logging; setup_logging(""DEBUG"")` | - Check test output for primitive call counts: `assert mock.call_count == expected` | - For async issues, ensure `@pytest.mark.asyncio` decorator present"
.github/instructions/logseq-knowledge-base.instructions.md,2,config,md,description: Logseq knowledge base and TODO management for all agents,--- | description: Logseq knowledge base and TODO management for all agents | applyTo: '**' | ---
.github/instructions/logseq-knowledge-base.instructions.md,8,config,md,"**ALL agents working on TTA.dev MUST use the Logseq system for TODOs, documentation, and knowledge management.**","# Logseq Knowledge Base Instructions |  | **ALL agents working on TTA.dev MUST use the Logseq system for TODOs, documentation, and knowledge management.** |  | ## ðŸŽ¯ Core Requirements"
.github/instructions/logseq-knowledge-base.instructions.md,12,config,md,### 1. TODO Management,## ðŸŽ¯ Core Requirements |  | ### 1. TODO Management |  | **Location:** `logseq/journals/YYYY_MM_DD.md`
.github/instructions/logseq-knowledge-base.instructions.md,16,config,md,**When to Add TODOs:**,**Location:** `logseq/journals/YYYY_MM_DD.md` |  | **When to Add TODOs:** | - Creating new implementation work | - Identifying missing tests
.github/instructions/logseq-knowledge-base.instructions.md,27,config,md,- TODO Implement feature X #dev-todo,```markdown | # Development Work | - TODO Implement feature X #dev-todo |   type:: implementation |   priority:: high
.github/instructions/logseq-knowledge-base.instructions.md,34,config,md,- TODO Create flashcards for primitives #user-todo, | # User/Agent Learning | - TODO Create flashcards for primitives #user-todo |   type:: learning |   audience:: intermediate-users
.github/instructions/logseq-knowledge-base.instructions.md,44,config,md,1. **Start of Session:** Check today's journal for relevant TODOs,**When working on TTA.dev:** |  | 1. **Start of Session:** Check today's journal for relevant TODOs | 2. **During Work:** Add new TODOs as they arise | 3. **After Completing Task:** Mark as DONE
.github/instructions/logseq-knowledge-base.instructions.md,45,config,md,2. **During Work:** Add new TODOs as they arise, | 1. **Start of Session:** Check today's journal for relevant TODOs | 2. **During Work:** Add new TODOs as they arise | 3. **After Completing Task:** Mark as DONE | 4. **End of Session:** Update status of in-progress items
.github/instructions/logseq-knowledge-base.instructions.md,52,config,md,## [[2025-10-31]] Session Notes, | ```markdown | ## [[2025-10-31]] Session Notes |  | ### Work Completed
.github/instructions/logseq-knowledge-base.instructions.md,63,config,md,- TODO Deploy to staging #dev-todo, | ### Blocked | - TODO Deploy to staging #dev-todo |   blocked:: true |   blocker:: Waiting for infrastructure approval
.github/instructions/logseq-knowledge-base.instructions.md,67,config,md,### New TODOs,  blocker:: Waiting for infrastructure approval |  | ### New TODOs | - TODO Document new API endpoints #dev-todo |   type:: documentation
.github/instructions/logseq-knowledge-base.instructions.md,68,config,md,- TODO Document new API endpoints #dev-todo, | ### New TODOs | - TODO Document new API endpoints #dev-todo |   type:: documentation |   priority:: medium
.github/instructions/logseq-knowledge-base.instructions.md,75,config,md,#### Development TODOs (#dev-todo),### 3. Properties to Use |  | #### Development TODOs (#dev-todo) |  | **Required:**
.github/instructions/logseq-knowledge-base.instructions.md,92,config,md,#### User/Agent TODOs (#user-todo),"- `estimate::` - Time estimate (e.g., ""2 hours"") |  | #### User/Agent TODOs (#user-todo) |  | **Required:**"
.github/instructions/logseq-knowledge-base.instructions.md,109,config,md,- TODO Add caching examples #dev-todo, | ```markdown | - TODO Add caching examples #dev-todo |   related:: [[TTA Primitives/CachePrimitive]] |   related:: [[TTA.dev/Examples]]
.github/instructions/logseq-knowledge-base.instructions.md,120,config,md,### 5. Using TODO Queries,- Guides: `[[TTA.dev/Guides/TopicName]]` |  | ### 5. Using TODO Queries |  | **Check dashboards before starting work:**
.github/instructions/logseq-knowledge-base.instructions.md,125,config,md,# View your relevant TODOs, | ```markdown | # View your relevant TODOs | {{query (and (task TODO) [[#dev-todo]] (property priority high))}} | 
.github/instructions/logseq-knowledge-base.instructions.md,126,config,md,{{query (and (task TODO) [[#dev-todo]] (property priority high))}},```markdown | # View your relevant TODOs | {{query (and (task TODO) [[#dev-todo]] (property priority high))}} |  | # Check blocked items
.github/instructions/logseq-knowledge-base.instructions.md,129,config,md,{{query (and (task TODO) (property blocked true))}}, | # Check blocked items | {{query (and (task TODO) (property blocked true))}} |  | # See what's in progress
.github/instructions/logseq-knowledge-base.instructions.md,135,config,md,**See:** `logseq/pages/TODO Management System.md` for complete query reference.,``` |  | **See:** `logseq/pages/TODO Management System.md` for complete query reference. |  | ## ðŸ“š Documentation in Logseq
.github/instructions/logseq-knowledge-base.instructions.md,144,config,md,4. **Investigation Notes:** Document research and decisions,"2. **Feature Documentation:** Create `[[TTA Primitives/PrimitiveName]]` | 3. **Learning Materials:** Create guides, flashcards, whiteboards | 4. **Investigation Notes:** Document research and decisions |  | ### Page Naming Convention"
.github/instructions/logseq-knowledge-base.instructions.md,193,config,md,- TODO Implement CachePrimitive enhancements #dev-todo,1. **Plan in Journal:** |    ```markdown |    - TODO Implement CachePrimitive enhancements #dev-todo |      type:: implementation |      priority:: high
.github/instructions/logseq-knowledge-base.instructions.md,205,config,md,- Update TODO status to DOING, | 3. **During Implementation:** |    - Update TODO status to DOING |    - Add sub-tasks as needed |    - Document blockers
.github/instructions/logseq-knowledge-base.instructions.md,210,config,md,- Mark TODO as DONE, | 4. **After Completion:** |    - Mark TODO as DONE |    - Create user learning tasks if needed |    - Update architecture diagrams
.github/instructions/logseq-knowledge-base.instructions.md,218,config,md,- TODO Document RouterPrimitive usage patterns #dev-todo,1. **Identify Documentation Need:** |    ```markdown |    - TODO Document RouterPrimitive usage patterns #dev-todo |      type:: documentation |      priority:: medium
.github/instructions/logseq-knowledge-base.instructions.md,231,config,md,- TODO Create flashcards for router patterns #user-todo,3. **Add User Learning Path:** |    ```markdown |    - TODO Create flashcards for router patterns #user-todo |      type:: learning |      audience:: intermediate-users
.github/instructions/logseq-knowledge-base.instructions.md,237,config,md,### Bug Fix Workflow,   ``` |  | ### Bug Fix Workflow |  | 1. **Log the Bug:**
.github/instructions/logseq-knowledge-base.instructions.md,239,config,md,1. **Log the Bug:**,### Bug Fix Workflow |  | 1. **Log the Bug:** |    ```markdown |    - TODO Fix CachePrimitive TTL edge case #dev-todo
.github/instructions/logseq-knowledge-base.instructions.md,241,config,md,- TODO Fix CachePrimitive TTL edge case #dev-todo,1. **Log the Bug:** |    ```markdown |    - TODO Fix CachePrimitive TTL edge case #dev-todo |      type:: implementation |      priority:: high
.github/instructions/logseq-knowledge-base.instructions.md,255,config,md,- TODO Add test coverage for TTL edge cases #dev-todo,3. **Track Testing:** |    ```markdown |    - TODO Add test coverage for TTL edge cases #dev-todo |      type:: testing |      priority:: high
.github/instructions/logseq-knowledge-base.instructions.md,269,config,md,- TODO Create examples for NewPrimitive #user-todo,```markdown | # After implementing new primitive | - TODO Create examples for NewPrimitive #user-todo |   type:: documentation |   audience:: all-users
.github/instructions/logseq-knowledge-base.instructions.md,274,config,md,- TODO Create flashcards for NewPrimitive #user-todo,  related:: [[TTA Primitives/NewPrimitive]] |  | - TODO Create flashcards for NewPrimitive #user-todo |   type:: learning |   audience:: intermediate-users
.github/instructions/logseq-knowledge-base.instructions.md,279,config,md,- TODO Update architecture diagram #user-todo,  related:: [[Learning TTA Primitives]] |  | - TODO Update architecture diagram #user-todo |   type:: documentation |   audience:: advanced-users
.github/instructions/logseq-knowledge-base.instructions.md,289,config,md,- TODO Update PRIMITIVES_CATALOG.md #dev-todo, | ```markdown | - TODO Update PRIMITIVES_CATALOG.md #dev-todo |   type:: documentation |   related:: [[TTA Primitives]]
.github/instructions/logseq-knowledge-base.instructions.md,306,config,md,2. **High-priority TODOs:**,   ``` |  | 2. **High-priority TODOs:** |    ```markdown |    {{query (and (task TODO) (property priority high))}}
.github/instructions/logseq-knowledge-base.instructions.md,308,config,md,{{query (and (task TODO) (property priority high))}},2. **High-priority TODOs:** |    ```markdown |    {{query (and (task TODO) (property priority high))}} |    ``` | 
.github/instructions/logseq-knowledge-base.instructions.md,313,config,md,{{query (and (task TODO) (property blocked true))}},3. **Blocked items to document:** |    ```markdown |    {{query (and (task TODO) (property blocked true))}} |    ``` | 
.github/instructions/logseq-knowledge-base.instructions.md,325,config,md,**Use:** `logseq/pages/TODO Management System.md` dashboards.,4. New priorities for this week |  | **Use:** `logseq/pages/TODO Management System.md` dashboards. |  | ## ðŸš« Anti-Patterns
.github/instructions/logseq-knowledge-base.instructions.md,331,config,md,- Create TODOs in code comments without logging in Logseq,### âŒ DON'T |  | - Create TODOs in code comments without logging in Logseq | - Skip property assignment (especially `type::` and `priority::`) | - Forget to mark completed tasks as DONE
.github/instructions/logseq-knowledge-base.instructions.md,334,config,md,- Create TODOs without linking related pages,- Skip property assignment (especially `type::` and `priority::`) | - Forget to mark completed tasks as DONE | - Create TODOs without linking related pages | - Mix dev and user TODOs without proper tags | 
.github/instructions/logseq-knowledge-base.instructions.md,335,config,md,- Mix dev and user TODOs without proper tags,- Forget to mark completed tasks as DONE | - Create TODOs without linking related pages | - Mix dev and user TODOs without proper tags |  | ### âœ… DO
.github/instructions/logseq-knowledge-base.instructions.md,339,config,md,- Always add TODOs to today's journal,### âœ… DO |  | - Always add TODOs to today's journal | - Use proper tags (#dev-todo vs #user-todo) | - Set all required properties
.github/instructions/logseq-knowledge-base.instructions.md,340,config,md,- Use proper tags (#dev-todo vs #user-todo), | - Always add TODOs to today's journal | - Use proper tags (#dev-todo vs #user-todo) | - Set all required properties | - Link to related Logseq pages
.github/instructions/logseq-knowledge-base.instructions.md,351,config,md,- **System Overview:** `logseq/pages/TODO Management System.md`,### Documentation |  | - **System Overview:** `logseq/pages/TODO Management System.md` | - **Advanced Features:** `logseq/ADVANCED_FEATURES.md` | - **Quick Reference:** `logseq/QUICK_REFERENCE_FEATURES.md`
.github/instructions/logseq-knowledge-base.instructions.md,371,config,md,1. **Use Templates:** Copy TODO structure from existing items,### For Efficiency |  | 1. **Use Templates:** Copy TODO structure from existing items | 2. **Batch Updates:** Update multiple TODOs during daily review | 3. **Query Shortcuts:** Save frequent queries as page templates
.github/instructions/logseq-knowledge-base.instructions.md,372,config,md,2. **Batch Updates:** Update multiple TODOs during daily review, | 1. **Use Templates:** Copy TODO structure from existing items | 2. **Batch Updates:** Update multiple TODOs during daily review | 3. **Query Shortcuts:** Save frequent queries as page templates | 4. **Link Liberally:** Over-link rather than under-link
.github/instructions/logseq-knowledge-base.instructions.md,375,config,md,5. **Tag Consistently:** Always use #dev-todo or #user-todo,3. **Query Shortcuts:** Save frequent queries as page templates | 4. **Link Liberally:** Over-link rather than under-link | 5. **Tag Consistently:** Always use #dev-todo or #user-todo |  | ### For Quality
.github/instructions/logseq-knowledge-base.instructions.md,391,config,md,5. **Update Status:** Keep TODO status current for team visibility,3. **Link Issues:** Use `issue::` to connect GitHub and Logseq | 4. **Share Context:** Create detailed investigation pages | 5. **Update Status:** Keep TODO status current for team visibility |  | ---
.github/instructions/documentation.instructions.instructions.md,230,config,md,- Bug fix Z with brief description, | ### Fixed | - Bug fix Z with brief description |  | ## [0.2.0] - 2025-10-28
.github/instructions/tests.instructions.instructions.md,423,config,md,**Note**: tests-split.yml is newly created and not yet run in CI. May require refinement after first execution.,4. **coverage** (15 min): Coverage report with Codecov upload |  | **Note**: tests-split.yml is newly created and not yet run in CI. May require refinement after first execution. |  | ### Marking New Tests
.github/ISSUE_TEMPLATE/file-watcher-implementation.md,15,config,md,**Related TODOs:**,"**Status:** FileWatcherPrimitive structure is complete with watchdog library integration, but actual file watching workflow is on hold pending further implementation phases. |  | **Related TODOs:** | - âœ… Phase 1.1: Package structure complete (10/10 tests passing) | - âœ… Phase 1.2: FileWatcherPrimitive implemented"
.github/ISSUE_TEMPLATE/file-watcher-implementation.md,126,config,md,### Integration Tests (TODO),- âœ… All 10 tests passing |  | ### Integration Tests (TODO) | ```python | @pytest.mark.asyncio
.github/ISSUE_TEMPLATE/file-watcher-implementation.md,214,config,md,## ðŸ’¡ Notes,--- |  | ## ðŸ’¡ Notes |  | - FileWatcherPrimitive is fully implemented but not yet integrated into workflows
