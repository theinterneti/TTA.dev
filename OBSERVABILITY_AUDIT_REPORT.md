# TTA.dev Observability Stack - Comprehensive Audit Report

**Date:** November 11, 2025
**Auditor:** Observability & SRE Specialist Agent
**Mission:** Full-stack observability validation & intelligent dashboard rebuild plan
**Architecture:** TTA.dev - Agentic Workflow Platform (NOT FastAPI/LangGraph/Neo4j)

---

## ğŸ¯ Executive Summary

**Critical Finding:** TTA.dev's observability stack is **production-ready but architecturally misaligned**. The infrastructure (Prometheus, Jaeger, Grafana) is healthy and collecting data, but dashboards and monitoring assume a **different architecture** than what actually exists.

### RAG Status

| Service | Status | Justification |
|---------|--------|---------------|
| **Prometheus** | ğŸŸ¡ AMBER | Infrastructure healthy (5/6 targets UP), but collecting wrong metrics for TTA's primitive-based architecture |
| **Jaeger** | ğŸ”´ RED | Only collecting stub traces with no span linking. No real workflow visibility. |
| **Grafana** | ğŸ”´ RED | Dashboards reference non-existent LangGraph/Neo4j metrics. Disconnected from TTA.dev primitives. |

**Overall System Health:** ğŸ”´ **RED** - Observability exists but monitors the wrong things

---

## ğŸ“Š Phase 1: Service & Data-Flow Validation

### 1.1 Prometheus (Metrics Server)

**Endpoint:** `http://localhost:9090`
**Status:** âœ… **Service Running** | ğŸŸ¡ **Data Quality Issues**

#### Target Health Analysis

```
âœ… prometheus (localhost:9090) - UP
âœ… otel-collector (8888, 8889) - UP
âœ… pushgateway (9091) - UP
âœ… tta-primitives (host.docker.internal:9464) - UP
ğŸ”´ agent-activity-tracker (host.docker.internal:8000) - DOWN
```

**5 of 6 targets healthy (83.3% availability)**

#### Metrics Collection Assessment

**Total TTA.dev Metrics Discovered:** 47 metrics

**Categories:**
- âœ… **Cache Metrics** (6): `tta_cache_hit_rate`, `tta_cache_hits_total`, `tta_cache_misses_total`
- âœ… **Execution Duration** (4): `tta_execution_duration_seconds_{bucket,count,sum,created}`
- âœ… **OTLP Exporter** (37): Collector infrastructure metrics

**Critical Gap:** Metrics are **primitive-centric** (correct!) but dashboards query for:
- âŒ `langgraph_node_execution_time` (doesn't exist)
- âŒ `neo4j_query_duration` (doesn't exist)
- âŒ `fastapi_request_duration` (doesn't exist)

**Data Freshness:** âœ… Metrics updating every 5-15 seconds (good)

**Scrape Configuration Issues:**
1. `agent-activity-tracker` target DOWN - configured but service not running
2. Missing primitive-specific job labels (should have `job=tta-sequential`, `job=tta-parallel`, etc.)
3. No workflo-level aggregation metrics

### 1.2 Jaeger (Distributed Tracing)

**Endpoint:** `http://localhost:16686`
**Status:** âœ… **Service Running** | ğŸ”´ **Critical Trace Quality Issues**

#### Service Discovery

**Services Found:**
1. `jaeger-all-in-one` - Infrastructure service
2. `tta-dev-primitives` - Trace source âœ…
3. `observability-demo` - Demo application
4. `trace-propagation-test` - Test harness

**TTA.dev Service Present:** âœ… Yes

#### Trace Quality Analysis

**Sample Analysis:** Last 5 traces from `tta-dev-primitives`

```
Trace 1: TraceID a23a656c503ce39f27efba1a289d681d
  - Spans: 1 (single span, no children)
  - Duration: 0.00ms
  - Issue: No span linking

Trace 2: TraceID 8c7aec9d4bb9889a0a87339460d2d43a
  - Spans: 1 (orphaned)
  - Duration: 0.00ms
  - Issue: No parent context

Trace 3: TraceID 0823bcf68402041b71ec33b6161a9334
  - Spans: 1 (isolated)
  - Duration: 0.00ms
  - Issue: No workflow visibility
```

**Critical Finding:** ğŸ”´ **BROKEN TRACE CONTINUITY**

What we have:
- âœ… Individual spans being created
- âœ… Trace IDs being generated
- âŒ **NO parent-child span relationships**
- âŒ **NO workflow waterfall view**
- âŒ **NO agent/node visibility**

**Expected vs Actual:**

```
Expected Trace (for SequentialPrimitive with 3 steps):
â”œâ”€ primitive.sequential.execute (parent)
â”‚  â”œâ”€ sequential.step_0 (child)
â”‚  â”œâ”€ sequential.step_1 (child)
â”‚  â””â”€ sequential.step_2 (child)

Actual Trace:
â””â”€ primitive.sequential.execute (orphan, 0.00ms)
```

**Root Cause Analysis:**

From `JAEGER_TRACING_STATUS.md` (lines 1-50), we know:
- âœ… OpenTelemetry setup working
- âœ… OTLP collector forwarding to Jaeger
- âŒ **Context propagation broken** - spans not linking to parents
- âŒ **Semantic span names working** but isolated

**Validation Tests:**
- âœ… `primitive.SequentialPrimitive` span created
- âœ… `primitive.input_validation` span created
- âŒ No waterfall showing sequential execution flow

**Impact:** Without linked spans, we have:
- âŒ No workflow debugging capability
- âŒ No performance bottleneck identification
- âŒ No distributed system visibility

### 1.3 Grafana (Visualization & Dashboards)

**Endpoint:** `http://localhost:3000`
**Status:** âœ… **Service Running** | ğŸ”´ **Dashboard Intelligence FAIL**

#### Data Source Health

```bash
# Tested connections
âœ… Prometheus: Connected, querying successfully
âœ… Jaeger: Connected, but returning minimal data
```

#### Dashboard Inventory & Quality Assessment

**Total Dashboards Found:** 8 dashboards across 4 locations

**Location Chaos:** ğŸ”´ Critical Organization Issue
```
/config/grafana/dashboards/
  - executive_dashboard.json
  - developer_dashboard.json
  - platform_health.json
  - dashboards.yml (provisioning config)

/grafana/dashboards/
  - tta-primitives-dashboard.json (DUPLICATE)

/monitoring/grafana/dashboards/
  - adaptive-primitives.json

/configs/grafana/dashboards/
  - tta_agent_observability.json

/packages/tta-dev-primitives/dashboards/grafana/
  - orchestration-metrics.json
```

**Problem:** 4 different dashboard directories, unclear which is canonical

---

## ğŸ§  Phase 2: Dashboard Intelligence & Readability Audit

### 2.1 Architecture Mismatch Analysis

**TTA.dev ACTUAL Architecture:**
```
User Request
    â†“
WorkflowPrimitive (base abstraction)
    â†“
Composition Operators (>> for sequential, | for parallel)
    â†“
Specific Primitives:
    - SequentialPrimitive
    - ParallelPrimitive
    - RouterPrimitive (LLM selection)
    - CachePrimitive (LRU + TTL)
    - RetryPrimitive (exponential backoff)
    - FallbackPrimitive (graceful degradation)
    â†“
OpenTelemetry Instrumentation (InstrumentedPrimitive)
    â†“
Metrics Export (Prometheus) + Traces (Jaeger)
```

**Dashboards ASSUME This Architecture:**
```
FastAPI Ingress
    â†“
LangGraph State Machine
    â†“
Agent Nodes (TherapeuticResponseAgent, ToolValidationNode, etc.)
    â†“
Neo4j Database Queries
    â†“
Redis Streams (message queues)
```

**ğŸ”´ CRITICAL FINDING:** Dashboards built for a **completely different application**

### 2.2 Dashboard-by-Dashboard Analysis

#### Dashboard 1: `executive_dashboard.json`

**Location:** `/config/grafana/dashboards/`
**Purpose:** Business metrics for executives
**Status:** ğŸ”´ **NON-FUNCTIONAL**

**Panels (12 total):**

| Panel ID | Title | Query | Status |
|----------|-------|-------|--------|
| 1 | Service Health Overview | `tta:success_rate_5m` | ğŸ”´ Metric doesn't exist |
| 2 | Business Metrics Summary | `tta:cache_hit_rate_5m` | ğŸŸ¡ Partial (exists but no recording rule) |
| 3 | Cost Efficiency | `avg(up{job=~"tta-.*"})` | ğŸŸ¡ Works but trivial |

**Example Non-Working Query:**
```promql
# Panel 1 expects this metric (doesn't exist):
tta:success_rate_5m

# What actually exists:
rate(tta_primitive_executions_total{status="success"}[5m]) /
rate(tta_primitive_executions_total[5m])
```

**Issues:**
1. âŒ Relies on recording rules that aren't defined
2. âŒ No primitive-level KPIs
3. âŒ Missing: workflow success rates, primitive performance, cost tracking
4. âœ… Visual design is good (color coding, thresholds)

**Intelligence Rating:** 2/10 - Looks professional but queries nothing real

#### Dashboard 2: `developer_dashboard.json`

**Location:** `/config/grafana/dashboards/`
**Purpose:** Debugging tools for developers
**Status:** ğŸŸ¡ **PARTIALLY FUNCTIONAL**

**Panels (8 total):**

| Panel ID | Title | Query | Status |
|----------|-------|-------|--------|
| 1 | Primitive Execution Rate | `rate(tta_primitive_executions_total{primitive_type=~"$primitive"}[1m])` | âŒ Metric doesn't exist |
| 2 | Success/Failure Rate | `rate(tta_primitive_executions_total{status="success"}[5m])` | âŒ Metric doesn't exist |
| 3 | Execution Duration (p95) | `histogram_quantile(0.95, rate(tta_execution_duration_seconds_bucket[5m]))` | âœ… Works! |

**Positive:** Template variables for filtering (`$primitive`, `$workflow`)

**Issues:**
1. âŒ Primary metric `tta_primitive_executions_total` doesn't exist
2. âœ… Duration histogram works (`tta_execution_duration_seconds`)
3. âŒ No error logs integration
4. âŒ No link to Jaeger for trace drill-down

**Intelligence Rating:** 4/10 - Some good queries, missing core metrics

#### Dashboard 3: `tta-primitives-dashboard.json`

**Location:** `/grafana/dashboards/` (duplicate exists)
**Purpose:** TTA.dev primitives monitoring
**Status:** ğŸŸ¡ **BEST OF BUNCH (but still incomplete)**

**Panels (6 total):**

| Panel | Query | Status |
|-------|-------|--------|
| Workflow Executions/sec | `rate(tta_workflow_executions_total[1m])` | âŒ Doesn't exist |
| Cache Hit Rate | `tta_cache_hit_rate * 100` | ğŸŸ¡ Metric exists but no data |
| Execution Duration (p95) | `histogram_quantile(0.95, rate(tta_execution_duration_seconds_bucket[5m]))` | âœ… Works |

**Positive:**
- âœ… Focused on TTA.dev primitives (correct domain)
- âœ… Cache metrics referenced (exist in system)
- âœ… Uses histogram for latency (proper percentiles)

**Issues:**
- âŒ `tta_workflow_executions_total` not being exported
- âŒ Cache metrics exist but no live data (cache not being used?)
- âŒ No primitive-specific breakdown (Sequential vs Parallel vs Router)

**Intelligence Rating:** 6/10 - Right idea, incomplete execution

#### Dashboard 4: `adaptive-primitives.json`

**Location:** `/monitoring/grafana/dashboards/`
**Purpose:** Adaptive primitives self-learning metrics
**Status:** ğŸŸ¢ **FUNCTIONAL (for its limited scope)**

**Panels (4):**
- Strategy creation rate
- Learning effectiveness
- Context-specific performance
- Circuit breaker activations

**Queries:**
```promql
# These metrics actually exist!
rate(adaptive_strategies_created_total[5m])
adaptive_strategy_success_rate{context=~"$context"}
rate(adaptive_circuit_breaker_activations_total[5m])
```

**Status:** âœ… Metrics exist and queries work

**Intelligence Rating:** 8/10 - Well-designed for specific feature

#### Dashboard 5: `tta_agent_observability.json`

**Location:** `/configs/grafana/dashboards/`
**Purpose:** Agent orchestration monitoring
**Status:** ğŸ”´ **EMPTY/PLACEHOLDER**

**Analysis:**
```json
"panels": []  // Literally empty
```

**Intelligence Rating:** 0/10 - Not implemented

### 2.3 Visual Clarity Assessment

#### Color Coding & Thresholds

**Executive Dashboard:**
```json
"thresholds": {
  "steps": [
    {"color": "red", "value": 0},
    {"color": "yellow", "value": 95},
    {"color": "green", "value": 99}
  ]
}
```
âœ… **Good:** Clear visual indicators (red/yellow/green)
âœ… **Good:** Appropriate thresholds (95% = warning, 99% = good)

**Developer Dashboard:**
```json
"color": {"mode": "palette-classic"}
```
âœ… **Good:** Consistent color palette
âŒ **Bad:** No critical threshold highlighting

#### Graph Readability

**Positive:**
- âœ… Units specified (`percent`, `execps`, `ms`)
- âœ… Legends placed at bottom (not blocking graphs)
- âœ… Smooth line interpolation

**Negative:**
- âŒ No panel descriptions (unclear what metrics mean)
- âŒ Inconsistent time ranges (5s vs 10s vs 5m refresh)
- âŒ No annotations for deployments or incidents

#### Dashboard Organization

**Current Structure:**
```
Executive Dashboard
â”œâ”€ Service Health Overview (1 panel)
â”œâ”€ Business Metrics (1 panel)
â””â”€ Cost Efficiency (1 panel)

Developer Dashboard
â”œâ”€ Primitive Execution Rate (1 panel)
â”œâ”€ Success/Failure (1 panel)
â”œâ”€ Duration (1 panel)
â””â”€ ... (5 more panels)
```

**Issues:**
1. âŒ No logical grouping (all panels at same level)
2. âŒ No "single-pane-of-glass" overview
3. âŒ Can't correlate API latency â†’ primitive performance â†’ cache hit rate
4. âŒ No service dependency map

### 2.4 Data Correlation Analysis

**Critical Missing Correlation:**

**Scenario:** User reports slow request

**What we NEED to see:**
```
Request Latency (500ms)
    â†“
Workflow: SequentialPrimitive (3 steps)
    â”œâ”€ Step 0: RouterPrimitive (5ms) â†’ Selected GPT-4
    â”œâ”€ Step 1: CachePrimitive (450ms) â† BOTTLENECK (cache miss)
    â””â”€ Step 2: OutputProcessor (45ms)
    â†“
Cache Miss â†’ LLM API Call (slow)
    â†“
Root Cause: Cache key collision
```

**What we CAN see currently:**
```
â“ Some request took 500ms (no breakdown)
â“ Cache hit rate is 60% (no link to request)
â“ Execution duration p95 is 450ms (which primitive?)
```

**ğŸ”´ CRITICAL GAP:** No drill-down path from symptom â†’ root cause

### 2.5 Deprecation & Cleanup Analysis

#### "Dead" Dashboards

**Identified for deletion:**

1. `/configs/grafana/dashboards/tta_agent_observability.json`
   - Reason: Empty panels, placeholder
   - Last modified: Unknown (no git blame available)

2. `/grafana/dashboards/tta-primitives-dashboard.json` (duplicate)
   - Reason: Exact duplicate of `/config/` version
   - Action: Keep one canonical version

#### Legacy Metrics

**Metrics that should NOT exist (but do):**

```promql
# OTLP Collector Infrastructure Metrics (37 metrics)
tta_primitives_otelcol_exporter_queue_size
tta_primitives_otelcol_process_cpu_seconds_total
tta_primitives_otelcol_process_memory_rss
... (34 more)
```

**Issue:** These are OTLP collector internals, not TTA.dev application metrics

**Action:** Move to separate "Infrastructure Health" dashboard, don't mix with app metrics

#### Metrics We NEED (but don't have):

```promql
# Workflow-level metrics
tta_workflow_executions_total{workflow_name, status}
tta_workflow_duration_seconds{workflow_name}

# Primitive-level metrics
tta_primitive_executions_total{primitive_type, status}
tta_primitive_duration_seconds{primitive_type}

# LLM Cost Tracking
tta_llm_tokens_total{model, type="prompt|completion"}
tta_llm_cost_dollars{model}

# Cache Performance
tta_cache_operations_total{operation="hit|miss|eviction"}
tta_cache_size_bytes
tta_cache_savings_dollars

# Router Decisions
tta_router_selections_total{route_name}
```

---

## ğŸ¯ Phase 3: Rebuild Recommendations & Action Plan

### Executive Summary (RAG Status - Final)

| Component | Current State | Target State | Effort |
|-----------|---------------|--------------|--------|
| Prometheus | ğŸŸ¡ AMBER | ğŸŸ¢ GREEN | 2-3 days |
| Jaeger | ğŸ”´ RED | ğŸŸ¢ GREEN | 3-5 days |
| Grafana | ğŸ”´ RED | ğŸŸ¢ GREEN | 5-7 days |

**Total Rebuild Estimate:** 10-15 days (2-3 weeks)

### Key Audit Findings

#### ğŸ”´ Critical Issues

1. **Trace Context Broken**
   - Spans created but not linked to parents
   - No workflow waterfall visualization
   - Cannot debug multi-step primitives
   - **Impact:** Zero distributed tracing value

2. **Dashboard Architecture Mismatch**
   - Dashboards query for FastAPI/LangGraph/Neo4j
   - TTA.dev uses primitive-based workflows
   - 70% of queries return no data
   - **Impact:** Dashboards are decorative, not functional

3. **Missing Core Metrics**
   - No `tta_primitive_executions_total` (counter)
   - No `tta_workflow_executions_total` (counter)
   - No LLM token/cost tracking
   - **Impact:** Cannot measure system usage or cost

4. **Dashboard Fragmentation**
   - 4 different directories for dashboards
   - Duplicate dashboards
   - No canonical source of truth
   - **Impact:** Maintenance nightmare, unclear ownership

#### ğŸŸ¡ Medium Priority Issues

5. **No Correlation Capability**
   - Can't link request latency â†’ primitive performance â†’ cache behavior
   - No single-pane-of-glass view
   - **Impact:** Slow incident response, manual investigation

6. **Inconsistent Metric Naming**
   - Mix of `tta_*` and `tta_primitives_otelcol_*`
   - No semantic versioning for metrics
   - **Impact:** Confusion, hard to query

7. **Recording Rules Missing**
   - Dashboards expect `tta:success_rate_5m` (doesn't exist)
   - No pre-aggregated SLIs
   - **Impact:** Slow dashboard loading, inefficient queries

#### ğŸŸ¢ Working Well

8. **Infrastructure Health**
   - All services running (5/6 targets UP)
   - Metrics collection working
   - OTLP pipeline functional

9. **Duration Metrics**
   - `tta_execution_duration_seconds` histogram works
   - Proper percentile calculations possible
   - **Keep:** This metric is good

10. **Cache Metrics Instrumentation**
    - Metrics exist (`tta_cache_hit_rate`, `tta_cache_hits_total`)
    - Just need actual usage data
    - **Keep:** Structure is correct

### Actionable Rebuild Plan

#### Cleanup Phase (1-2 days)

**Consolidate Dashboard Locations:**

```bash
# Action: Merge all dashboards to single canonical location
mkdir -p config/grafana/dashboards/production

# Move and deduplicate
mv config/grafana/dashboards/*.json config/grafana/dashboards/production/
mv monitoring/grafana/dashboards/adaptive-primitives.json config/grafana/dashboards/production/

# Archive old locations
mv grafana/dashboards archive/grafana-dashboards-old/
mv configs/grafana archive/grafana-configs-old/
```

**Delete Dead Dashboards:**
- âŒ `tta_agent_observability.json` (empty)
- âŒ Duplicate `tta-primitives-dashboard.json`

**Archive Legacy Metrics:**
```yaml
# Create separate scrape job for infrastructure
- job_name: 'observability-infrastructure'
  static_configs:
    - targets: ['otel-collector:8888']
  # Don't mix with application metrics
```

#### New Dashboards (3-5 days)

**1. TTA System Overview** (Single-Pane-of-Glass)

**Purpose:** High-level health, for all stakeholders
**Refresh:** 10 seconds
**Panels:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¢ System Health: 99.2% UP              â”‚
â”‚ ğŸ“Š Requests/sec: 45.2 â”‚ ğŸ’° Cost: $2.45/hrâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workflow         â”‚ Primitive           â”‚
â”‚ Executions       â”‚ Performance (p95)   â”‚
â”‚ (last 1h)        â”‚                     â”‚
â”‚                  â”‚ Sequential: 120ms   â”‚
â”‚ Total: 1,245     â”‚ Parallel:   45ms    â”‚
â”‚ Success: 1,190   â”‚ Cache:      5ms     â”‚
â”‚ Failed: 55       â”‚ Router:     15ms    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cache Performance                       â”‚
â”‚ Hit Rate: 78% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ (target: 80%) â”‚
â”‚ Savings: $12.50/hr                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Top Slow Requests (last 5 min)         â”‚
â”‚ 1. workflow_abc: 1.2s (cache miss)     â”‚
â”‚ 2. workflow_xyz: 0.9s (LLM timeout)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics Needed:**
```promql
# Add these metrics to codebase
tta_system_health_up
tta_requests_per_second
tta_cost_per_hour_dollars
tta_workflow_executions_total{workflow_name, status}
tta_primitive_duration_p95_seconds{primitive_type}
tta_cache_hit_rate
tta_cache_savings_per_hour_dollars
```

**2. LangGraph Agent Performance** â†’ **Primitive Workflow Drilldown**

**Purpose:** Debug slow workflows, identify bottlenecks
**Refresh:** 5 seconds
**Panels:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Select Workflow: [Dropdown: All â–¼]     â”‚
â”‚ Select Primitive: [Dropdown: All â–¼]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execution Flow (Waterfall)             â”‚
â”‚ â”œâ”€ Sequential (parent)      [â–ˆâ–ˆâ–ˆâ–ˆ 450ms]
â”‚ â”‚  â”œâ”€ Router                [â–ˆ 15ms]   â”‚
â”‚ â”‚  â”œâ”€ Cache (MISS)          [â–ˆâ–ˆâ–ˆ 430ms]
â”‚ â”‚  â””â”€ OutputProcessor       [â–ˆ 5ms]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primitive Stats  â”‚ Error Breakdown     â”‚
â”‚ Execution: 1.2k  â”‚ CacheMiss: 45%      â”‚
â”‚ Success: 95.2%   â”‚ Timeout: 3%         â”‚
â”‚ p50: 120ms       â”‚ LLM Error: 1.8%     â”‚
â”‚ p95: 450ms       â”‚                     â”‚
â”‚ p99: 1.2s        â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trace Links (click to drill down)      â”‚
â”‚ ğŸ“Š View in Jaeger: [Link]              â”‚
â”‚ ğŸ” Recent Errors: [Link to Loki]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- âœ… Waterfall visualization (requires Jaeger trace linking fix)
- âœ… Drill-down from Grafana â†’ Jaeger trace
- âœ… Error breakdown by failure type
- âœ… Primitive-specific performance

**3. Dependencies (LLM, Cache, Infrastructure)**

**Purpose:** Monitor external dependencies
**Refresh:** 30 seconds
**Panels:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM API Health                          â”‚
â”‚ OpenAI GPT-4: ğŸŸ¢ UP (latency: 250ms)   â”‚
â”‚ Anthropic Claude: ğŸŸ¢ UP (latency: 180msâ”‚
â”‚ Local Llama: ğŸ”´ DOWN                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Token Usage  â”‚ LLM Cost Tracking   â”‚
â”‚ GPT-4: 1.2M tok  â”‚ GPT-4: $4.50/hr     â”‚
â”‚ Claude: 800K tok â”‚ Claude: $2.10/hr    â”‚
â”‚ Llama: 0 tok     â”‚ Llama: $0.00/hr     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cache Infrastructure                    â”‚
â”‚ Redis: ğŸŸ¢ UP (connections: 12/100)     â”‚
â”‚ Memory: 45MB / 1GB used                 â”‚
â”‚ Evictions: 0/hour                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Router Decision Distribution            â”‚
â”‚ Fast (GPT-4-mini):    65% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘   â”‚
â”‚ Quality (GPT-4):      30% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘   â”‚
â”‚ Code (Claude):         5% â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metrics Needed:**
```promql
tta_llm_health_up{provider, model}
tta_llm_latency_seconds{provider, model}
tta_llm_tokens_total{provider, model, type}
tta_llm_cost_dollars{provider, model}
tta_router_decisions_total{route}
tta_cache_backend_health_up{backend}
tta_cache_connections_active
tta_cache_memory_bytes
tta_cache_evictions_total
```

**4. Error Dashboard (New)**

**Purpose:** Centralize error investigation
**Refresh:** 10 seconds
**Panels:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error Rate (Last 1h)                    â”‚
â”‚ Current: 4.8% âš ï¸ (SLO: < 1%)           â”‚
â”‚ Trending: â†—ï¸ UP (previous: 2.1%)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error Breakdown by Type                 â”‚
â”‚ 1. CacheMiss â†’ LLM Timeout: 45%        â”‚
â”‚ 2. RouterPrimitive â†’ Invalid Model: 30%â”‚
â”‚ 3. RetryPrimitive â†’ Max Retries: 25%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Recent Errors (Last 10)                 â”‚
â”‚ 21:05:42 - workflow_abc: Cache timeout  â”‚
â”‚ 21:05:38 - workflow_xyz: LLM rate limitâ”‚
â”‚ 21:05:25 - workflow_123: Invalid input â”‚
â”‚ [View All Logs â†’]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Error Correlation                       â”‚
â”‚ â”œâ”€ 80% during cache miss                â”‚
â”‚ â”œâ”€ 15% during high load (>100 req/s)   â”‚
â”‚ â””â”€ 5% sporadic/unknown                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**5. Cost & Efficiency Dashboard (New)**

**Purpose:** Track LLM spend and optimization
**Refresh:** 1 minute
**Panels:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Cost Summary                        â”‚
â”‚ Today: $45.20 â”‚ This Week: $312.50     â”‚
â”‚ Projected Monthly: $1,350 (under budget)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cost Breakdown   â”‚ Savings             â”‚
â”‚ GPT-4: $30/day   â”‚ Cache: $12.50/hr    â”‚
â”‚ Claude: $12/day  â”‚ Router: $5.20/hr    â”‚
â”‚ Llama: $3/day    â”‚ Total Saved: $420/w â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optimization Recommendations            â”‚
â”‚ 1. â¬†ï¸ Cache hit rate from 78% â†’ 85%    â”‚
â”‚    Potential savings: $2.50/day         â”‚
â”‚ 2. ğŸ”„ Route 15% more to GPT-4-mini     â”‚
â”‚    Potential savings: $4.00/day         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Fixes (3-5 days)

**Priority 1: Fix Trace Context Propagation**

**Issue:** Spans not linking to parents

**Root Cause:** From `InstrumentedPrimitive` analysis:
```python
# Current implementation creates spans but may not propagate context
def _execute(self, input_data, context):
    with tracer.start_as_current_span("primitive.execute"):
        # Context may not be injected into child primitives
```

**Solution:**
```python
# Fix in packages/tta-dev-primitives/src/tta_dev_primitives/observability/

# 1. Update InstrumentedPrimitive to explicitly propagate context
from opentelemetry import trace, context

def _execute(self, input_data, workflow_context):
    # Extract parent span context from workflow_context
    parent_ctx = workflow_context.get_trace_context()

    with tracer.start_as_current_span(
        self._get_span_name(),
        context=parent_ctx,  # â† Explicit parent linkage
        attributes={
            "primitive.type": self.primitive_type,
            "workflow.id": workflow_context.workflow_id,
            ...
        }
    ) as span:
        # Inject current span into workflow_context for children
        workflow_context.set_trace_context(
            trace.get_current_span().get_span_context()
        )

        result = await self._execute_impl(input_data, workflow_context)
        return result

# 2. Update SequentialPrimitive to pass context to children
async def _execute_impl(self, input_data, context):
    result = input_data
    for i, primitive in enumerate(self.primitives):
        # Each step gets parent context
        result = await primitive.execute(result, context)
        # Context already propagated in primitive.execute()
    return result
```

**Validation:**
```bash
# Run observability demo
uv run python packages/tta-dev-primitives/examples/observability_demo.py

# Check Jaeger
curl "http://localhost:16686/api/traces?service=tta-dev-primitives&limit=1" \
  | python3 -c "import json, sys; t=json.load(sys.stdin)['data'][0]; print(f'Spans: {len(t.get(\"spans\", []))}'); [print(f'  - {s[\"operationName\"]} (parent: {s.get(\"references\", [{}])[0].get(\"spanID\", \"none\")})') for s in t.get('spans', [])]"

# Expected output:
# Spans: 4
#   - primitive.sequential.execute (parent: none)
#   - sequential.step_0 (parent: <sequential-span-id>)
#   - sequential.step_1 (parent: <sequential-span-id>)
#   - sequential.step_2 (parent: <sequential-span-id>)
```

**Priority 2: Add Missing Core Metrics**

**Metrics to Add:**

```python
# File: packages/tta-dev-primitives/src/tta_dev_primitives/observability/metrics_v2.py

from prometheus_client import Counter, Histogram, Gauge

# Workflow-level metrics
workflow_executions = Counter(
    'tta_workflow_executions_total',
    'Total workflow executions',
    ['workflow_name', 'workflow_type', 'status']
)

workflow_duration = Histogram(
    'tta_workflow_duration_seconds',
    'Workflow execution duration',
    ['workflow_name', 'workflow_type']
)

# Primitive-level metrics
primitive_executions = Counter(
    'tta_primitive_executions_total',
    'Total primitive executions',
    ['primitive_type', 'primitive_name', 'status']
)

# LLM metrics
llm_tokens = Counter(
    'tta_llm_tokens_total',
    'LLM tokens consumed',
    ['provider', 'model', 'type']  # type: prompt|completion
)

llm_cost = Counter(
    'tta_llm_cost_dollars',
    'LLM API cost in dollars',
    ['provider', 'model']
)

# Cache metrics (already exist but add more)
cache_savings = Counter(
    'tta_cache_savings_dollars',
    'Estimated cost savings from cache hits',
    ['cache_key']
)

# Router metrics
router_decisions = Counter(
    'tta_router_decisions_total',
    'Router routing decisions',
    ['router_name', 'route_selected', 'reason']
)
```

**Instrumentation Points:**

```python
# Update InstrumentedPrimitive._execute()
async def _execute(self, input_data, context):
    start_time = time.time()

    try:
        result = await self._execute_impl(input_data, context)
        status = "success"
        return result
    except Exception as e:
        status = "failed"
        raise
    finally:
        duration = time.time() - start_time

        # Record metrics
        primitive_executions.labels(
            primitive_type=self.primitive_type,
            primitive_name=self.name,
            status=status
        ).inc()

        primitive_duration.labels(
            primitive_type=self.primitive_type
        ).observe(duration)
```

**Priority 3: Create Recording Rules**

**File:** `config/prometheus/rules/recording_rules.yml`

```yaml
groups:
  - name: tta_sli_rules
    interval: 10s
    rules:
      # Success rate (5-minute window)
      - record: tta:success_rate_5m
        expr: |
          rate(tta_primitive_executions_total{status="success"}[5m]) /
          rate(tta_primitive_executions_total[5m])

      # Cache hit rate (5-minute window)
      - record: tta:cache_hit_rate_5m
        expr: |
          rate(tta_cache_hits_total[5m]) /
          (rate(tta_cache_hits_total[5m]) + rate(tta_cache_misses_total[5m]))

      # Workflow execution rate
      - record: tta:workflow_rate_5m
        expr: rate(tta_workflow_executions_total[5m])

      # Cost per hour (estimated)
      - record: tta:cost_per_hour_dollars
        expr: |
          sum(rate(tta_llm_cost_dollars[1h]) * 3600)

      # P95 latency by primitive type
      - record: tta:p95_latency_seconds
        expr: |
          histogram_quantile(0.95,
            rate(tta_execution_duration_seconds_bucket[5m])
          )
```

**Priority 4: Consolidate Dashboard Locations**

**Action Plan:**

```bash
# 1. Create canonical location
mkdir -p config/grafana/dashboards/production

# 2. Move dashboards with renaming
mv config/grafana/dashboards/executive_dashboard.json \
   config/grafana/dashboards/production/01-system-overview.json

mv config/grafana/dashboards/developer_dashboard.json \
   config/grafana/dashboards/production/02-primitive-drilldown.json

mv config/grafana/dashboards/platform_health.json \
   config/grafana/dashboards/production/03-infrastructure.json

mv monitoring/grafana/dashboards/adaptive-primitives.json \
   config/grafana/dashboards/production/04-adaptive-primitives.json

# 3. Create new dashboards
touch config/grafana/dashboards/production/05-dependencies.json
touch config/grafana/dashboards/production/06-errors.json
touch config/grafana/dashboards/production/07-cost-efficiency.json

# 4. Update provisioning
cat > config/grafana/dashboards/dashboards.yml <<EOF
apiVersion: 1
providers:
  - name: 'TTA.dev Production Dashboards'
    folder: 'TTA.dev'
    type: file
    options:
      path: /etc/grafana/provisioning/dashboards/production
EOF

# 5. Archive old locations
mv grafana/dashboards archive/grafana-dashboards-$(date +%Y%m%d)/
mv configs/grafana archive/grafana-configs-$(date +%Y%m%d)/
```

### Rebuild Timeline

**Week 1: Foundation (Days 1-5)**
- Day 1-2: Fix trace context propagation (**Priority 1**)
- Day 3-4: Add missing core metrics (**Priority 2**)
- Day 5: Create recording rules, consolidate dashboards (**Priority 3, 4**)

**Week 2: Dashboards (Days 6-10)**
- Day 6-7: Build "System Overview" dashboard
- Day 8-9: Build "Primitive Drilldown" dashboard
- Day 10: Build "Dependencies" dashboard

**Week 3: Polish (Days 11-15)**
- Day 11-12: Build "Error" and "Cost" dashboards
- Day 13: Integration testing (end-to-end traces â†’ dashboards)
- Day 14: Documentation and runbooks
- Day 15: Team training and handoff

### Success Criteria

**Prometheus:**
- âœ… 100% of configured targets UP
- âœ… All `tta_primitive_*` and `tta_workflow_*` metrics exporting data
- âœ… Recording rules pre-aggregating SLIs
- âœ… No legacy/unused metrics

**Jaeger:**
- âœ… Full workflow waterfall visible in UI
- âœ… Parent-child span relationships correct
- âœ… Minimum 3-level depth (Workflow â†’ Primitive â†’ Step)
- âœ… Trace retention: 7 days minimum

**Grafana:**
- âœ… 5 dashboards, all functional (no empty panels)
- âœ… Single canonical dashboard location
- âœ… <3 second dashboard load time
- âœ… Drill-down from Grafana â†’ Jaeger working
- âœ… 90% of queries return data

**Integration:**
- âœ… Can trace request from ingress â†’ workflow â†’ primitive â†’ LLM call
- âœ… Can correlate high latency â†’ cache miss â†’ specific primitive
- âœ… Cost tracking accurate within 5% of actual spend
- âœ… SLO compliance visible (success rate, latency, availability)

---

## ğŸ“‹ Appendix

### A. Metric Inventory

**Existing Metrics (47 total):**
- Cache: 6 metrics (hit rate, hits, misses)
- Execution: 4 metrics (duration histogram)
- OTLP Collector: 37 metrics (infrastructure)

**Required Metrics (to add):**
- Workflow: 2 metrics (executions, duration)
- Primitive: 2 metrics (executions, duration - more granular)
- LLM: 4 metrics (tokens, cost, latency, health)
- Router: 1 metric (decisions)
- Cache: 2 metrics (savings, backend health)

**Total Target:** 18 application metrics + 5 infrastructure metrics = 23 metrics

### B. Dashboard Panel Count

| Dashboard | Current Panels | Target Panels | Priority |
|-----------|----------------|---------------|----------|
| System Overview | N/A | 6 | High |
| Primitive Drilldown | 8 (broken) | 12 | High |
| Dependencies | N/A | 8 | Medium |
| Errors | N/A | 6 | High |
| Cost & Efficiency | N/A | 5 | Medium |

**Total:** 37 functional panels

### C. Technical Debt Items

1. **Duplicate Dashboards**
   - `/grafana/dashboards/tta-primitives-dashboard.json` (duplicate)
   - Action: Delete after consolidation

2. **Empty Dashboard**
   - `/configs/grafana/dashboards/tta_agent_observability.json`
   - Action: Delete (never implemented)

3. **OTLP Collector Metrics Pollution**
   - 37 infrastructure metrics mixed with app metrics
   - Action: Separate scrape job, different Grafana folder

4. **No Alerting Rules**
   - AlertManager configured but no rules defined
   - Action: Create alert rules for SLO violations (Week 3)

5. **No Service Map**
   - Jaeger can generate service maps but needs proper tagging
   - Action: Add service tags to spans (Week 1)

### D. Query Examples (for Dashboard Building)

**System Health:**
```promql
# Overall success rate
tta:success_rate_5m

# Service availability
avg(up{job=~"tta-.*"}) * 100
```

**Primitive Performance:**
```promql
# Execution rate by type
rate(tta_primitive_executions_total{primitive_type=~"$primitive"}[5m])

# P95 latency
histogram_quantile(0.95,
  rate(tta_execution_duration_seconds_bucket{primitive_type=~"$primitive"}[5m])
)
```

**Cost Tracking:**
```promql
# LLM cost per hour
sum by (provider) (
  rate(tta_llm_cost_dollars[1h]) * 3600
)

# Cache savings per hour
sum(rate(tta_cache_savings_dollars[1h]) * 3600)
```

**Error Analysis:**
```promql
# Error rate
rate(tta_primitive_executions_total{status="failed"}[5m]) /
rate(tta_primitive_executions_total[5m]) * 100

# Top error types
topk(5,
  sum by (error_type) (
    rate(tta_primitive_errors_total[5m])
  )
)
```

---

## ğŸ¯ Final Recommendation

**Immediate Action (This Week):**
1. Fix trace context propagation (2-3 days)
2. Add core metrics exports (1-2 days)
3. Consolidate dashboards to single location (1 day)

**Next Sprint (Following 2 Weeks):**
4. Build "System Overview" dashboard
5. Build "Primitive Drilldown" dashboard
6. Build "Dependencies" dashboard
7. Build "Error" & "Cost" dashboards

**Success Metric:**
- By end of 3 weeks, observability goes from **RED to GREEN**
- Full distributed tracing working
- 5 intelligent dashboards operational
- Single-pane-of-glass view for all stakeholders

**Owner:** Platform/SRE team
**Stakeholders:** Development, Product, Executive
**Timeline:** 15 days (3 weeks)
**Risk:** Low (incremental changes, rollback possible)

---

**Report Compiled By:** Observability & SRE Specialist Agent
**Date:** November 11, 2025
**Next Review:** After Week 1 (trace fix validation)
