# Feedback Collection Template

**Document Version**: 1.0.0  
**Last Updated**: 2025-10-29

---

## Overview

This document provides templates and guidelines for collecting feedback from pilot program volunteers. Use these templates to maintain consistency and gather actionable insights.

---

## Weekly Quick Poll (5 minutes)

**Frequency**: Every Monday  
**Channel**: Slack/Discord or Email  
**Purpose**: Track satisfaction trends and identify urgent issues

### Template

```markdown
## üìä Week [N] Quick Poll

Hi [Name]! Quick check-in on your experience this week.

### 1. Satisfaction (1-5)
How satisfied were you with the AI Context Optimizer this week?
1 = Very Dissatisfied | 5 = Very Satisfied

Your rating: [ ]

### 2. Most Helpful Feature
What was the most helpful feature or aspect this week?

[ Text response ]

### 3. Biggest Challenge
What was your biggest challenge or frustration?

[ Text response ]

### 4. Token Awareness (optional)
Did you notice the token reduction this week?
[ ] Yes, definitely
[ ] Somewhat
[ ] Not really
[ ] Unsure

### 5. Quick Thoughts
Any other quick thoughts? (optional)

[ Text response ]

---

Thanks! Your feedback helps us improve. üôè
```

---

## Mid-Pilot Survey (15 minutes)

**Timing**: End of Week 2  
**Purpose**: Detailed feedback on experience so far

### Template

```markdown
## üîç Mid-Pilot Survey - Week 2

Thank you for your participation! This survey helps us understand your 
experience so far and make improvements for the rest of the pilot.

### Section 1: Usage & Experience

**1.1 How frequently did you use the AI Context Optimizer?**
[ ] Multiple times daily (10+ interactions)
[ ] Daily (5-10 interactions)
[ ] Most days (3-4 days/week)
[ ] Occasionally (1-2 days/week)
[ ] Rarely (<1 day/week)

**1.2 Which features have you used?** (Select all that apply)
[ ] Context pruning
[ ] Smart caching
[ ] Template suggestions
[ ] Auto-compression
[ ] Custom rules
[ ] Other: __________

**1.3 Overall satisfaction (1-5)**
1 = Very Dissatisfied | 5 = Very Satisfied
Rating: [ ]

---

### Section 2: Impact Assessment

**2.1 Perceived productivity change**
Compared to before the pilot, I feel:
[ ] Much more productive (+2)
[ ] Somewhat more productive (+1)
[ ] About the same (0)
[ ] Somewhat less productive (-1)
[ ] Much less productive (-2)

**2.2 Have you noticed token reduction?**
[ ] Yes, significant reduction (>30%)
[ ] Yes, moderate reduction (20-30%)
[ ] Yes, some reduction (10-20%)
[ ] Minimal or no reduction (<10%)
[ ] Unsure

**2.3 Impact on code quality**
Since starting the pilot, my code quality has:
[ ] Improved significantly
[ ] Improved somewhat
[ ] Stayed the same
[ ] Declined somewhat
[ ] Declined significantly

---

### Section 3: Features & Usability

**3.1 Most valuable features** (Rank top 3)
___ Context pruning
___ Smart caching
___ Template suggestions
___ Auto-compression
___ Custom rules

**3.2 Least valuable features** (Rank top 3)
___ Context pruning
___ Smart caching
___ Template suggestions
___ Auto-compression
___ Custom rules

**3.3 Ease of use (1-5)**
1 = Very Difficult | 5 = Very Easy
Rating: [ ]

**3.4 Learning curve (1-5)**
1 = Very Steep | 5 = Very Gentle
Rating: [ ]

---

### Section 4: Specific Feedback

**4.1 What works well?**
Tell us about features or aspects you love.

[ Text response - 2-3 sentences ]

**4.2 What needs improvement?**
Tell us about pain points or missing features.

[ Text response - 2-3 sentences ]

**4.3 Unexpected benefits**
Did you discover any unexpected benefits?

[ Text response - optional ]

**4.4 Unexpected challenges**
Did you encounter any unexpected challenges?

[ Text response - optional ]

---

### Section 5: Performance & Reliability

**5.1 Response time**
Compared to before, response times are:
[ ] Much faster
[ ] Somewhat faster
[ ] About the same
[ ] Somewhat slower
[ ] Much slower

**5.2 Reliability (1-5)**
1 = Very Unreliable | 5 = Very Reliable
Rating: [ ]

**5.3 Encountered issues?**
[ ] Yes, frequently (multiple times/day)
[ ] Yes, occasionally (few times/week)
[ ] Yes, rarely (once or twice total)
[ ] No issues

If yes, please describe:
[ Text response ]

---

### Section 6: Recommendations

**6.1 Would you recommend to colleagues?**
Net Promoter Score: How likely are you to recommend? (0-10)
0 = Not at all likely | 10 = Extremely likely
Rating: [ ]

**6.2 Continue using after pilot?**
[ ] Definitely yes
[ ] Probably yes
[ ] Unsure
[ ] Probably no
[ ] Definitely no

---

### Section 7: Open Feedback

**7.1 Additional comments**
Any other feedback, suggestions, or thoughts?

[ Text response - optional, any length ]

---

Thank you for your detailed feedback! üéâ
```

---

## Final Survey (20 minutes)

**Timing**: End of Week 4  
**Purpose**: Comprehensive evaluation and rollout recommendation

### Template

```markdown
## üéì Final Pilot Survey

Congratulations on completing the AI Context Optimizer pilot! 
This final survey captures your overall experience and recommendations.

### Section 1: Overall Evaluation

**1.1 Overall satisfaction (1-5)**
1 = Very Dissatisfied | 5 = Very Satisfied
Rating: [ ]

**1.2 Met your expectations?**
[ ] Exceeded expectations
[ ] Met expectations
[ ] Somewhat below expectations
[ ] Well below expectations

**1.3 Overall value (1-5)**
1 = No Value | 5 = Extremely Valuable
Rating: [ ]

---

### Section 2: Impact Summary

**2.1 Productivity impact**
Overall, the optimizer made me:
[ ] Much more productive (+2)
[ ] Somewhat more productive (+1)
[ ] About the same (0)
[ ] Somewhat less productive (-1)
[ ] Much less productive (-2)

**2.2 Token reduction awareness**
I noticed token reduction of approximately:
[ ] >40% (significant)
[ ] 30-40% (substantial)
[ ] 20-30% (moderate)
[ ] 10-20% (minor)
[ ] <10% (minimal)
[ ] Unsure/didn't notice

**2.3 Quality impact**
My code quality:
[ ] Improved significantly
[ ] Improved somewhat
[ ] Stayed the same
[ ] Declined somewhat
[ ] Declined significantly

**2.4 Development speed**
Time to complete tasks:
[ ] Much faster (>20% improvement)
[ ] Faster (10-20% improvement)
[ ] About the same (¬±10%)
[ ] Slower (10-20% decline)
[ ] Much slower (>20% decline)

---

### Section 3: Feature Evaluation

**3.1 Feature usefulness** (Rate each 1-5)
1 = Not Useful | 5 = Extremely Useful

Context pruning: [ ]
Smart caching: [ ]
Template suggestions: [ ]
Auto-compression: [ ]
Custom rules: [ ]

**3.2 Must-have features**
Which features are essential? (Select all that apply)
[ ] Context pruning
[ ] Smart caching
[ ] Template suggestions
[ ] Auto-compression
[ ] Custom rules

**3.3 Could-live-without features**
Which features are non-essential?
[ ] Context pruning
[ ] Smart caching
[ ] Template suggestions
[ ] Auto-compression
[ ] Custom rules

**3.4 Missing features**
What features should be added?

[ Text response ]

---

### Section 4: Usability Assessment

**4.1 System Usability Scale (SUS)**

Rate each statement (1-5):
1 = Strongly Disagree | 5 = Strongly Agree

a) I think I would like to use this system frequently: [ ]
b) I found the system unnecessarily complex: [ ]
c) I thought the system was easy to use: [ ]
d) I would need support to be able to use this system: [ ]
e) I found the various functions well integrated: [ ]
f) I thought there was too much inconsistency: [ ]
g) Most people would learn this system quickly: [ ]
h) I found the system very cumbersome to use: [ ]
i) I felt very confident using the system: [ ]
j) I needed to learn a lot before I could get going: [ ]

**4.2 Setup experience**
Setting up the optimizer was:
[ ] Very easy
[ ] Easy
[ ] Moderate
[ ] Difficult
[ ] Very difficult

**4.3 Documentation quality (1-5)**
1 = Very Poor | 5 = Excellent
Rating: [ ]

---

### Section 5: Comparison

**5.1 Best aspect vs. previous workflow**
What improved most compared to not using the optimizer?

[ Text response - 2-3 sentences ]

**5.2 Worst aspect vs. previous workflow**
What was worse compared to not using the optimizer?

[ Text response - 2-3 sentences ]

**5.3 Breaking point**
What would make you stop using the optimizer?

[ Text response - 2-3 sentences ]

---

### Section 6: Recommendations

**6.1 Net Promoter Score**
How likely are you to recommend to a colleague? (0-10)
0 = Not at all likely | 10 = Extremely likely
Rating: [ ]

Reason (optional):
[ Text response ]

**6.2 Rollout recommendation**
Should this be rolled out to all developers?
[ ] Strong yes - roll out immediately
[ ] Yes - roll out with minor improvements
[ ] Maybe - needs significant improvements
[ ] No - not ready for rollout
[ ] Strong no - should not be rolled out

**6.3 Improvement priority**
What should be fixed/improved before rollout?

[ Text response ]

**6.4 Continue using?**
After the pilot ends, I will:
[ ] Definitely keep using it
[ ] Probably keep using it
[ ] Unsure
[ ] Probably stop using it
[ ] Definitely stop using it

---

### Section 7: Use Cases

**7.1 Most effective for**
The optimizer worked best for:
(Select all that apply)
[ ] Writing new code
[ ] Refactoring existing code
[ ] Debugging
[ ] Writing tests
[ ] Writing documentation
[ ] Code review
[ ] Learning new concepts
[ ] Other: __________

**7.2 Least effective for**
The optimizer worked worst for:
(Select all that apply)
[ ] Writing new code
[ ] Refactoring existing code
[ ] Debugging
[ ] Writing tests
[ ] Writing documentation
[ ] Code review
[ ] Learning new concepts
[ ] Other: __________

---

### Section 8: Demographics (Optional)

**8.1 Experience level**
[ ] Junior (0-2 years)
[ ] Mid-level (3-5 years)
[ ] Senior (6-10 years)
[ ] Staff+ (10+ years)

**8.2 Primary language**
[ ] Python
[ ] JavaScript/TypeScript
[ ] Both equally
[ ] Other: __________

**8.3 AI assistant usage before pilot**
[ ] Heavy user (10+ interactions/day)
[ ] Regular user (5-10 interactions/day)
[ ] Moderate user (2-4 interactions/day)
[ ] Light user (1-2 interactions/day)

---

### Section 9: Open Feedback

**9.1 Success story**
Share a specific example where the optimizer helped you.

[ Text response ]

**9.2 Challenge story**
Share a specific example where the optimizer hindered you.

[ Text response ]

**9.3 Suggestions for improvement**
If you could change one thing, what would it be?

[ Text response ]

**9.4 Final thoughts**
Any other comments or feedback?

[ Text response - any length ]

---

### Section 10: Participation

**10.1 Time commitment**
Was the time commitment reasonable?
[ ] Yes, very reasonable
[ ] Yes, reasonable
[ ] Borderline
[ ] No, too much time
[ ] No, way too much time

**10.2 Support quality (1-5)**
1 = Very Poor | 5 = Excellent
Rating: [ ]

**10.3 Communication quality (1-5)**
1 = Very Poor | 5 = Excellent
Rating: [ ]

**10.4 Would you participate in future pilots?**
[ ] Definitely yes
[ ] Probably yes
[ ] Unsure
[ ] Probably no
[ ] Definitely no

---

## üéâ Thank you for your participation!

Your feedback has been invaluable. We'll share the results and next 
steps soon.

---

Estimated time: 20 minutes
```

---

## Issue Reporting Template

**When**: As issues arise  
**Channel**: GitHub Issues or dedicated channel

### Template

```markdown
## üêõ Pilot Issue Report

**Reporter**: [Your Name]
**Date**: [Date]
**Severity**: [ ] Critical [ ] High [ ] Medium [ ] Low

### Issue Description
[Clear description of the issue]

### Steps to Reproduce
1. [Step 1]
2. [Step 2]
3. [Step 3]

### Expected Behavior
[What should happen]

### Actual Behavior
[What actually happens]

### Impact
[ ] Blocks all work
[ ] Blocks some work
[ ] Workaround available
[ ] Minor inconvenience

### Environment
- OS: [e.g., macOS 14.0]
- IDE: [e.g., VS Code 1.85]
- AI Assistant: [e.g., Claude, Copilot]
- Optimizer Version: [e.g., 0.1.0]

### Additional Context
[Screenshots, logs, or other relevant information]
```

---

## Success Story Template

**When**: Anytime something great happens  
**Channel**: Slack/Discord channel

### Template

```markdown
## ‚ú® Success Story

**What happened?**
[Brief description of the successful outcome]

**Context**
[What task were you working on?]

**How the optimizer helped**
[Specific ways the optimizer made a difference]

**Metrics** (if available)
- Tokens saved: [estimate]
- Time saved: [estimate]
- Iterations reduced: [count]

**Would you like this featured?**
[ ] Yes, you can share this publicly
[ ] Yes, but anonymously
[ ] No, for internal use only
```

---

## Interview Guide (Optional)

**Who**: 3-5 selected volunteers  
**When**: End of pilot  
**Duration**: 30 minutes  
**Format**: Video call

### Interview Script

```markdown
## üìû Pilot Program Exit Interview

### Introduction (2 min)
Thank you for participating and agreeing to this interview. 
This is an open discussion about your experience.

### Section 1: Overall Experience (10 min)

1. How would you describe your overall experience in one sentence?

2. What surprised you most during the pilot?

3. Walk me through a typical day using the optimizer.

4. Tell me about a time when the optimizer really helped you.

5. Tell me about a time when the optimizer frustrated you.

### Section 2: Specific Features (8 min)

6. Which feature did you use most? Why?

7. Which feature did you use least? Why?

8. If you could only keep one feature, which would it be?

9. If you could add one feature, what would it be?

### Section 3: Impact (5 min)

10. How did the optimizer change your workflow?

11. Did you notice the token reduction? How did it affect you?

12. Did your code quality change? In what ways?

### Section 4: Future (3 min)

13. Would you recommend this to your team? Why or why not?

14. What would make you stop using it?

15. Any final thoughts or suggestions?

### Closing (2 min)
Thank you! Your insights are incredibly valuable.
```

---

## Feedback Analysis Framework

### Quantitative Analysis

1. **Calculate scores**
   - Mean satisfaction scores
   - NPS calculation
   - SUS score calculation
   - Feature ratings

2. **Track trends**
   - Week-over-week changes
   - Individual trajectories
   - Cohort comparisons

3. **Identify patterns**
   - Correlations between metrics
   - Feature usage patterns
   - Issue frequency patterns

### Qualitative Analysis

1. **Thematic coding**
   - Categorize open-ended responses
   - Identify recurring themes
   - Extract representative quotes

2. **Sentiment analysis**
   - Positive vs. negative feedback
   - Emotional language patterns
   - Intensity of opinions

3. **Use case mapping**
   - When optimizer works well
   - When optimizer struggles
   - Context-specific insights

---

## Response Guidelines

### Acknowledge All Feedback

**Within 24 hours**:
```markdown
Hi [Name],

Thank you for your feedback on [topic]. We've noted your 
[suggestion/concern/praise] and [action being taken].

[Specific response to their feedback]

Keep the feedback coming!

Best,
[Program Team]
```

### Address Critical Issues

**Within 2 hours**:
```markdown
Hi [Name],

We've seen your critical issue report about [issue]. 
This is our top priority.

Current status: [investigating/fixing/testing]
Workaround: [if available]
ETA: [if known]

We'll keep you updated.

Best,
[Program Team]
```

### Share Quick Wins

**Within 48 hours of implementing feedback**:
```markdown
Hi everyone,

Thanks to feedback from [Name], we've implemented [improvement].
You should see this in [next update/now].

This is a great example of how your feedback shapes the pilot!

Keep it coming!

Best,
[Program Team]
```

---

**Contact**: feedback@tta.dev  
**Version**: 1.0.0  
**Last Updated**: 2025-10-29
