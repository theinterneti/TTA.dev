# Free-Tier LLM Analysis for ACE Phase 2 Integration

**Zero-Cost LLM Options for Self-Learning Code Generation**

**Date:** November 7, 2025
**Purpose:** Identify optimal free-tier LLM for ACE + E2B integration
**Constraint:** $0.00 additional cost beyond existing subscriptions

---

## ðŸŽ¯ Executive Summary

**CRITICAL FINDING:** Google AI Studio provides **FREE access to Gemini 2.5 Pro** (not just Flash) via API!

**Recommendation:** Use **Google AI Studio + Gemini 2.5 Pro** for ACE Phase 2 integration.

**Why:**
- âœ… **Zero cost** (free tier, not trial)
- âœ… **Gemini 2.5 Pro** available (most capable model)
- âœ… **User already has API key** (ready to use)
- âœ… **Generous limits** (sufficient for development)
- âœ… **No credit card required** (true free tier)

---

## ðŸ“Š Google AI Studio Free Tier Analysis

### Models Available (FREE)

| Model | Free Tier Access | Input Price | Output Price | Best For |
|-------|------------------|-------------|--------------|----------|
| **Gemini 2.5 Pro** | âœ… YES | FREE | FREE | **Complex reasoning, coding** â­ |
| **Gemini 2.5 Flash** | âœ… YES | FREE | FREE | Fast, balanced tasks |
| **Gemini 2.5 Flash-Lite** | âœ… YES | FREE | FREE | High-volume, cost-sensitive |
| **Gemini 2.0 Flash** | âœ… YES | FREE | FREE | Multimodal, agents |
| **Gemma 3** | âœ… YES | FREE | FREE | Lightweight, open-source |

### Key Features (Free Tier)

**âœ… What's Included:**
- **Gemini 2.5 Pro** - State-of-the-art coding and reasoning
- **1M token context window** (Gemini 2.5 Flash, 2.0 Flash)
- **Google AI Studio access** (web UI for testing)
- **API access** (Python SDK, REST API)
- **No credit card required**

**âš ï¸ Limitations:**
- **Rate limits** (not publicly documented, but generous for development)
- **Content used to improve products** (data logging enabled)
- **No context caching** (paid tier only)
- **No batch API** (paid tier only)

### Rate Limits (Free Tier)

**From documentation:**
- "Limited access to certain models" (but includes Gemini 2.5 Pro!)
- "Free input & output tokens"
- Rate limits not explicitly stated (likely 15-60 RPM based on community reports)

**Estimated Limits (based on community reports):**
- **Requests per minute (RPM):** 15-60 (varies by model)
- **Tokens per minute (TPM):** 32,000-1,000,000 (varies by model)
- **Requests per day (RPD):** 1,500 (for some features like Google Search grounding)

**For ACE use case:**
- Test generation: 3-5 iterations per TODO
- Each iteration: 1 request (~2,000-5,000 tokens)
- Total per TODO: 5-15 requests, ~10,000-25,000 tokens
- **Conclusion:** Free tier is MORE than sufficient

---

## ðŸ” Alternative Free-Tier Options

### OpenRouter Free Models

**Status:** âš ï¸ Limited and restrictive

**Free Models Available:**
- DeepSeek V3 (recently limited to 200 requests/day)
- Some other models with severe rate limits

**Issues:**
- Rate limits recently reduced (April 2025)
- Requires 10 credits purchase ($10) for 1000 requests/day
- Less generous than Google AI Studio
- More complex setup

**Verdict:** âŒ Not recommended (Google AI Studio is better)

### Cline + Free LLM

**Status:** âœ… Possible but requires configuration

**Cline Features:**
- VS Code extension (not CLI)
- MCP integration support
- Supports custom LLM providers
- Can use Google AI Studio API

**Setup:**
- Configure Cline to use Google AI Studio API
- Use Gemini 2.5 Pro via API key
- Integrate with TTA.dev primitives

**Verdict:** â­ï¸ Possible, but adds complexity (evaluate if needed)

### OpenHands + Free LLM

**Status:** â­ï¸ Requires investigation

**OpenHands Features:**
- Mature sub-agent framework
- MCP integration potential
- Supports multiple LLM providers

**Issues:**
- No clear documentation on free-tier LLM integration
- May require paid LLM for full functionality
- More complex than direct API integration

**Verdict:** â­ï¸ Defer to future phase (start with direct API)

---

## ðŸ’¡ Recommended Approach

### Phase 2A: Direct Google AI Studio Integration (Week 1)

**Goal:** Replace mock implementation with real LLM code generation

**Steps:**
1. **Install Google AI SDK**
   ```bash
   uv add google-generativeai
   ```

2. **Update `_generate_code_with_strategies()`**
   ```python
   import google.generativeai as genai

   async def _generate_code_with_strategies(self, task, context, language, strategies):
       """Generate code using Gemini 2.5 Pro + learned strategies."""

       # Configure API
       genai.configure(api_key=os.getenv("GOOGLE_AI_STUDIO_API_KEY"))
       model = genai.GenerativeModel("gemini-2.5-pro")

       # Build prompt with strategies
       prompt = f"""Generate {language} code for: {task}

   Context: {context}

   Apply these learned strategies:
   {self._format_strategies(strategies)}

   Generate production-quality code that follows best practices.
   Include proper imports, error handling, and documentation.
   """

       # Generate code
       response = await model.generate_content_async(prompt)
       return response.text
   ```

3. **Test with CachePrimitive**
   - Re-run test generation
   - Validate 90%+ coverage
   - Measure strategies learned

**Expected Results:**
- Real pytest tests (not placeholders)
- 3-5 iterations to working tests
- Strategies that improve code quality
- Cost: $0.00 (free tier)

### Phase 2B: Sub-Agent Integration (Week 2-3, Optional)

**Goal:** Integrate Cline or OpenHands for enhanced capabilities

**Only if:**
- Direct API integration proves insufficient
- Need for more sophisticated agent behavior
- MCP integration becomes critical

**Defer until:** Phase 2A is complete and validated

---

## ðŸ“‹ Implementation Checklist

### Immediate (This Week)

- [x] âœ… Research free-tier LLM options
- [x] âœ… Confirm Google AI Studio Gemini 2.5 Pro access
- [ ] â­ï¸ Install Google AI SDK (`uv add google-generativeai`)
- [ ] â­ï¸ Update `_generate_code_with_strategies()` with real LLM
- [ ] â­ï¸ Test with simple code generation task
- [ ] â­ï¸ Re-run CachePrimitive test generation

### Short-Term (Next Week)

- [ ] Validate 90%+ test coverage achieved
- [ ] Measure strategies learned and quality
- [ ] Document API usage patterns
- [ ] Update ACE_INTEGRATION_ROADMAP.md
- [ ] Create example showing real LLM integration

### Medium-Term (Weeks 3-4, Optional)

- [ ] Evaluate Cline integration (if needed)
- [ ] Evaluate OpenHands integration (if needed)
- [ ] Implement MCP integration (if needed)
- [ ] Build benchmark suite for LLM performance

---

## ðŸŽ“ Key Learnings

### 1. **Google AI Studio is Incredibly Generous**

**Free Tier Includes:**
- Gemini 2.5 Pro (most capable model)
- Gemini 2.5 Flash (fast, balanced)
- Multiple other models
- No credit card required
- Sufficient rate limits for development

**This is NOT a trial** - it's a permanent free tier!

### 2. **User Already Has API Key**

From conversation history:
> "User has Google AI Studio API key and wants to verify Gemini Pro free access"

**Action:** Use existing API key, no setup needed!

### 3. **Sub-Agents Add Complexity**

**Direct API integration is simpler:**
- Fewer dependencies
- Easier to debug
- More control over prompts
- Faster iteration

**Sub-agents (Cline, OpenHands) add value when:**
- Need sophisticated agent behavior
- MCP integration is critical
- Multi-step workflows required

**Recommendation:** Start simple (direct API), add complexity only if needed

### 4. **Free Tier is Sufficient for ACE**

**ACE use case:**
- 3-5 iterations per TODO
- 5-15 requests per TODO
- ~10,000-25,000 tokens per TODO

**Free tier limits:**
- 15-60 RPM (sufficient)
- 32K-1M TPM (more than enough)
- 1,500 RPD for some features (plenty)

**Conclusion:** Can complete 100+ TODOs per day on free tier!

---

## ðŸš€ Next Steps

1. **Install Google AI SDK**
   ```bash
   cd /home/thein/repos/TTA.dev
   uv add google-generativeai
   ```

2. **Update cognitive_manager.py**
   - Replace mock `_generate_code_with_strategies()`
   - Use Gemini 2.5 Pro API
   - Implement strategy-aware prompting

3. **Test with Simple Task**
   - Generate a simple function (fibonacci, prime check)
   - Validate code executes in E2B
   - Confirm learning loop works

4. **Re-run CachePrimitive Test Generation**
   - Use real LLM instead of mock
   - Target 90%+ coverage
   - Measure strategies learned

5. **Document Results**
   - Update ACE_INTEGRATION_ROADMAP.md
   - Create example code
   - Update Logseq TODO

---

## ðŸ’° Cost Analysis

### Current (Mock Implementation)

- **LLM Cost:** $0.00 (no LLM calls)
- **E2B Cost:** $0.00 (free tier)
- **Total:** $0.00

### Phase 2 (Google AI Studio)

- **LLM Cost:** $0.00 (free tier)
- **E2B Cost:** $0.00 (free tier)
- **Total:** $0.00

### Alternative (Paid LLM)

- **OpenAI GPT-4:** ~$0.15-0.30 per TODO
- **Anthropic Claude:** ~$0.10-0.20 per TODO
- **Google Vertex AI:** ~$0.08-0.15 per TODO

**Savings with Free Tier:** 100% ($0.15-0.30 per TODO avoided)

---

**Conclusion:** Google AI Studio + Gemini 2.5 Pro is the optimal choice for ACE Phase 2 integration. Zero cost, generous limits, and user already has API key. Proceed with direct API integration before considering sub-agents.

---

**Last Updated:** November 7, 2025
**Status:** Research Complete âœ…
**Next Milestone:** Implement LLM Integration (Phase 2A)



---
**Logseq:** [[TTA.dev/_archive/Planning/Free_tier_llm_analysis]]
